{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"color-code-stim","text":"<p>Python package for simulating &amp; decoding 2D color code circuits via the concatenated MWPM decoder.</p>"},{"location":"#installation","title":"Installation","text":"<p>Requires Python &gt;= 3.11</p> <pre><code>pip install color-code-stim\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>from color_code_stim import ColorCode, NoiseModel\n\n# Create noise model\nnoise = NoiseModel.uniform_circuit_noise(1e-3)\n\n# Create color code instance\ncolorcode = ColorCode(\n    d=5,                    # Code distance\n    rounds=5,              # Syndrome extraction rounds\n    circuit_type=\"tri\",    # Circuit type\n    noise_model=noise      # Noise configuration\n)\n\n# Run simulation\nnum_fails, info = colorcode.simulate(shots=10000, full_output=True)\n</code></pre> <p>See the Getting Started Notebook for more details.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Simulation of 2D color code circuits using Stim</li> <li>Concatenated Minimum-Weight Perfect Matching (MWPM) decoder implementation</li> <li>Support for multiple circuit types: memory experiments with triangular/rectangular patches, stability experiments, growing operation, and cultivation+growing circuit</li> <li>Monte Carlo simulation for decoder performance evaluation</li> <li>Comparative decoding with logical gap calculation</li> </ul>"},{"location":"#citation","title":"Citation","text":"<pre><code>@article{lee2025color,\n  doi = {10.22331/q-2025-01-27-1609},\n  title = {Color code decoder with improved scaling for correcting circuit-level noise},\n  author = {Lee, Seok-Hyung and Li, Andrew and Bartlett, Stephen D.},\n  journal = {{Quantum}},\n  volume = {9},\n  pages = {1609},\n  year = {2025}\n}\n</code></pre>"},{"location":"api/circuit_builder/","title":"CircuitBuilder","text":"<p>Builder class for constructing color code quantum circuits.</p> <p>This class extracts circuit generation logic from the monolithic ColorCode class to provide modular, testable circuit construction for different topologies.</p> Source code in <code>src/color_code_stim/circuit_builder.py</code> <pre><code>class CircuitBuilder:\n    \"\"\"\n    Builder class for constructing color code quantum circuits.\n\n    This class extracts circuit generation logic from the monolithic ColorCode class\n    to provide modular, testable circuit construction for different topologies.\n    \"\"\"\n\n    def __init__(\n        self,\n        d: int,\n        d2: Optional[int],\n        rounds: int,\n        circuit_type: CIRCUIT_TYPE,\n        cnot_schedule: List[int],\n        superdense_circuit: bool,\n        temp_bdry_type: str,\n        noise_model: Union[NoiseModel, Dict[str, float]],\n        perfect_init_final: bool,\n        perfect_logical_initialization: bool,\n        perfect_logical_measurement: bool,\n        perfect_first_syndrome_extraction: bool,\n        tanner_graph: ig.Graph,\n        qubit_groups: Dict[str, ig.VertexSeq],\n        exclude_non_essential_pauli_detectors: bool = False,\n        cultivation_circuit: Optional[stim.Circuit] = None,\n        comparative_decoding: bool = False,\n    ):\n        \"\"\"\n        Initialize the circuit builder.\n\n        Parameters\n        ----------\n        d : int\n            Code distance.\n        d2 : Optional[int]\n            Second code distance (required for some circuit types).\n        rounds : int\n            Number of syndrome extraction rounds.\n        circuit_type : CIRCUIT_TYPE\n            Type of circuit to build.\n        cnot_schedule : List[int]\n            CNOT gate schedule.\n        superdense_circuit : bool\n            Whether to use superdense syndrome extraction circuit.\n        temp_bdry_type : str\n            Temporal boundary type.\n        noise_model : NoiseModel or Dict[str, float]\n            Noise model specifying error rates for different operations.\n        perfect_init_final : bool\n            Whether to use perfect initialization and final measurement (backward compatibility).\n        perfect_logical_initialization : bool\n            Whether logical initialization operations (data qubit reset) are noiseless.\n        perfect_logical_measurement : bool\n            Whether logical final measurement operations are noiseless.\n        perfect_first_syndrome_extraction : bool\n            Whether the first syndrome extraction round is noiseless.\n        tanner_graph : ig.Graph\n            The Tanner graph representing the color code.\n        qubit_groups : Dict[str, ig.VertexSeq]\n            Grouped qubits by type (data, anc, anc_Z, anc_X).\n        exclude_non_essential_pauli_detectors : bool, default False\n            Whether to exclude non-essential Pauli detectors.\n        cultivation_circuit : Optional[stim.Circuit], default None\n            Cultivation circuit for cult+growing.\n        comparative_decoding : bool, default False\n            Whether to use comparative decoding.\n        \"\"\"\n        self.d = d\n        self.d2 = d2\n        self.rounds = rounds\n        self.circuit_type = circuit_type\n        self.cnot_schedule = cnot_schedule\n        self.superdense_circuit = superdense_circuit\n        self.temp_bdry_type = temp_bdry_type\n        self.noise_model = noise_model\n        self.perfect_init_final = perfect_init_final\n        self.perfect_logical_initialization = perfect_logical_initialization\n        self.perfect_logical_measurement = perfect_logical_measurement\n        self.perfect_first_syndrome_extraction = perfect_first_syndrome_extraction\n        self.tanner_graph = tanner_graph\n        self.qubit_groups = qubit_groups\n        self.exclude_non_essential_pauli_detectors = (\n            exclude_non_essential_pauli_detectors\n        )\n        self.cultivation_circuit = cultivation_circuit\n        self.comparative_decoding = comparative_decoding\n\n        # Validate parameters\n        self.validate()\n\n        # Extract physical error rates\n        self.p_bitflip = noise_model[\"bitflip\"]\n        self.p_depol = noise_model[\"depol\"]\n        self.p_reset = noise_model[\"reset\"]\n        self.p_meas = noise_model[\"meas\"]\n        self.p_cnot = noise_model[\"cnot\"]\n        self.p_idle = noise_model[\"idle\"]\n        self.p_initial_data_qubit_depol = noise_model[\"initial_data_qubit_depol\"]\n        self.p_depol1_after_cnot = noise_model[\"depol1_after_cnot\"]\n        self.p_idle_during_cnot = noise_model[\"idle_during_cnot\"]\n        self.p_idle_during_meas = noise_model[\"idle_during_meas\"]\n\n        # Extract granular reset/measurement rates\n        self.p_reset_data = noise_model[\"reset_data\"]\n        self.p_reset_anc_X = noise_model[\"reset_anc_X\"]\n        self.p_reset_anc_Z = noise_model[\"reset_anc_Z\"]\n        self.p_meas_data = noise_model[\"meas_data\"]\n        self.p_meas_anc_X = noise_model[\"meas_anc_X\"]\n        self.p_meas_anc_Z = noise_model[\"meas_anc_Z\"]\n\n        # Extract qubit groups\n        self.data_qubits = qubit_groups[\"data\"]\n        self.anc_qubits = qubit_groups[\"anc\"]\n        self.anc_Z_qubits = qubit_groups[\"anc_Z\"]\n        self.anc_X_qubits = qubit_groups[\"anc_X\"]\n\n        # Extract qubit IDs\n        self.data_qids = self.data_qubits[\"qid\"]\n        self.anc_qids = self.anc_qubits[\"qid\"]\n        self.anc_Z_qids = self.anc_Z_qubits[\"qid\"]\n        self.anc_X_qids = self.anc_X_qubits[\"qid\"]\n\n        # Calculate counts\n        self.num_data_qubits = len(self.data_qids)\n        self.num_anc_Z_qubits = len(self.anc_Z_qubits)\n        self.num_anc_X_qubits = len(self.anc_X_qubits)\n        self.num_anc_qubits = self.num_anc_X_qubits + self.num_anc_Z_qubits\n\n        self.num_qubits = tanner_graph.vcount()\n        self.all_qids = list(range(self.num_qubits))\n        self.all_qids_set = set(self.all_qids)\n\n    def validate(self) -&gt; None:\n        \"\"\"\n        Validate parameter compatibility with circuit type.\n\n        Raises\n        ------\n        ValueError\n            If parameters are incompatible with the specified circuit_type.\n        \"\"\"\n        # Validate rounds\n        if self.rounds &lt; 1:\n            raise ValueError(f\"rounds must be &gt;= 1. Got rounds={self.rounds}\")\n\n        # Validate circuit_type\n        supported_types = set(get_args(CIRCUIT_TYPE))\n        if self.circuit_type not in supported_types:\n            raise ValueError(\n                f\"circuit_type must be one of {supported_types}. Got circuit_type='{self.circuit_type}'\"\n            )\n\n        # Validate cnot_schedule\n        if len(self.cnot_schedule) != 12:\n            raise ValueError(\n                f\"cnot_schedule must have 12 integers. Got {len(self.cnot_schedule)} elements\"\n            )\n        if not all(isinstance(x, int) for x in self.cnot_schedule):\n            raise ValueError(\n                f\"cnot_schedule must contain only integers. Got {self.cnot_schedule}\"\n            )\n\n        # Validate temp_bdry_type based on circuit_type\n        if self.circuit_type in {\"tri\", \"rec\", \"growing\"}:\n            if self.temp_bdry_type not in {\"X\", \"Y\", \"Z\"}:\n                raise ValueError(\n                    f\"'{self.circuit_type}' circuit requires temp_bdry_type in {{'X', 'Y', 'Z'}}. Got temp_bdry_type='{self.temp_bdry_type}'\"\n                )\n        elif self.circuit_type == \"cult+growing\":\n            if self.temp_bdry_type != \"Y\":\n                raise ValueError(\n                    f\"'cult+growing' circuit requires temp_bdry_type='Y'. Got temp_bdry_type='{self.temp_bdry_type}'\"\n                )\n        elif self.circuit_type == \"rec_stability\":\n            if self.temp_bdry_type != \"r\":\n                raise ValueError(\n                    f\"'rec_stability' circuit requires temp_bdry_type='r'. Got temp_bdry_type='{self.temp_bdry_type}'\"\n                )\n\n        # Validate d and d2 constraints\n        if self.circuit_type == \"tri\":\n            if self.d &lt; 3 or self.d % 2 == 0:\n                raise ValueError(f\"'tri' circuit requires d: odd &gt;= 3. Got d={self.d}\")\n\n        elif self.circuit_type == \"rec\":\n            if (\n                self.d &lt; 2\n                or self.d % 2 != 0\n                or self.d2 is None\n                or self.d2 &lt; 2\n                or self.d2 % 2 != 0\n            ):\n                raise ValueError(\n                    f\"'rec' circuit requires d, d2: even &gt;= 2. Got d={self.d}, d2={self.d2}\"\n                )\n\n        elif self.circuit_type == \"rec_stability\":\n            if (\n                self.d &lt; 4\n                or self.d % 2 != 0\n                or self.d2 is None\n                or self.d2 &lt; 4\n                or self.d2 % 2 != 0\n            ):\n                raise ValueError(\n                    f\"'rec_stability' circuit requires d, d2: even &gt;= 4. Got d={self.d}, d2={self.d2}\"\n                )\n\n        elif self.circuit_type == \"growing\":\n            if (\n                self.d &lt; 3\n                or self.d % 2 == 0\n                or self.d2 is None\n                or self.d2 % 2 == 0\n                or self.d2 &lt;= self.d\n            ):\n                raise ValueError(\n                    f\"'growing' circuit requires d, d2: odd, d2 &gt; d &gt;= 3. Got d={self.d}, d2={self.d2}\"\n                )\n\n        elif self.circuit_type == \"cult+growing\":\n            if (\n                self.d not in {3, 5}\n                or self.d2 is None\n                or self.d2 % 2 == 0\n                or self.d2 &lt;= self.d\n            ):\n                raise ValueError(\n                    f\"'cult+growing' circuit requires d in {{3, 5}}, d2: odd, d2 &gt; d. Got d={self.d}, d2={self.d2}\"\n                )\n\n    def build(self) -&gt; stim.Circuit:\n        \"\"\"\n        Build the complete quantum circuit.\n\n        Returns\n        -------\n        stim.Circuit\n            The constructed quantum circuit.\n        \"\"\"\n        # Identify red linkes (only for 'rec_stability', 'growing', and 'cult+growing')\n        red_links, data_q1s, data_q2s = self._identify_red_links()\n\n        # Initialize main circuit with qubit coordinates\n        circuit = self._initialize_circuit_with_coordinates()\n\n        # Add cultivation circuit if needed\n        interface_detectors_info = self._add_cultivation_circuit(circuit)\n\n        # Build syndrome extraction circuits\n        synd_extr_circuits, obs_included_lookbacks = (\n            self._build_syndrome_extraction_circuits(interface_detectors_info)\n        )\n\n        # Add data qubit initialization\n        self._add_data_qubit_initialization(circuit, red_links, data_q1s, data_q2s)\n\n        # Add initial data qubit depolarizing noise if perfect_first_syndrome_extraction=False\n        if not self.perfect_first_syndrome_extraction:\n            self._add_initial_data_qubit_depol(circuit)\n\n        # Add ancilla qubit initialization\n        self._add_ancilla_initialization(circuit)\n\n        # Add main syndrome extraction rounds\n        circuit += synd_extr_circuits[0]\n\n        # Add initial data qubit depolarizing noise if perfect_first_syndrome_extraction=True\n        if self.perfect_first_syndrome_extraction:\n            self._add_initial_data_qubit_depol(circuit)\n\n        circuit += synd_extr_circuits[1] * (self.rounds - 1)\n\n        # Add final measurements and detectors\n        self._add_final_measurements_and_detectors(\n            circuit, red_links, data_q1s, data_q2s\n        )\n\n        # Add logical observables\n        self._add_logical_observables(circuit, obs_included_lookbacks)\n\n        return circuit\n\n    def _add_initial_data_qubit_depol(self, circuit: stim.Circuit) -&gt; None:\n        \"\"\"\n        Add initial data qubit depolarizing noise.\n\n        Timing depends on perfect_first_syndrome_extraction:\n        - If True: Applied after first syndrome extraction round\n        - If False: Applied after data qubit initialization\n        \"\"\"\n        if self.p_initial_data_qubit_depol &gt; 0:\n            circuit.append(\n                \"DEPOLARIZE1\", self.data_qids, self.p_initial_data_qubit_depol\n            )\n\n    def _identify_red_links(\n        self,\n    ) -&gt; Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray]]:\n        \"\"\"Identify red links for the circuit.\"\"\"\n        if self.circuit_type == \"rec_stability\":\n            red_links = [\n                [link.source, link.target]\n                for link in self.tanner_graph.es.select(color=\"r\")\n            ]\n            red_links = np.array(red_links).reshape(-1, 2)\n            data_q1s = red_links[:, 0]\n            data_q2s = red_links[:, 1]\n        elif self.circuit_type in {\"tri\", \"rec\"}:\n            red_links = data_q1s = data_q2s = None\n        elif self.circuit_type in {\"growing\", \"cult+growing\"}:\n            x_offset_init_patch = 6 * round((self.d2 - self.d) / 2)\n            y_offset_init_patch = 3 * round((self.d2 - self.d) / 2)\n            self.x_offset_init_patch = x_offset_init_patch\n            self.y_offset_init_patch = y_offset_init_patch\n\n            data_qubits_outside_init_patch = self.data_qubits.select(\n                y_lt=y_offset_init_patch\n            )\n            red_links = [\n                [link.source, link.target]\n                for link in self.tanner_graph.es.select(\n                    color=\"r\",\n                    _within=data_qubits_outside_init_patch,\n                )\n            ]\n            red_links = np.array(red_links)\n            data_q1s = red_links[:, 0]\n            data_q2s = red_links[:, 1]\n        else:\n            raise NotImplementedError(\n                f\"Circuit type {self.circuit_type} not implemented\"\n            )\n\n        return red_links, data_q1s, data_q2s\n\n    def _initialize_circuit_with_coordinates(self) -&gt; stim.Circuit:\n        \"\"\"Initialize circuit and add qubit coordinates.\"\"\"\n        circuit = stim.Circuit()\n        for qubit in self.tanner_graph.vs:\n            coords = get_qubit_coords(qubit)\n            circuit.append(\"QUBIT_COORDS\", qubit.index, coords)\n        return circuit\n\n    def _add_cultivation_circuit(self, circuit: stim.Circuit) -&gt; Optional[Dict]:\n        \"\"\"Add cultivation circuit for cult+growing type.\"\"\"\n        if self.circuit_type == \"cult+growing\":\n            qubit_coords = {}\n            for qubit in self.tanner_graph.vs:\n                coords = get_qubit_coords(qubit)\n                qubit_coords[qubit.index] = coords\n\n            cult_circuit, interface_detectors_info = _reformat_cultivation_circuit(\n                self.cultivation_circuit,\n                self.d,\n                qubit_coords,\n                x_offset=self.x_offset_init_patch,\n                y_offset=self.y_offset_init_patch,\n            )\n            circuit += cult_circuit\n            return interface_detectors_info\n        return None\n\n    def _build_syndrome_extraction_circuits(\n        self,\n        interface_detectors_info: Optional[Dict],\n    ) -&gt; Tuple[List[stim.Circuit], Set]:\n        \"\"\"Build syndrome extraction circuits with and without detectors.\"\"\"\n        # Build circuits with measurements and detectors\n        synd_extr_circuits = []\n        obs_included_lookbacks = set()\n\n        for first in [True, False]:\n            # Check if this is the first round and perfect_first_syndrome_extraction is enabled\n            skip_noise = first and self.perfect_first_syndrome_extraction\n\n            # Build base syndrome extraction circuit (with or without noise)\n            base_result = self._build_base_syndrome_extraction(perfect_round=skip_noise)\n\n            # Handle different return types (regular vs superdense circuits)\n            if self.superdense_circuit:\n                synd_extr_circuit, z_anc_data_connections = base_result\n            else:\n                synd_extr_circuit = base_result\n                z_anc_data_connections = None\n\n            # Add bit-flip errors (skip if perfect first round)\n            if self.p_bitflip &gt; 0 and not skip_noise:\n                synd_extr_circuit.insert(\n                    0,\n                    stim.CircuitInstruction(\n                        \"X_ERROR\", self.data_qids, [self.p_bitflip]\n                    ),\n                )\n\n            # Add depolarizing errors (skip if perfect first round)\n            if self.p_depol &gt; 0 and not skip_noise:\n                synd_extr_circuit.insert(\n                    0,\n                    stim.CircuitInstruction(\n                        \"DEPOLARIZE1\", self.data_qids, [self.p_depol]\n                    ),\n                )\n\n            # Add measurements (use specific meas rates or 0 for perfect first round)\n            if skip_noise:\n                p_meas_anc_Z = 0\n                p_meas_anc_X = 0\n            else:\n                p_meas_anc_Z = self._get_meas_rate(\"anc_Z\")\n                p_meas_anc_X = self._get_meas_rate(\"anc_X\")\n            synd_extr_circuit.append(\"MRZ\", self.anc_Z_qids, p_meas_anc_Z)\n\n            # Add pauli feedforward for superdense syndrome extraction\n            if self.superdense_circuit and z_anc_data_connections:\n                # For each Z-type ancilla (in reverse measurement order)\n                for i, anc_Z_qid in enumerate(reversed(self.anc_Z_qids)):\n                    if anc_Z_qid in z_anc_data_connections:\n                        connected_data_qids = z_anc_data_connections[anc_Z_qid]\n                        # Measurement result index: most recent measurement = -1, next = -2, etc.\n                        measurement_target = stim.target_rec(-(i + 1))\n\n                        # Add CX gate from measurement result to each connected data qubit\n                        for data_qid in connected_data_qids:\n                            synd_extr_circuit.append(\n                                \"CX\", [measurement_target, data_qid]\n                            )\n\n            synd_extr_circuit.append(\"MRX\", self.anc_X_qids, p_meas_anc_X)\n\n            # Apply idle noise to data qubits during measurement operations\n            if not skip_noise:\n                idle_rate_meas = self._get_idle_rate_for_context(\"meas\")\n                if idle_rate_meas &gt; 0:\n                    synd_extr_circuit.append(\n                        \"DEPOLARIZE1\", self.data_qids, idle_rate_meas\n                    )\n\n            # Add detectors\n            obs_included_lookbacks = self._add_detectors(\n                synd_extr_circuit,\n                first,\n                interface_detectors_info,\n                obs_included_lookbacks,\n            )\n\n            # Add reset errors and idle errors (these are for the next round, so always include)\n            reset_rate_anc_Z = self._get_reset_rate(\"anc_Z\")\n            reset_rate_anc_X = self._get_reset_rate(\"anc_X\")\n            if reset_rate_anc_Z &gt; 0:\n                synd_extr_circuit.append(\"X_ERROR\", self.anc_Z_qids, reset_rate_anc_Z)\n            if reset_rate_anc_X &gt; 0:\n                synd_extr_circuit.append(\"Z_ERROR\", self.anc_X_qids, reset_rate_anc_X)\n\n            synd_extr_circuit.append(\"TICK\")\n            synd_extr_circuit.append(\"SHIFT_COORDS\", (), (0, 0, 1))\n\n            synd_extr_circuits.append(synd_extr_circuit)\n\n        return synd_extr_circuits, obs_included_lookbacks\n\n    def _build_base_syndrome_extraction(\n        self, perfect_round: bool = False\n    ) -&gt; Union[stim.Circuit, Tuple[stim.Circuit, Dict[int, List[int]]]]:\n        \"\"\"Build the base syndrome extraction circuit without SPAM operations.\n\n        Parameters\n        ----------\n        perfect_round : bool, default False\n            If True, skip CNOT and idle errors for a perfect syndrome extraction round.\n\n        Returns\n        -------\n        stim.Circuit or Tuple[stim.Circuit, Dict[int, List[int]]]\n            For regular circuits: Returns just the circuit.\n            For superdense circuits: Returns tuple of (circuit, z_anc_data_connections).\n        \"\"\"\n        # Route to superdense version if enabled\n        if self.superdense_circuit:\n            return self._build_superdense_syndrome_extraction(perfect_round)\n\n        synd_extr_circuit = stim.Circuit()\n\n        for timeslice in range(1, max(self.cnot_schedule) + 1):\n            targets = [\n                i for i, val in enumerate(self.cnot_schedule) if val == timeslice\n            ]\n            operated_qids = set()\n\n            CX_targets = []\n            for target in targets:\n                # Define offset based on target\n                if target in {0, 6}:\n                    offset = (-2, 1)\n                elif target in {1, 7}:\n                    offset = (2, 1)\n                elif target in {2, 8}:\n                    offset = (4, 0)\n                elif target in {3, 9}:\n                    offset = (2, -1)\n                elif target in {4, 10}:\n                    offset = (-2, -1)\n                else:\n                    offset = (-4, 0)\n\n                target_anc_qubits = (\n                    self.anc_Z_qubits if target &lt; 6 else self.anc_X_qubits\n                )\n                for anc_qubit in target_anc_qubits:\n                    data_qubit_x = anc_qubit[\"face_x\"] + offset[0]\n                    data_qubit_y = anc_qubit[\"face_y\"] + offset[1]\n                    data_qubit_name = f\"{data_qubit_x}-{data_qubit_y}\"\n                    try:\n                        data_qubit = self.tanner_graph.vs.find(name=data_qubit_name)\n                    except ValueError:\n                        continue\n                    anc_qid = anc_qubit.index\n                    data_qid = data_qubit.index\n                    operated_qids.update({anc_qid, data_qid})\n\n                    CX_target = (\n                        [data_qid, anc_qid] if target &lt; 6 else [anc_qid, data_qid]\n                    )\n                    CX_targets.extend(CX_target)\n\n            synd_extr_circuit.append(\"CX\", CX_targets)\n            if self.p_cnot &gt; 0 and not perfect_round:\n                synd_extr_circuit.append(\"DEPOLARIZE2\", CX_targets, self.p_cnot)\n\n            # Apply single-qubit depolarizing noise to each qubit involved in CNOT gates\n            self._apply_depol1_after_cnot(synd_extr_circuit, CX_targets, perfect_round)\n\n            idle_rate = self._get_idle_rate_for_context(\"cnot\")\n            if idle_rate &gt; 0 and not perfect_round:\n                idling_qids = list(self.all_qids_set - operated_qids)\n                synd_extr_circuit.append(\"DEPOLARIZE1\", idling_qids, idle_rate)\n\n            synd_extr_circuit.append(\"TICK\")\n\n        return synd_extr_circuit\n\n    def _build_superdense_syndrome_extraction(\n        self, perfect_round: bool = False\n    ) -&gt; Tuple[stim.Circuit, Dict[int, List[int]]]:\n        \"\"\"Build the superdense syndrome extraction circuit without SPAM operations.\n\n        Implements the 4-step superdense pattern:\n        1. X-type anc \u2192 Z-type anc CNOTs (same face_x)\n        2. Data \u2192 anc CNOTs with spatial routing (x &lt; face_x \u2192 Z-type, x &gt; face_x \u2192 X-type)\n        3. Anc \u2192 data CNOTs (reverse of step 2)\n        4. Repeat step 1\n\n        Parameters\n        ----------\n        perfect_round : bool, default False\n            If True, skip CNOT and idle errors for a perfect syndrome extraction round.\n\n        Returns\n        -------\n        stim.Circuit\n            The superdense syndrome extraction circuit.\n        Dict[int, List[int]]\n            Dictionary mapping Z-type ancilla qids to lists of connected data qids.\n            Used for implementing classical controlled gates after measurements.\n        \"\"\"\n        synd_extr_circuit = stim.Circuit()\n\n        # Track connections between Z-type ancillas and data qubits\n        z_anc_data_connections: Dict[int, List[int]] = {}\n\n        # Step 1: X-type anc \u2192 Z-type anc CNOTs (same face_x)\n        self._add_anc_to_anc_cnots(synd_extr_circuit, perfect_round)\n\n        # Step 2: Data \u2192 anc CNOTs using first half of schedule\n        self._add_data_anc_cnots(\n            synd_extr_circuit,\n            self.cnot_schedule[:6],\n            data_to_anc=True,\n            perfect_round=perfect_round,\n            track_connections=True,\n            connections_dict=z_anc_data_connections,\n        )\n\n        # Step 3: Anc \u2192 data CNOTs using second half of schedule\n        self._add_data_anc_cnots(\n            synd_extr_circuit,\n            self.cnot_schedule[6:],\n            data_to_anc=False,\n            perfect_round=perfect_round,\n            track_connections=True,\n            connections_dict=z_anc_data_connections,\n        )\n\n        # Step 4: Repeat step 1\n        self._add_anc_to_anc_cnots(synd_extr_circuit, perfect_round)\n\n        return synd_extr_circuit, z_anc_data_connections\n\n    def _add_anc_to_anc_cnots(\n        self, circuit: stim.Circuit, perfect_round: bool = False\n    ) -&gt; None:\n        \"\"\"Add X-type anc \u2192 Z-type anc CNOTs for superdense circuit.\"\"\"\n        CX_targets = []\n        operated_qids = set()\n\n        # Group ancilla qubits by both face_x and face_y to find pairs\n        face_groups = {}\n        for anc_Z_qubit in self.anc_Z_qubits:\n            face_key = (anc_Z_qubit[\"face_x\"], anc_Z_qubit[\"face_y\"])\n            if face_key not in face_groups:\n                face_groups[face_key] = {\"Z\": None, \"X\": None}\n            face_groups[face_key][\"Z\"] = anc_Z_qubit\n\n        for anc_X_qubit in self.anc_X_qubits:\n            face_key = (anc_X_qubit[\"face_x\"], anc_X_qubit[\"face_y\"])\n            if face_key not in face_groups:\n                face_groups[face_key] = {\"Z\": None, \"X\": None}\n            face_groups[face_key][\"X\"] = anc_X_qubit\n\n        # Add CNOTs from X-type to Z-type ancillas with same face_x and face_y\n        for face_key, anc_pair in face_groups.items():\n            if anc_pair[\"Z\"] is not None and anc_pair[\"X\"] is not None:\n                anc_X_qid = anc_pair[\"X\"].index\n                anc_Z_qid = anc_pair[\"Z\"].index\n                CX_targets.extend([anc_X_qid, anc_Z_qid])\n                operated_qids.update({anc_X_qid, anc_Z_qid})\n\n        if CX_targets:\n            circuit.append(\"CX\", CX_targets)\n            if self.p_cnot &gt; 0 and not perfect_round:\n                circuit.append(\"DEPOLARIZE2\", CX_targets, self.p_cnot)\n\n            # Apply single-qubit depolarizing noise\n            self._apply_depol1_after_cnot(circuit, CX_targets, perfect_round)\n\n            # Apply idle noise to non-operated qubits\n            idle_rate = self._get_idle_rate_for_context(\"cnot\")\n            if idle_rate &gt; 0 and not perfect_round:\n                idling_qids = list(self.all_qids_set - operated_qids)\n                circuit.append(\"DEPOLARIZE1\", idling_qids, idle_rate)\n\n            circuit.append(\"TICK\")\n\n    def _add_data_anc_cnots(\n        self,\n        circuit: stim.Circuit,\n        schedule_part: List[int],\n        data_to_anc: bool,\n        perfect_round: bool = False,\n        track_connections: bool = False,\n        connections_dict: Optional[Dict[int, List[int]]] = None,\n    ) -&gt; None:\n        \"\"\"Add data \u2194 anc CNOTs for superdense circuit with spatial routing.\n\n        For superdense circuits:\n        - schedule_part contains 6 elements (timeslices for the 6 spatial positions)\n        - All 6 spatial positions are covered in both data\u2192anc and anc\u2192data steps\n        - Ancilla type (Z vs X) is determined solely by spatial routing logic\n\n        Parameters\n        ----------\n        circuit : stim.Circuit\n            Circuit to add CNOT operations to.\n        schedule_part : List[int]\n            Timeslice schedule for CNOT operations.\n        data_to_anc : bool\n            Direction of CNOT (True: data\u2192anc, False: anc\u2192data).\n        perfect_round : bool, default False\n            If True, skip CNOT and idle errors.\n        track_connections : bool, default False\n            If True, record Z-ancilla to data qubit connections.\n        connections_dict : Optional[Dict[int, List[int]]], default None\n            Dictionary to store Z-ancilla to data connections when tracking enabled.\n        \"\"\"\n        for timeslice in range(1, max(schedule_part) + 1):\n            targets = [i for i, val in enumerate(schedule_part) if val == timeslice]\n            operated_qids = set()\n            CX_targets = []\n\n            for target in targets:\n                # target is always in range 0-5 (spatial positions)\n                # Define offset based on target position\n                if target == 0:\n                    offset = (-2, 1)\n                elif target == 1:\n                    offset = (2, 1)\n                elif target == 2:\n                    offset = (4, 0)\n                elif target == 3:\n                    offset = (2, -1)\n                elif target == 4:\n                    offset = (-2, -1)\n                elif target == 5:\n                    offset = (-4, 0)\n                else:\n                    continue  # Invalid target\n\n                # Check Z-type ancillas for spatial routing: x &lt; face_x \u2192 Z-type only\n                for anc_qubit in self.anc_Z_qubits:\n                    data_qubit_x = anc_qubit[\"face_x\"] + offset[0]\n                    data_qubit_y = anc_qubit[\"face_y\"] + offset[1]\n                    data_qubit_name = f\"{data_qubit_x}-{data_qubit_y}\"\n\n                    try:\n                        data_qubit = self.tanner_graph.vs.find(name=data_qubit_name)\n                    except ValueError:\n                        continue\n\n                    # Apply spatial routing: data qubits with x &lt; face_x connect to Z-type anc only\n                    face_x = anc_qubit[\"face_x\"]\n                    if data_qubit_x &lt; face_x:\n                        anc_qid = anc_qubit.index\n                        data_qid = data_qubit.index\n                        operated_qids.update({anc_qid, data_qid})\n\n                        # Track connection for classical controlled gates (superdense circuits)\n                        if track_connections and connections_dict is not None:\n                            if anc_qid not in connections_dict:\n                                connections_dict[anc_qid] = []\n                            if data_qid not in connections_dict[anc_qid]:\n                                connections_dict[anc_qid].append(data_qid)\n\n                        if data_to_anc:\n                            CX_target = [data_qid, anc_qid]\n                        else:\n                            CX_target = [anc_qid, data_qid]\n                        CX_targets.extend(CX_target)\n\n                # Check X-type ancillas for spatial routing: x &gt; face_x \u2192 X-type only\n                for anc_qubit in self.anc_X_qubits:\n                    data_qubit_x = anc_qubit[\"face_x\"] + offset[0]\n                    data_qubit_y = anc_qubit[\"face_y\"] + offset[1]\n                    data_qubit_name = f\"{data_qubit_x}-{data_qubit_y}\"\n\n                    try:\n                        data_qubit = self.tanner_graph.vs.find(name=data_qubit_name)\n                    except ValueError:\n                        continue\n\n                    # Apply spatial routing: data qubits with x &gt; face_x connect to X-type anc only\n                    face_x = anc_qubit[\"face_x\"]\n                    if data_qubit_x &gt; face_x:\n                        anc_qid = anc_qubit.index\n                        data_qid = data_qubit.index\n                        operated_qids.update({anc_qid, data_qid})\n\n                        if data_to_anc:\n                            CX_target = [data_qid, anc_qid]\n                        else:\n                            CX_target = [anc_qid, data_qid]\n                        CX_targets.extend(CX_target)\n\n            if CX_targets:\n                circuit.append(\"CX\", CX_targets)\n                if self.p_cnot &gt; 0 and not perfect_round:\n                    circuit.append(\"DEPOLARIZE2\", CX_targets, self.p_cnot)\n\n                # Apply single-qubit depolarizing noise\n                self._apply_depol1_after_cnot(circuit, CX_targets, perfect_round)\n\n                # Apply idle noise to non-operated qubits\n                idle_rate = self._get_idle_rate_for_context(\"cnot\")\n                if idle_rate &gt; 0 and not perfect_round:\n                    idling_qids = list(self.all_qids_set - operated_qids)\n                    circuit.append(\"DEPOLARIZE1\", idling_qids, idle_rate)\n\n                circuit.append(\"TICK\")\n\n    def _add_detectors(\n        self,\n        circuit: stim.Circuit,\n        first: bool,\n        interface_detectors_info: Optional[Dict],\n        obs_included_lookbacks: Set,\n    ) -&gt; Set:\n        \"\"\"Add Z-type, X-type, and Y-type detectors to the circuit.\"\"\"\n        # Z- and X-type detectors\n        for pauli in [\"Z\", \"X\"]:\n            if self.exclude_non_essential_pauli_detectors:\n                if self.temp_bdry_type in {\"X\", \"Z\"} and pauli != self.temp_bdry_type:\n                    continue\n\n            anc_qubits_now = self.anc_Z_qubits if pauli == \"Z\" else self.anc_X_qubits\n            init_lookback = (\n                -self.num_anc_qubits if pauli == \"Z\" else -self.num_anc_X_qubits\n            )\n\n            for j, anc_qubit in enumerate(anc_qubits_now):\n                pauli_val = 0 if pauli == \"X\" else 2\n                color = anc_qubit[\"color\"]\n                color_val = color_to_color_val(color)\n                coords = get_qubit_coords(anc_qubit)\n                det_coords = coords + (0, pauli_val, color_val)\n\n                if not first:\n                    lookback = init_lookback + j\n                    targets = [\n                        stim.target_rec(lookback),\n                        stim.target_rec(lookback - self.num_anc_qubits),\n                    ]\n                    circuit.append(\"DETECTOR\", targets, det_coords)\n                else:\n                    detector_exists = self._check_detector_exists(coords, color, pauli)\n\n                    if detector_exists:\n                        targets = [stim.target_rec(init_lookback + j)]\n\n                        # Special handling for cult+growing\n                        if (\n                            self.circuit_type == \"cult+growing\"\n                            and coords[1] &gt;= self.y_offset_init_patch\n                        ):\n                            obs_included_lookbacks = self._handle_cultivation_detectors(\n                                circuit,\n                                targets,\n                                det_coords,\n                                coords,\n                                color,\n                                pauli,\n                                anc_qubit,\n                                interface_detectors_info,\n                                obs_included_lookbacks,\n                            )\n                        else:\n                            circuit.append(\"DETECTOR\", targets, det_coords)\n\n        # Y-type detectors\n        self._add_y_type_detectors(circuit, first)\n\n        return obs_included_lookbacks\n\n    def _check_detector_exists(\n        self, coords: Tuple[int, int], color: str, pauli: str\n    ) -&gt; bool:\n        \"\"\"Check if a detector should exist based on circuit type and position.\"\"\"\n        if self.circuit_type in {\"tri\", \"rec\"}:\n            return self.temp_bdry_type == pauli\n        elif self.circuit_type == \"rec_stability\":\n            return color != \"r\"\n        elif self.circuit_type == \"growing\":\n            if coords[1] &gt;= self.y_offset_init_patch:\n                return self.temp_bdry_type == pauli\n            else:\n                return color != \"r\"\n        elif self.circuit_type == \"cult+growing\":\n            return coords[1] &gt;= self.y_offset_init_patch or color != \"r\"\n        else:\n            raise NotImplementedError\n\n    def _handle_cultivation_detectors(\n        self,\n        circuit: stim.Circuit,\n        targets: List,\n        det_coords: Tuple,\n        coords: Tuple[int, int],\n        color: str,\n        pauli: str,\n        anc_qubit: ig.Vertex,\n        interface_detectors_info: Dict,\n        obs_included_lookbacks: Set,\n    ) -&gt; Set:\n        \"\"\"Handle special detector logic for cultivation + growing circuits.\"\"\"\n        det_coords += (-1,)\n        adj_data_qubits = frozenset(\n            qubit.index\n            for qubit in anc_qubit.neighbors()\n            if qubit[\"y\"] &gt;= self.y_offset_init_patch - 1e-6\n        )\n        paulis = [pauli]\n        if pauli == \"X\":\n            paulis.append(\"Z\")\n            det_coords = list(det_coords)\n            det_coords[3] = 1\n            det_coords = tuple(det_coords)\n\n            anc_Z_name = f\"{coords[0] - 2}-{coords[1]}-Z\"\n            anc_Z_qid = self.tanner_graph.vs.find(name=anc_Z_name).index\n            j_Z = self.anc_Z_qids.index(anc_Z_qid)\n            targets.append(stim.target_rec(-self.num_anc_qubits + j_Z))\n\n        targets_cult_all = []\n        lookbacks = []\n        for pauli_now in paulis:\n            key = (pauli_now, adj_data_qubits)\n            targets_cult = interface_detectors_info[key]\n            lookbacks.extend(targets_cult)\n            targets_cult = [\n                stim.target_rec(-self.num_anc_qubits + cult_lookback)\n                for cult_lookback in targets_cult\n            ]\n            targets_cult_all.extend(targets_cult)\n        targets.extend(targets_cult_all)\n\n        if pauli == \"X\" and color == \"g\":\n            obs_included_lookbacks ^= set(lookbacks)\n\n        circuit.append(\"DETECTOR\", targets, det_coords)\n        return obs_included_lookbacks\n\n    def _add_y_type_detectors(self, circuit: stim.Circuit, first: bool) -&gt; None:\n        \"\"\"Add Y-type detectors for Y temporal boundary.\"\"\"\n        if first and self.temp_bdry_type == \"Y\" and self.circuit_type != \"cult+growing\":\n            for j_Z, anc_qubit_Z in enumerate(self.anc_Z_qubits):\n                color = anc_qubit_Z[\"color\"]\n                coords = get_qubit_coords(anc_qubit_Z)\n\n                detector_exists = self._check_y_detector_exists(coords, color)\n\n                if detector_exists:\n                    j_X = self.anc_X_qubits[\"name\"].index(\n                        f\"{anc_qubit_Z['face_x'] + 1}-{anc_qubit_Z['face_y']}-X\"\n                    )\n                    det_coords = coords + (0, 1, color_to_color_val(color))\n                    targets = [\n                        stim.target_rec(-self.num_anc_qubits + j_Z),\n                        stim.target_rec(-self.num_anc_X_qubits + j_X),\n                    ]\n                    circuit.append(\"DETECTOR\", targets, det_coords)\n\n    def _check_y_detector_exists(self, coords: Tuple[int, int], color: str) -&gt; bool:\n        \"\"\"Check if Y-type detector should exist.\"\"\"\n        if self.circuit_type in {\"tri\", \"rec\"}:\n            return True\n        elif self.circuit_type == \"rec_stability\":\n            return color != \"r\"\n        elif self.circuit_type == \"growing\":\n            return coords[1] &gt;= self.y_offset_init_patch\n        else:\n            raise NotImplementedError\n\n    def _add_data_qubit_initialization(\n        self,\n        circuit: stim.Circuit,\n        red_links: Optional[np.ndarray],\n        data_q1s: Optional[np.ndarray],\n        data_q2s: Optional[np.ndarray],\n    ) -&gt; None:\n        \"\"\"Add data qubit initialization based on circuit type.\"\"\"\n        if self.circuit_type in {\"tri\", \"rec\"}:\n            circuit.append(f\"R{self.temp_bdry_type}\", self.data_qids)\n            reset_rate_data = self._get_reset_rate(\"data\")\n            if reset_rate_data &gt; 0 and not self.perfect_logical_initialization:\n                error_type = \"Z_ERROR\" if self.temp_bdry_type == \"X\" else \"X_ERROR\"\n                circuit.append(error_type, self.data_qids, reset_rate_data)\n\n        elif self.circuit_type == \"rec_stability\":\n            circuit.append(\"RX\", data_q1s)\n            circuit.append(\"RZ\", data_q2s)\n            reset_rate_data = self._get_reset_rate(\"data\")\n            if reset_rate_data &gt; 0 and not self.perfect_logical_initialization:\n                circuit.append(\"Z_ERROR\", data_q1s, reset_rate_data)\n                circuit.append(\"X_ERROR\", data_q2s, reset_rate_data)\n            circuit.append(\"TICK\")\n            circuit.append(\"CX\", red_links.ravel())\n            if self.p_cnot &gt; 0:\n                circuit.append(\"DEPOLARIZE2\", red_links.ravel(), self.p_cnot)\n            # Apply single-qubit depolarizing noise to each qubit involved in CNOT gates\n            self._apply_depol1_after_cnot(circuit, red_links.ravel())\n\n        elif self.circuit_type == \"growing\":\n            # Data qubits inside the initial patch\n            data_qids_init_patch = self.data_qubits.select(\n                y_ge=self.y_offset_init_patch\n            )[\"qid\"]\n            circuit.append(f\"R{self.temp_bdry_type}\", data_qids_init_patch)\n            reset_rate_data = self._get_reset_rate(\"data\")\n            if reset_rate_data &gt; 0 and not self.perfect_logical_initialization:\n                error_type = \"Z_ERROR\" if self.temp_bdry_type == \"X\" else \"X_ERROR\"\n                circuit.append(error_type, data_qids_init_patch, reset_rate_data)\n\n            # Data qubits outside the initial patch\n            circuit.append(\"RX\", data_q1s)\n            circuit.append(\"RZ\", data_q2s)\n            if reset_rate_data &gt; 0:\n                circuit.append(\"Z_ERROR\", data_q1s, reset_rate_data)\n                circuit.append(\"X_ERROR\", data_q2s, reset_rate_data)\n            circuit.append(\"TICK\")\n            circuit.append(\"CX\", red_links.ravel())\n            if self.p_cnot &gt; 0:\n                circuit.append(\"DEPOLARIZE2\", red_links.ravel(), self.p_cnot)\n            # Apply single-qubit depolarizing noise to each qubit involved in CNOT gates\n            self._apply_depol1_after_cnot(circuit, red_links.ravel())\n\n        elif self.circuit_type == \"cult+growing\":\n            # Find last tick position\n            for i in range(len(circuit) - 1, -1, -1):\n                instruction = circuit[i]\n                if (\n                    isinstance(instruction, stim.CircuitInstruction)\n                    and instruction.name == \"TICK\"\n                ):\n                    last_tick_pos = i\n                    break\n\n            # Data qubits outside the initial patch (inserted before the last tick)\n            circuit.insert(last_tick_pos, stim.CircuitInstruction(\"RX\", data_q1s))\n            circuit.insert(last_tick_pos + 1, stim.CircuitInstruction(\"RZ\", data_q2s))\n            reset_rate_data = self._get_reset_rate(\"data\")\n            if reset_rate_data &gt; 0:\n                circuit.insert(\n                    last_tick_pos + 2,\n                    stim.CircuitInstruction(\"Z_ERROR\", data_q1s, [reset_rate_data]),\n                )\n                circuit.insert(\n                    last_tick_pos + 3,\n                    stim.CircuitInstruction(\"X_ERROR\", data_q2s, [reset_rate_data]),\n                )\n\n            # CX gate (inserted after the last tick)\n            circuit.append(\"CX\", red_links.ravel())\n            if self.p_cnot &gt; 0:\n                circuit.append(\"DEPOLARIZE2\", red_links.ravel(), self.p_cnot)\n            # Apply single-qubit depolarizing noise to each qubit involved in CNOT gates\n            self._apply_depol1_after_cnot(circuit, red_links.ravel())\n\n        else:\n            raise NotImplementedError\n\n    def _add_ancilla_initialization(self, circuit: stim.Circuit) -&gt; None:\n        \"\"\"Add ancilla qubit initialization.\"\"\"\n        circuit.append(\"RZ\", self.anc_Z_qids)\n        circuit.append(\"RX\", self.anc_X_qids)\n\n        if not self.perfect_logical_initialization:\n            reset_rate_anc_Z = self._get_reset_rate(\"anc_Z\")\n            reset_rate_anc_X = self._get_reset_rate(\"anc_X\")\n            if reset_rate_anc_Z &gt; 0:\n                circuit.append(\"X_ERROR\", self.anc_Z_qids, reset_rate_anc_Z)\n            if reset_rate_anc_X &gt; 0:\n                circuit.append(\"Z_ERROR\", self.anc_X_qids, reset_rate_anc_X)\n\n        circuit.append(\"TICK\")\n\n    def _add_final_measurements_and_detectors(\n        self,\n        circuit: stim.Circuit,\n        red_links: Optional[np.ndarray],\n        data_q1s: Optional[np.ndarray],\n        data_q2s: Optional[np.ndarray],\n    ) -&gt; None:\n        \"\"\"Add final data qubit measurements and last detectors.\"\"\"\n        use_last_detectors = True\n        p_meas_final = (\n            0 if self.perfect_logical_measurement else self._get_meas_rate(\"data\")\n        )\n\n        if self.circuit_type in {\"tri\", \"rec\", \"growing\", \"cult+growing\"}:\n            circuit.append(f\"M{self.temp_bdry_type}\", self.data_qids, p_meas_final)\n            if use_last_detectors:\n                self._add_last_detectors(circuit)\n\n        elif self.circuit_type == \"rec_stability\":\n            if not use_last_detectors:\n                raise NotImplementedError\n            self._add_stability_final_measurements(\n                circuit, red_links, data_q1s, data_q2s, p_meas_final\n            )\n\n        else:\n            raise NotImplementedError\n\n    def _add_last_detectors(self, circuit: stim.Circuit) -&gt; None:\n        \"\"\"Add last detectors for tri/rec/growing/cult+growing circuits.\"\"\"\n        if self.temp_bdry_type == \"X\":\n            anc_qubits_now = self.anc_X_qubits\n            init_lookback = -self.num_data_qubits - self.num_anc_X_qubits\n            pauli_val = 0\n        else:\n            anc_qubits_now = self.anc_Z_qubits\n            init_lookback = -self.num_data_qubits - self.num_anc_qubits\n            pauli_val = 2 if self.temp_bdry_type == \"Z\" else 1\n\n        for j_anc, anc_qubit in enumerate(anc_qubits_now):\n            ngh_data_qubits = anc_qubit.neighbors()\n            lookback_inds = [\n                -self.num_data_qubits + self.data_qids.index(q.index)\n                for q in ngh_data_qubits\n            ]\n            lookback_inds.append(init_lookback + j_anc)\n            if self.temp_bdry_type == \"Y\":\n                anc_X_qubit = self.tanner_graph.vs.find(\n                    name=f\"{anc_qubit['face_x'] + 1}-{anc_qubit['face_y']}-X\"\n                )\n                j_anc_X = self.anc_X_qids.index(anc_X_qubit.index)\n                lookback_inds.append(\n                    -self.num_data_qubits - self.num_anc_X_qubits + j_anc_X\n                )\n\n            target = [stim.target_rec(ind) for ind in lookback_inds]\n            color_val = color_to_color_val(anc_qubit[\"color\"])\n            coords = get_qubit_coords(anc_qubit) + (0, pauli_val, color_val)\n            circuit.append(\"DETECTOR\", target, coords)\n\n    def _add_stability_final_measurements(\n        self,\n        circuit: stim.Circuit,\n        red_links: np.ndarray,\n        data_q1s: np.ndarray,\n        data_q2s: np.ndarray,\n        p_meas_final: float,\n    ) -&gt; None:\n        \"\"\"Add final measurements for rec_stability circuits.\"\"\"\n        circuit.append(\"CX\", red_links.ravel())\n        if self.p_cnot &gt; 0 and not self.perfect_logical_measurement:\n            circuit.append(\"DEPOLARIZE2\", red_links.ravel(), self.p_cnot)\n        # Apply single-qubit depolarizing noise to each qubit involved in CNOT gates\n        # Use perfect_logical_measurement flag to determine if noise should be skipped\n        self._apply_depol1_after_cnot(\n            circuit, red_links.ravel(), self.perfect_logical_measurement\n        )\n\n        circuit.append(\"TICK\")\n\n        # ZZ measurement outcomes\n        circuit.append(\"MZ\", data_q2s, p_meas_final)\n\n        # Apply idle noise to ancilla qubits during data qubit measurements\n        if not self.perfect_logical_measurement:\n            idle_rate_meas = self._get_idle_rate_for_context(\"meas\")\n            if idle_rate_meas &gt; 0:\n                circuit.append(\"DEPOLARIZE1\", self.anc_qids, idle_rate_meas)\n\n        num_data_q2s = data_q2s.size\n        lookback_inds_anc = {}\n        for j, data_q2 in enumerate(data_q2s):\n            for anc_Z_qubit in self.tanner_graph.vs[data_q2].neighbors():\n                if anc_Z_qubit[\"pauli\"] == \"Z\" and anc_Z_qubit[\"color\"] != \"r\":\n                    anc_Z_qid = anc_Z_qubit.index\n                    lookback_ind = j - num_data_q2s\n                    try:\n                        lookback_inds_anc[anc_Z_qid].append(lookback_ind)\n                    except KeyError:\n                        lookback_inds_anc[anc_Z_qid] = [lookback_ind]\n\n        obs_Z_lookback_inds = []\n        for j_anc_Z, anc_Z_qubit in enumerate(self.anc_Z_qubits):\n            check_meas_lookback_ind = j_anc_Z - num_data_q2s - self.num_anc_qubits\n            if anc_Z_qubit[\"color\"] != \"g\":\n                obs_Z_lookback_inds.append(check_meas_lookback_ind)\n            try:\n                lookback_inds = lookback_inds_anc[anc_Z_qubit.index]\n            except KeyError:\n                continue\n            lookback_inds.append(check_meas_lookback_ind)\n            target = [stim.target_rec(ind) for ind in lookback_inds]\n            color_val = color_to_color_val(anc_Z_qubit[\"color\"])\n            coords = get_qubit_coords(anc_Z_qubit) + (0, 2, color_val)\n            circuit.append(\"DETECTOR\", target, coords)\n\n        target = [stim.target_rec(ind) for ind in obs_Z_lookback_inds]\n        circuit.append(\"OBSERVABLE_INCLUDE\", target, 0)\n        if self.comparative_decoding:\n            raise NotImplementedError\n\n        # XX measurement outcomes\n        circuit.append(\"MX\", data_q1s, p_meas_final)\n\n        # Apply idle noise to ancilla qubits during data qubit measurements\n        if not self.perfect_logical_measurement:\n            idle_rate_meas = self._get_idle_rate_for_context(\"meas\")\n            if idle_rate_meas &gt; 0:\n                circuit.append(\"DEPOLARIZE1\", self.anc_qids, idle_rate_meas)\n\n        num_data_q1s = data_q1s.size\n        lookback_inds_anc = {}\n        for j, data_q1 in enumerate(data_q1s):\n            for anc_X_qubit in self.tanner_graph.vs[data_q1].neighbors():\n                if anc_X_qubit[\"pauli\"] == \"X\" and anc_X_qubit[\"color\"] != \"r\":\n                    anc_X_qid = anc_X_qubit.index\n                    lookback_ind = j - num_data_q1s\n                    try:\n                        lookback_inds_anc[anc_X_qid].append(lookback_ind)\n                    except KeyError:\n                        lookback_inds_anc[anc_X_qid] = [lookback_ind]\n\n        obs_X_lookback_inds = []\n        for j_anc_X, anc_X_qubit in enumerate(self.anc_X_qubits):\n            check_meas_lookback_ind = (\n                j_anc_X - num_data_q1s - num_data_q2s - self.num_anc_X_qubits\n            )\n            color = anc_X_qubit[\"color\"]\n            if color != \"g\":\n                obs_X_lookback_inds.append(check_meas_lookback_ind)\n\n            try:\n                lookback_inds = lookback_inds_anc[anc_X_qubit.index]\n            except KeyError:\n                continue\n\n            lookback_inds.append(check_meas_lookback_ind)\n            target = [stim.target_rec(ind) for ind in lookback_inds]\n            color_val = color_to_color_val(color)\n            coords = get_qubit_coords(anc_X_qubit) + (0, 0, color_val)\n            circuit.append(\"DETECTOR\", target, coords)\n\n        target = [stim.target_rec(ind) for ind in obs_X_lookback_inds]\n        circuit.append(\"OBSERVABLE_INCLUDE\", target, 1)\n        if self.comparative_decoding:\n            raise NotImplementedError\n\n    def _apply_depol1_after_cnot(\n        self, circuit: stim.Circuit, CX_targets: list, perfect_round: bool = False\n    ) -&gt; None:\n        \"\"\"\n        Apply single-qubit depolarizing noise to each qubit involved in CNOT gates.\n\n        Parameters\n        ----------\n        circuit : stim.Circuit\n            Circuit to add noise to.\n        CX_targets : list\n            List of CNOT targets in the format [control, target, control2, target2, ...].\n        perfect_round : bool, default False\n            If True, skip noise application for perfect syndrome extraction rounds.\n        \"\"\"\n        if self.p_depol1_after_cnot == 0 or perfect_round:\n            return\n\n        # Extract unique qubits from CX_targets\n        # CX_targets format: [control1, target1, control2, target2, ...]\n        unique_qubits = list(set(CX_targets))\n\n        if unique_qubits:\n            circuit.append(\"DEPOLARIZE1\", unique_qubits, self.p_depol1_after_cnot)\n\n    def _get_reset_rate(self, qubit_type: str) -&gt; float:\n        \"\"\"\n        Get the appropriate reset noise rate for a given qubit type.\n\n        Parameters\n        ----------\n        qubit_type : str\n            Type of qubit for which to get reset rate. Must be one of:\n            - \"data\": Data qubits\n            - \"anc_X\": X-type ancilla qubits\n            - \"anc_Z\": Z-type ancilla qubits\n\n        Returns\n        -------\n        float\n            Appropriate reset noise rate based on qubit type and parameter overrides.\n            Falls back to base reset rate if no specific rate is set.\n        \"\"\"\n        if qubit_type == \"data\":\n            return self.p_reset_data\n        elif qubit_type == \"anc_X\":\n            return self.p_reset_anc_X\n        elif qubit_type == \"anc_Z\":\n            return self.p_reset_anc_Z\n        else:\n            raise ValueError(\n                f\"Invalid qubit_type '{qubit_type}'. Must be 'data', 'anc_X', or 'anc_Z'.\"\n            )\n\n    def _get_meas_rate(self, qubit_type: str) -&gt; float:\n        \"\"\"\n        Get the appropriate measurement noise rate for a given qubit type.\n\n        Parameters\n        ----------\n        qubit_type : str\n            Type of qubit for which to get measurement rate. Must be one of:\n            - \"data\": Data qubits\n            - \"anc_X\": X-type ancilla qubits\n            - \"anc_Z\": Z-type ancilla qubits\n\n        Returns\n        -------\n        float\n            Appropriate measurement noise rate based on qubit type and parameter overrides.\n            Falls back to base measurement rate if no specific rate is set.\n        \"\"\"\n        if qubit_type == \"data\":\n            return self.p_meas_data\n        elif qubit_type == \"anc_X\":\n            return self.p_meas_anc_X\n        elif qubit_type == \"anc_Z\":\n            return self.p_meas_anc_Z\n        else:\n            raise ValueError(\n                f\"Invalid qubit_type '{qubit_type}'. Must be 'data', 'anc_X', or 'anc_Z'.\"\n            )\n\n    def _get_idle_rate_for_context(self, context: str) -&gt; float:\n        \"\"\"\n        Get the appropriate idle noise rate for a given context.\n\n        Parameters\n        ----------\n        context : str\n            Context for which to get idle rate. Must be one of:\n            - \"cnot\": During CNOT operations\n            - \"meas\": During measurement operations\n            - \"general\": General idle periods (mixed CNOT and measurement)\n\n        Returns\n        -------\n        float\n            Appropriate idle noise rate based on context and parameter overrides.\n            For general context, uses maximum between idle_during_cnot and idle_during_meas\n            if both are specified, otherwise falls back to individual overrides or base idle.\n        \"\"\"\n        if context == \"cnot\" and self.p_idle_during_cnot is not None:\n            return self.p_idle_during_cnot\n        elif context == \"meas\" and self.p_idle_during_meas is not None:\n            return self.p_idle_during_meas\n        elif context == \"general\":\n            # For general idle periods (mixed operations), use maximum of context-specific rates\n            rates_to_consider = []\n\n            if self.p_idle_during_cnot is not None:\n                rates_to_consider.append(self.p_idle_during_cnot)\n            if self.p_idle_during_meas is not None:\n                rates_to_consider.append(self.p_idle_during_meas)\n\n            if rates_to_consider:\n                # Use maximum of specified context-specific rates\n                return max(rates_to_consider)\n            else:\n                # Fall back to base idle rate if no context-specific rates specified\n                return self.p_idle\n        else:\n            return self.p_idle\n\n    def _add_logical_observables(\n        self, circuit: stim.Circuit, obs_included_lookbacks: Set\n    ) -&gt; None:\n        \"\"\"Add logical observables based on circuit type.\"\"\"\n        if self.circuit_type not in {\"tri\", \"rec\", \"growing\", \"cult+growing\"}:\n            return\n\n        if self.circuit_type in {\"tri\", \"growing\", \"cult+growing\"}:\n            qubits_logs = [self.tanner_graph.vs.select(obs=True)]\n            if self.circuit_type == \"tri\":\n                bdry_colors = [0]\n            elif self.circuit_type == \"growing\":\n                bdry_colors = [1]\n            elif self.circuit_type == \"cult+growing\":\n                bdry_colors = [1]\n        elif self.circuit_type == \"rec\":\n            qubits_log_r = self.tanner_graph.vs.select(obs_r=True)\n            qubits_log_g = self.tanner_graph.vs.select(obs_g=True)\n            qubits_logs = [qubits_log_r, qubits_log_g]\n            bdry_colors = [1, 0]\n\n        for obs_id, qubits_log in enumerate(qubits_logs):\n            lookback_inds = [\n                -self.num_data_qubits + self.data_qids.index(q.index)\n                for q in qubits_log\n            ]\n            if obs_included_lookbacks:\n                num_meas_after_cult = (\n                    self.num_anc_qubits * self.rounds + self.num_data_qubits\n                )\n                lookback_inds.extend(\n                    lb - num_meas_after_cult for lb in obs_included_lookbacks\n                )\n\n            target = [stim.target_rec(ind) for ind in lookback_inds]\n            circuit.append(\"OBSERVABLE_INCLUDE\", target, obs_id)\n            if self.comparative_decoding:\n                color_val = bdry_colors[obs_id]\n                if self.temp_bdry_type == \"X\":\n                    pauli_val = 0\n                elif self.temp_bdry_type == \"Y\":\n                    pauli_val = 1\n                elif self.temp_bdry_type == \"Z\":\n                    pauli_val = 2\n                else:\n                    raise ValueError(f\"Invalid temp_bdry_type: {self.temp_bdry_type}\")\n                coords = (-1, -1, -1, pauli_val, color_val, obs_id)\n                circuit.append(\"DETECTOR\", target, coords)\n</code></pre>"},{"location":"api/circuit_builder/#color_code_stim.CircuitBuilder.__init__","title":"<code>__init__(d, d2, rounds, circuit_type, cnot_schedule, superdense_circuit, temp_bdry_type, noise_model, perfect_init_final, perfect_logical_initialization, perfect_logical_measurement, perfect_first_syndrome_extraction, tanner_graph, qubit_groups, exclude_non_essential_pauli_detectors=False, cultivation_circuit=None, comparative_decoding=False)</code>","text":"<p>Initialize the circuit builder.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>int</code> <p>Code distance.</p> required <code>d2</code> <code>Optional[int]</code> <p>Second code distance (required for some circuit types).</p> required <code>rounds</code> <code>int</code> <p>Number of syndrome extraction rounds.</p> required <code>circuit_type</code> <code>CIRCUIT_TYPE</code> <p>Type of circuit to build.</p> required <code>cnot_schedule</code> <code>List[int]</code> <p>CNOT gate schedule.</p> required <code>superdense_circuit</code> <code>bool</code> <p>Whether to use superdense syndrome extraction circuit.</p> required <code>temp_bdry_type</code> <code>str</code> <p>Temporal boundary type.</p> required <code>noise_model</code> <code>NoiseModel or Dict[str, float]</code> <p>Noise model specifying error rates for different operations.</p> required <code>perfect_init_final</code> <code>bool</code> <p>Whether to use perfect initialization and final measurement (backward compatibility).</p> required <code>perfect_logical_initialization</code> <code>bool</code> <p>Whether logical initialization operations (data qubit reset) are noiseless.</p> required <code>perfect_logical_measurement</code> <code>bool</code> <p>Whether logical final measurement operations are noiseless.</p> required <code>perfect_first_syndrome_extraction</code> <code>bool</code> <p>Whether the first syndrome extraction round is noiseless.</p> required <code>tanner_graph</code> <code>Graph</code> <p>The Tanner graph representing the color code.</p> required <code>qubit_groups</code> <code>Dict[str, VertexSeq]</code> <p>Grouped qubits by type (data, anc, anc_Z, anc_X).</p> required <code>exclude_non_essential_pauli_detectors</code> <code>bool</code> <p>Whether to exclude non-essential Pauli detectors.</p> <code>False</code> <code>cultivation_circuit</code> <code>Optional[Circuit]</code> <p>Cultivation circuit for cult+growing.</p> <code>None</code> <code>comparative_decoding</code> <code>bool</code> <p>Whether to use comparative decoding.</p> <code>False</code> Source code in <code>src/color_code_stim/circuit_builder.py</code> <pre><code>def __init__(\n    self,\n    d: int,\n    d2: Optional[int],\n    rounds: int,\n    circuit_type: CIRCUIT_TYPE,\n    cnot_schedule: List[int],\n    superdense_circuit: bool,\n    temp_bdry_type: str,\n    noise_model: Union[NoiseModel, Dict[str, float]],\n    perfect_init_final: bool,\n    perfect_logical_initialization: bool,\n    perfect_logical_measurement: bool,\n    perfect_first_syndrome_extraction: bool,\n    tanner_graph: ig.Graph,\n    qubit_groups: Dict[str, ig.VertexSeq],\n    exclude_non_essential_pauli_detectors: bool = False,\n    cultivation_circuit: Optional[stim.Circuit] = None,\n    comparative_decoding: bool = False,\n):\n    \"\"\"\n    Initialize the circuit builder.\n\n    Parameters\n    ----------\n    d : int\n        Code distance.\n    d2 : Optional[int]\n        Second code distance (required for some circuit types).\n    rounds : int\n        Number of syndrome extraction rounds.\n    circuit_type : CIRCUIT_TYPE\n        Type of circuit to build.\n    cnot_schedule : List[int]\n        CNOT gate schedule.\n    superdense_circuit : bool\n        Whether to use superdense syndrome extraction circuit.\n    temp_bdry_type : str\n        Temporal boundary type.\n    noise_model : NoiseModel or Dict[str, float]\n        Noise model specifying error rates for different operations.\n    perfect_init_final : bool\n        Whether to use perfect initialization and final measurement (backward compatibility).\n    perfect_logical_initialization : bool\n        Whether logical initialization operations (data qubit reset) are noiseless.\n    perfect_logical_measurement : bool\n        Whether logical final measurement operations are noiseless.\n    perfect_first_syndrome_extraction : bool\n        Whether the first syndrome extraction round is noiseless.\n    tanner_graph : ig.Graph\n        The Tanner graph representing the color code.\n    qubit_groups : Dict[str, ig.VertexSeq]\n        Grouped qubits by type (data, anc, anc_Z, anc_X).\n    exclude_non_essential_pauli_detectors : bool, default False\n        Whether to exclude non-essential Pauli detectors.\n    cultivation_circuit : Optional[stim.Circuit], default None\n        Cultivation circuit for cult+growing.\n    comparative_decoding : bool, default False\n        Whether to use comparative decoding.\n    \"\"\"\n    self.d = d\n    self.d2 = d2\n    self.rounds = rounds\n    self.circuit_type = circuit_type\n    self.cnot_schedule = cnot_schedule\n    self.superdense_circuit = superdense_circuit\n    self.temp_bdry_type = temp_bdry_type\n    self.noise_model = noise_model\n    self.perfect_init_final = perfect_init_final\n    self.perfect_logical_initialization = perfect_logical_initialization\n    self.perfect_logical_measurement = perfect_logical_measurement\n    self.perfect_first_syndrome_extraction = perfect_first_syndrome_extraction\n    self.tanner_graph = tanner_graph\n    self.qubit_groups = qubit_groups\n    self.exclude_non_essential_pauli_detectors = (\n        exclude_non_essential_pauli_detectors\n    )\n    self.cultivation_circuit = cultivation_circuit\n    self.comparative_decoding = comparative_decoding\n\n    # Validate parameters\n    self.validate()\n\n    # Extract physical error rates\n    self.p_bitflip = noise_model[\"bitflip\"]\n    self.p_depol = noise_model[\"depol\"]\n    self.p_reset = noise_model[\"reset\"]\n    self.p_meas = noise_model[\"meas\"]\n    self.p_cnot = noise_model[\"cnot\"]\n    self.p_idle = noise_model[\"idle\"]\n    self.p_initial_data_qubit_depol = noise_model[\"initial_data_qubit_depol\"]\n    self.p_depol1_after_cnot = noise_model[\"depol1_after_cnot\"]\n    self.p_idle_during_cnot = noise_model[\"idle_during_cnot\"]\n    self.p_idle_during_meas = noise_model[\"idle_during_meas\"]\n\n    # Extract granular reset/measurement rates\n    self.p_reset_data = noise_model[\"reset_data\"]\n    self.p_reset_anc_X = noise_model[\"reset_anc_X\"]\n    self.p_reset_anc_Z = noise_model[\"reset_anc_Z\"]\n    self.p_meas_data = noise_model[\"meas_data\"]\n    self.p_meas_anc_X = noise_model[\"meas_anc_X\"]\n    self.p_meas_anc_Z = noise_model[\"meas_anc_Z\"]\n\n    # Extract qubit groups\n    self.data_qubits = qubit_groups[\"data\"]\n    self.anc_qubits = qubit_groups[\"anc\"]\n    self.anc_Z_qubits = qubit_groups[\"anc_Z\"]\n    self.anc_X_qubits = qubit_groups[\"anc_X\"]\n\n    # Extract qubit IDs\n    self.data_qids = self.data_qubits[\"qid\"]\n    self.anc_qids = self.anc_qubits[\"qid\"]\n    self.anc_Z_qids = self.anc_Z_qubits[\"qid\"]\n    self.anc_X_qids = self.anc_X_qubits[\"qid\"]\n\n    # Calculate counts\n    self.num_data_qubits = len(self.data_qids)\n    self.num_anc_Z_qubits = len(self.anc_Z_qubits)\n    self.num_anc_X_qubits = len(self.anc_X_qubits)\n    self.num_anc_qubits = self.num_anc_X_qubits + self.num_anc_Z_qubits\n\n    self.num_qubits = tanner_graph.vcount()\n    self.all_qids = list(range(self.num_qubits))\n    self.all_qids_set = set(self.all_qids)\n</code></pre>"},{"location":"api/circuit_builder/#color_code_stim.CircuitBuilder.build","title":"<code>build()</code>","text":"<p>Build the complete quantum circuit.</p> <p>Returns:</p> Type Description <code>Circuit</code> <p>The constructed quantum circuit.</p> Source code in <code>src/color_code_stim/circuit_builder.py</code> <pre><code>def build(self) -&gt; stim.Circuit:\n    \"\"\"\n    Build the complete quantum circuit.\n\n    Returns\n    -------\n    stim.Circuit\n        The constructed quantum circuit.\n    \"\"\"\n    # Identify red linkes (only for 'rec_stability', 'growing', and 'cult+growing')\n    red_links, data_q1s, data_q2s = self._identify_red_links()\n\n    # Initialize main circuit with qubit coordinates\n    circuit = self._initialize_circuit_with_coordinates()\n\n    # Add cultivation circuit if needed\n    interface_detectors_info = self._add_cultivation_circuit(circuit)\n\n    # Build syndrome extraction circuits\n    synd_extr_circuits, obs_included_lookbacks = (\n        self._build_syndrome_extraction_circuits(interface_detectors_info)\n    )\n\n    # Add data qubit initialization\n    self._add_data_qubit_initialization(circuit, red_links, data_q1s, data_q2s)\n\n    # Add initial data qubit depolarizing noise if perfect_first_syndrome_extraction=False\n    if not self.perfect_first_syndrome_extraction:\n        self._add_initial_data_qubit_depol(circuit)\n\n    # Add ancilla qubit initialization\n    self._add_ancilla_initialization(circuit)\n\n    # Add main syndrome extraction rounds\n    circuit += synd_extr_circuits[0]\n\n    # Add initial data qubit depolarizing noise if perfect_first_syndrome_extraction=True\n    if self.perfect_first_syndrome_extraction:\n        self._add_initial_data_qubit_depol(circuit)\n\n    circuit += synd_extr_circuits[1] * (self.rounds - 1)\n\n    # Add final measurements and detectors\n    self._add_final_measurements_and_detectors(\n        circuit, red_links, data_q1s, data_q2s\n    )\n\n    # Add logical observables\n    self._add_logical_observables(circuit, obs_included_lookbacks)\n\n    return circuit\n</code></pre>"},{"location":"api/circuit_builder/#color_code_stim.CircuitBuilder.validate","title":"<code>validate()</code>","text":"<p>Validate parameter compatibility with circuit type.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If parameters are incompatible with the specified circuit_type.</p> Source code in <code>src/color_code_stim/circuit_builder.py</code> <pre><code>def validate(self) -&gt; None:\n    \"\"\"\n    Validate parameter compatibility with circuit type.\n\n    Raises\n    ------\n    ValueError\n        If parameters are incompatible with the specified circuit_type.\n    \"\"\"\n    # Validate rounds\n    if self.rounds &lt; 1:\n        raise ValueError(f\"rounds must be &gt;= 1. Got rounds={self.rounds}\")\n\n    # Validate circuit_type\n    supported_types = set(get_args(CIRCUIT_TYPE))\n    if self.circuit_type not in supported_types:\n        raise ValueError(\n            f\"circuit_type must be one of {supported_types}. Got circuit_type='{self.circuit_type}'\"\n        )\n\n    # Validate cnot_schedule\n    if len(self.cnot_schedule) != 12:\n        raise ValueError(\n            f\"cnot_schedule must have 12 integers. Got {len(self.cnot_schedule)} elements\"\n        )\n    if not all(isinstance(x, int) for x in self.cnot_schedule):\n        raise ValueError(\n            f\"cnot_schedule must contain only integers. Got {self.cnot_schedule}\"\n        )\n\n    # Validate temp_bdry_type based on circuit_type\n    if self.circuit_type in {\"tri\", \"rec\", \"growing\"}:\n        if self.temp_bdry_type not in {\"X\", \"Y\", \"Z\"}:\n            raise ValueError(\n                f\"'{self.circuit_type}' circuit requires temp_bdry_type in {{'X', 'Y', 'Z'}}. Got temp_bdry_type='{self.temp_bdry_type}'\"\n            )\n    elif self.circuit_type == \"cult+growing\":\n        if self.temp_bdry_type != \"Y\":\n            raise ValueError(\n                f\"'cult+growing' circuit requires temp_bdry_type='Y'. Got temp_bdry_type='{self.temp_bdry_type}'\"\n            )\n    elif self.circuit_type == \"rec_stability\":\n        if self.temp_bdry_type != \"r\":\n            raise ValueError(\n                f\"'rec_stability' circuit requires temp_bdry_type='r'. Got temp_bdry_type='{self.temp_bdry_type}'\"\n            )\n\n    # Validate d and d2 constraints\n    if self.circuit_type == \"tri\":\n        if self.d &lt; 3 or self.d % 2 == 0:\n            raise ValueError(f\"'tri' circuit requires d: odd &gt;= 3. Got d={self.d}\")\n\n    elif self.circuit_type == \"rec\":\n        if (\n            self.d &lt; 2\n            or self.d % 2 != 0\n            or self.d2 is None\n            or self.d2 &lt; 2\n            or self.d2 % 2 != 0\n        ):\n            raise ValueError(\n                f\"'rec' circuit requires d, d2: even &gt;= 2. Got d={self.d}, d2={self.d2}\"\n            )\n\n    elif self.circuit_type == \"rec_stability\":\n        if (\n            self.d &lt; 4\n            or self.d % 2 != 0\n            or self.d2 is None\n            or self.d2 &lt; 4\n            or self.d2 % 2 != 0\n        ):\n            raise ValueError(\n                f\"'rec_stability' circuit requires d, d2: even &gt;= 4. Got d={self.d}, d2={self.d2}\"\n            )\n\n    elif self.circuit_type == \"growing\":\n        if (\n            self.d &lt; 3\n            or self.d % 2 == 0\n            or self.d2 is None\n            or self.d2 % 2 == 0\n            or self.d2 &lt;= self.d\n        ):\n            raise ValueError(\n                f\"'growing' circuit requires d, d2: odd, d2 &gt; d &gt;= 3. Got d={self.d}, d2={self.d2}\"\n            )\n\n    elif self.circuit_type == \"cult+growing\":\n        if (\n            self.d not in {3, 5}\n            or self.d2 is None\n            or self.d2 % 2 == 0\n            or self.d2 &lt;= self.d\n        ):\n            raise ValueError(\n                f\"'cult+growing' circuit requires d in {{3, 5}}, d2: odd, d2 &gt; d. Got d={self.d}, d2={self.d2}\"\n            )\n</code></pre>"},{"location":"api/color_code/","title":"ColorCode","text":"Source code in <code>src/color_code_stim/color_code.py</code> <pre><code>class ColorCode:\n    tanner_graph: ig.Graph\n    circuit: stim.Circuit\n    d: int\n    d2: Optional[int]\n    rounds: int\n    circuit_type: str\n    temp_bdry_type: Literal[\"X\", \"Y\", \"Z\", \"r\", \"g\", \"b\"]\n    cnot_schedule: List[int]\n    num_obs: int\n    qubit_groups: Dict[str, ig.VertexSeq]\n    obs_paulis: List[PAULI_LABEL]\n    dem_xz: stim.DetectorErrorModel\n    H: csc_matrix\n    probs_xz: np.ndarray\n    obs_matrix: csc_matrix\n    detector_ids_by_color: Dict[COLOR_LABEL, List[int]]\n    detectors_checks_map: List[Tuple[ig.Vertex, int]]\n    cult_detector_ids: List[int]\n    interface_detector_ids: List[int]\n    dems_decomposed: Dict[COLOR_LABEL, DemDecomp]\n    perfect_init_final: bool\n    noise_model: Dict[\n        Literal[\"bitflip\", \"reset\", \"meas\", \"cnot\", \"idle\", \"cult\"], float\n    ]\n    comparative_decoding: bool\n    exclude_non_essential_pauli_detectors: bool\n    cultivation_circuit: Optional[stim.Circuit]\n    remove_non_edge_like_errors: bool\n    _benchmarking: bool\n    _bp_inputs: Dict[str, Any]\n    _dem_manager: Optional[DemManager]\n    _concat_matching_decoder: Optional[ConcatMatchingDecoder]\n    _bp_decoder: Optional[BPDecoder]\n    _belief_concat_matching_decoder: Optional[BeliefConcatMatchingDecoder]\n    _simulator: Optional[Simulator]\n\n    def __init__(\n        self,\n        *,\n        d: int,\n        rounds: int,\n        circuit_type: str = \"tri\",\n        d2: int = None,\n        cnot_schedule: Union[str, List[int]] = \"tri_optimal\",\n        superdense_circuit: bool = False,\n        temp_bdry_type: Optional[Literal[\"X\", \"Y\", \"Z\", \"x\", \"y\", \"z\"]] = None,\n        noise_model: Optional[NoiseModel] = None,\n        perfect_logical_initialization: bool = False,\n        perfect_logical_measurement: bool = False,\n        perfect_init_final: bool = False,\n        perfect_first_syndrome_extraction: bool = False,\n        comparative_decoding: bool = False,\n        exclude_non_essential_pauli_detectors: bool = False,\n        cultivation_circuit: Optional[stim.Circuit] = None,\n        remove_non_edge_like_errors: bool = True,\n        shape: str = None,\n        p_bitflip: float = 0.0,\n        p_depol: float = 0.0,\n        p_reset: float = 0.0,\n        p_meas: float = 0.0,\n        p_cnot: float = 0.0,\n        p_idle: float = 0.0,\n        p_circuit: Optional[float] = None,\n        p_cult: Optional[float] = None,\n        _generate_dem: bool = True,\n        _decompose_dem: bool = True,\n        _benchmarking: bool = False,\n    ):\n        \"\"\"\n        Class for constructing a color code circuit and simulating the\n        concatenated MWPM decoder.\n\n        Examples\n        --------\n        Triangular patch with uniform circuit-level noise of 1e-3:\n\n        &gt;&gt;&gt; from color_code_stim import ColorCode, NoiseModel\n        &gt;&gt;&gt; noise = NoiseModel.uniform_circuit_noise(1e-3)\n        &gt;&gt;&gt; colorcode = ColorCode(d=5, rounds=5, circuit_type=\"tri\", noise_model=noise)\n        &gt;&gt;&gt; num_fails, info = colorcode.simulate(shots=10000, full_output=True)\n\n        See `getting_started.ipynb` for more detailed usage.\n\n        Parameters\n        ----------\n        d : int &gt;= 3\n            Code distance.\n\n        rounds : int &gt;= 1\n            Number of syndrome extraction rounds.\n\n        circuit_type : {'triangle', 'tri', 'rectangle', 'rec', 'rec_stability', 'growing', 'cult+growing'}, default 'tri'\n            Circuit type.\n\n            - 'triangle'/'tri': memory experiment of a triangular patch with distance\n              `d`.\n\n            - 'rectangle'/'rec': memory experiment of a rectangular patch with distance\n              `d` and `d2`.\n\n            - 'rec_stability': stability experiment of a rectangle-like patch with\n              single-type boundaries. `d` and `d2` indicate the size of the patch,\n              rather than code distances.\n\n            - 'growing': growing operation from a triangular patch with distance `d` to\n              a larger triangular patch with distance `d2`. Must be `d2 &gt; d`.\n\n            - 'cult+growing': cultivation on a triangular patch with distance `d`,\n              followed by a growing operation to distance `d2`. Must be `d2 &gt; d`.\n\n        d2 : int &gt;= 3, optional\n            Second code distance required for circuit types 'rec'/'rectangle', 'growing',\n            and 'cult+growing'. If not provided, `d2 = d` is used.\n\n        cnot_schedule : {'tri_optimal', 'tri_optimal_reversed', 'superdense_default'} or list of 12 integers,\n                        default 'tri_optimal'\n            CNOT schedule.\n\n            - List of 12 integers: (a, b, ... l) specifying the CNOT schedule.\n\n            - 'tri_optimal': (2, 3, 6, 5, 4, 1, 3, 4, 7, 6, 5, 2), which is the optimal\n            schedule for the triangular color code.\n\n            - 'tri_optimal_reversed': (3, 4, 7, 6, 5, 2, 2, 3, 6, 5, 4, 1),\n            which has the X- and Z-part reversed from 'tri_optimal'.\n\n            - 'superdense_default': (3, 1, 2, 3, 1, 2, 6, 4, 5, 6, 4, 5),\n            which is used for superdense syndrome extraction circuits.\n\n        superdense_circuit : bool, default False\n            Whether to use superdense syndrome extraction circuit. When True, the syndrome\n            extraction follows a 4-step pattern: (1) X-type anc \u2192 Z-type anc CNOTs,\n            (2) data \u2192 anc CNOTs with spatial routing, (3) anc \u2192 data CNOTs, (4) repeat step 1.\n            If True and cnot_schedule is 'tri_optimal', it automatically switches to\n            'superdense_default'.\n\n        temp_bdry_type : {'X', 'Y', 'Z', 'x', 'y', 'z'}, optional\n            Type of the temporal boundaries, i.e., the reset/measurement basis of\n            data qubits at the beginning and end of the circuit.\n            Not supported for `rec_stability` and `cult+growing` circuits: the types of\n            the temporal boundaries are fixed to red for `rec_stability` and `Y` for\n            `cult+growing`. For the other circuit types, it is `Z` by default.\n\n        noise_model : NoiseModel, optional\n            Noise model specifying error rates for different operations. If provided,\n            individual noise parameters (p_bitflip, p_depol, etc.) are ignored.\n            If not provided, a NoiseModel is constructed from individual parameters.\n\n        perfect_logical_initialization : bool, default False\n            Whether logical initialization operations (data qubit reset) are noiseless\n        perfect_logical_measurement : bool, default False\n            Whether logical final measurement operations are noiseless\n        perfect_init_final : bool, default False\n            If True, sets both perfect_logical_initialization and perfect_logical_measurement\n            to True.\n        perfect_first_syndrome_extraction : bool, default False\n            Whether the first syndrome extraction round is noiseless. Useful when\n            starting from a perfect logical state (together with\n            `perfect_logical_initialization=True`).\n            *Note:* `rounds` still includes this perfect round, so set to `T + 1` where\n            `T` is the number of actual faulty syndrome extraction rounds you want to consider.\n        comparative_decoding : bool, default False\n            Whether to use the comparative decoding technique. If True, observables are\n            included as additional detectors and decoding can be done by running the\n            decoder for each logical class and choosing the lowest-weight one. This also\n            provides the logical gap information, which quantifies the reliability of\n            decoding.\n        exclude_non_essential_pauli_detectors : bool, default False\n            If True and `temp_bdry_type` is not \"Y\", detectors with the Pauli type\n            different from the temporal boundary type (e.g., X-type detectors for\n            `temp_bdry_type=\"Z\"`) are excluded from the circuit. This does not affect the\n            decoding results since X and Z errors are independently decoded in our method\n            and physical errors with the same pauli type as the temporal boundaries do\n            not affect the logical values. If `temp_bdry_type=\"Y\"` or\n            `circuit_type=\"cult+growing\"`, both types of detectors are required for decoding,\n            so this option is ignored.\n        cultivation_circuit: stim.Circuit, optional\n            If given, it is used as the cultivation circuit for cultivation + growing\n            circuit (`circuit_type == 'cult+growing'`). WARNING: Its validity is not\n            checked internally.\n        remove_non_edge_like_errors: bool, default True\n            Whether to remove error mechanisms that are not edge-like when decomposing\n            the detector error model.\n\n        Parameters (legacy for backward compatibility)\n        ----------\n        shape: str, optional\n            Same as `circuit_type`. If given, prioritized over `circuit_type`.\n        p_bitflip : float, default 0\n            Bit-flip noise on every data qubit at the start of each round.\n            Ignored if noise_model is provided.\n        p_depol : float, default 0\n            Depolarizing noise on every data qubit at the start of each round.\n            Ignored if noise_model is provided.\n        p_reset : float, default 0\n            Error rate for each reset (producing an orthogonal state).\n            Ignored if noise_model is provided.\n        p_meas : float, default 0\n            Error rate for each measurement (flipped measurement outcome).\n            Ignored if noise_model is provided.\n        p_cnot : float, default 0\n            Two-qubit depolarizing noise rate for each CNOT gate.\n            Ignored if noise_model is provided.\n        p_idle : float, default 0\n            Single-qubit depolarizing noise rate for each idle gate.\n            Ignored if noise_model is provided.\n        p_circuit : float, optional\n            If given, p_reset = p_meas = p_cnot = p_idle = p_circuit.\n            Ignored if noise_model is provided.\n        p_cult : float, optional\n            Physical error rate during cultivation (only used for 'cult+growing'\n            circuits). If not given, `p_cult = p_cnot` is used.\n            Ignored if noise_model is provided.\n\n        \"\"\"\n        # Automatic cnot_schedule selection for superdense circuits\n        if superdense_circuit and cnot_schedule == \"tri_optimal\":\n            cnot_schedule = \"superdense_default\"\n\n        if isinstance(cnot_schedule, str):\n            if cnot_schedule in CNOT_SCHEDULES:\n                cnot_schedule = CNOT_SCHEDULES[cnot_schedule]\n            else:\n                raise ValueError(f\"Invalid cnot schedule: {cnot_schedule}\")\n        else:\n            cnot_schedule = list(cnot_schedule)\n            assert len(cnot_schedule) == 12\n\n        assert d &gt; 1 and rounds &gt;= 1\n\n        # Handle noise model: use provided NoiseModel or create from individual parameters\n        if noise_model is not None:\n            # Use provided NoiseModel\n            self.noise_model = noise_model\n        else:\n            # Create NoiseModel from individual parameters\n            if p_circuit is not None:\n                p_reset = p_meas = p_cnot = p_idle = p_circuit\n\n            # For cult+growing, validate requirements\n            if circuit_type in {\"cultivation+growing\", \"cult+growing\"}:\n                if p_circuit is None:\n                    raise ValueError(\n                        \"p_circuit must be provided for cult+growing circuit type\"\n                    )\n                if p_bitflip &gt; 0:\n                    raise ValueError(\n                        \"p_bitflip must be 0 for cult+growing circuit type\"\n                    )\n\n            # Create NoiseModel from individual parameters\n            self.noise_model = NoiseModel(\n                bitflip=p_bitflip,\n                depol=p_depol,\n                reset=p_reset,\n                meas=p_meas,\n                cnot=p_cnot,\n                idle=p_idle,\n                cult=p_cult,\n            )\n\n        self.d = d\n        d2 = self.d2 = d if d2 is None else d2\n        self.rounds = rounds\n\n        if shape is not None:\n            circuit_type = shape\n\n        if circuit_type in {\"triangle\", \"tri\"}:\n            assert d % 2 == 1\n            self.circuit_type = \"tri\"\n            self.num_obs = 1\n\n        elif circuit_type in {\"rectangle\", \"rec\"}:\n            assert d2 is not None\n            assert d % 2 == 0 and d2 % 2 == 0\n            self.circuit_type = \"rec\"\n            self.num_obs = 2\n\n        elif circuit_type == \"rec_stability\":\n            assert d2 is not None\n            assert d % 2 == 0 and d2 % 2 == 0\n            self.circuit_type = \"rec_stability\"\n            self.num_obs = 2\n\n        elif circuit_type == \"growing\":\n            assert d2 is not None\n            assert d % 2 == 1 and d2 % 2 == 1 and d2 &gt; d\n            self.circuit_type = \"growing\"\n            self.num_obs = 1\n\n        elif circuit_type in {\"cultivation+growing\", \"cult+growing\"}:\n            assert d2 is not None\n            assert d % 2 == 1 and d2 % 2 == 1 and d2 &gt; d\n            self.circuit_type = \"cult+growing\"\n            self.num_obs = 1\n\n        else:\n            raise ValueError(f\"Invalid circuit type: {circuit_type}\")\n\n        if temp_bdry_type is None:\n            if circuit_type == \"rec_stability\":\n                temp_bdry_type = \"r\"\n            elif circuit_type == \"cult+growing\":\n                temp_bdry_type = \"Y\"\n            else:\n                temp_bdry_type = \"Z\"\n        else:\n            assert temp_bdry_type in {\"X\", \"Y\", \"Z\", \"x\", \"y\", \"z\"}\n            assert circuit_type not in {\"rec_stability\", \"cult+growing\"}\n            temp_bdry_type = temp_bdry_type.upper()\n\n        self.temp_bdry_type = temp_bdry_type\n\n        if circuit_type == \"rec_stability\":\n            self.obs_paulis = [\"Z\", \"X\"]\n        else:\n            self.obs_paulis = [temp_bdry_type] * self.num_obs\n\n        self.cnot_schedule = cnot_schedule\n        self.superdense_circuit = superdense_circuit\n        self.perfect_init_final = perfect_init_final\n\n        # Handle backward compatibility: perfect_init_final sets both initialization and measurement\n        if perfect_init_final:\n            perfect_logical_initialization = True\n            perfect_logical_measurement = True\n\n        self.perfect_logical_initialization = perfect_logical_initialization\n        self.perfect_logical_measurement = perfect_logical_measurement\n        self.perfect_first_syndrome_extraction = perfect_first_syndrome_extraction\n\n        self.comparative_decoding = comparative_decoding\n\n        self.exclude_non_essential_pauli_detectors = (\n            exclude_non_essential_pauli_detectors\n        )\n\n        self.remove_non_edge_like_errors = remove_non_edge_like_errors\n\n        if self.comparative_decoding and self.circuit_type == \"rec_stability\":\n            raise NotImplementedError\n\n        if self.circuit_type == \"cult+growing\":\n            if cultivation_circuit is None:\n                cultivation_circuit = _load_cultivation_circuit(\n                    d=d, p=self.noise_model[\"cult\"]\n                )\n\n        else:\n            cultivation_circuit = None\n        self.cultivation_circuit = cultivation_circuit\n\n        self._benchmarking = _benchmarking\n\n        # Build Tanner graph using TannerGraphBuilder\n        graph_builder = TannerGraphBuilder(\n            circuit_type=self.circuit_type,\n            d=self.d,\n            d2=self.d2,\n        )\n        self.tanner_graph, self.qubit_groups = graph_builder.build()\n\n        # Generate circuit using CircuitBuilder\n        builder = CircuitBuilder(\n            d=self.d,\n            d2=self.d2,\n            rounds=self.rounds,\n            circuit_type=self.circuit_type,\n            cnot_schedule=self.cnot_schedule,\n            superdense_circuit=self.superdense_circuit,\n            temp_bdry_type=self.temp_bdry_type,\n            noise_model=self.noise_model,\n            perfect_init_final=self.perfect_init_final,\n            perfect_logical_initialization=self.perfect_logical_initialization,\n            perfect_logical_measurement=self.perfect_logical_measurement,\n            perfect_first_syndrome_extraction=self.perfect_first_syndrome_extraction,\n            tanner_graph=self.tanner_graph,\n            qubit_groups=self.qubit_groups,\n            exclude_non_essential_pauli_detectors=self.exclude_non_essential_pauli_detectors,\n            cultivation_circuit=self.cultivation_circuit,\n            comparative_decoding=self.comparative_decoding,\n        )\n        self.circuit = builder.build()\n\n        # Initialize DEM manager (lazy loading)\n        self._dem_manager = None\n        self._generate_dem = _generate_dem\n        self._decompose_dem = _decompose_dem\n\n        # Initialize decoders (lazy loading)\n        self._concat_matching_decoder = None\n        self._bp_decoder = None\n        self._belief_concat_matching_decoder = None\n        self._simulator = None\n\n        self._bp_inputs = {}\n\n    @property\n    def dem_manager(self) -&gt; DemManager:\n        \"\"\"Lazy loading property for DEM Manager.\"\"\"\n        if self._dem_manager is None:\n            if self._generate_dem:\n                self._dem_manager = DemManager(\n                    circuit=self.circuit,\n                    tanner_graph=self.tanner_graph,\n                    circuit_type=self.circuit_type,\n                    comparative_decoding=self.comparative_decoding,\n                    remove_non_edge_like_errors=self.remove_non_edge_like_errors,\n                )\n            else:\n                # Create a minimal DEM manager for backward compatibility\n                # when _generate_dem is False\n                raise NotImplementedError(\"DEM generation is disabled\")\n        return self._dem_manager\n\n    # Property delegation for backward compatibility\n    @property\n    def dem_xz(self) -&gt; stim.DetectorErrorModel:\n        \"\"\"Delegate to DEM manager.\"\"\"\n        return self.dem_manager.dem_xz\n\n    @property\n    def H(self) -&gt; csc_matrix:\n        \"\"\"Delegate to DEM manager.\"\"\"\n        return self.dem_manager.H\n\n    @property\n    def obs_matrix(self) -&gt; csc_matrix:\n        \"\"\"Delegate to DEM manager.\"\"\"\n        return self.dem_manager.obs_matrix\n\n    @property\n    def probs_xz(self) -&gt; np.ndarray:\n        \"\"\"Delegate to DEM manager.\"\"\"\n        return self.dem_manager.probs_xz\n\n    @property\n    def detector_ids_by_color(self) -&gt; Dict[COLOR_LABEL, List[int]]:\n        \"\"\"Delegate to DEM manager.\"\"\"\n        return self.dem_manager.detector_ids_by_color\n\n    @property\n    def cult_detector_ids(self) -&gt; List[int]:\n        \"\"\"Delegate to DEM manager.\"\"\"\n        return self.dem_manager.cult_detector_ids\n\n    @property\n    def interface_detector_ids(self) -&gt; List[int]:\n        \"\"\"Delegate to DEM manager.\"\"\"\n        return self.dem_manager.interface_detector_ids\n\n    @property\n    def detectors_checks_map(self) -&gt; List[Tuple[ig.Vertex, int]]:\n        \"\"\"Delegate to DEM manager.\"\"\"\n        return self.dem_manager.detectors_checks_map\n\n    @property\n    def dems_decomposed(self) -&gt; Dict[COLOR_LABEL, DemDecomp]:\n        \"\"\"Delegate to DEM manager.\"\"\"\n        return self.dem_manager.dems_decomposed\n\n    @property\n    def concat_matching_decoder(self) -&gt; ConcatMatchingDecoder:\n        \"\"\"Lazy loading property for concatenated matching decoder.\"\"\"\n        if self._concat_matching_decoder is None:\n            self._concat_matching_decoder = ConcatMatchingDecoder(\n                dem_manager=self.dem_manager,\n            )\n        return self._concat_matching_decoder\n\n    @property\n    def bp_decoder(self) -&gt; BPDecoder:\n        \"\"\"Lazy loading property for belief propagation decoder.\"\"\"\n        if self._bp_decoder is None:\n            self._bp_decoder = BPDecoder(\n                dem_manager=self.dem_manager,\n                comparative_decoding=self.comparative_decoding,\n                cache_inputs=True,\n            )\n        return self._bp_decoder\n\n    @property\n    def belief_concat_matching_decoder(self) -&gt; BeliefConcatMatchingDecoder:\n        \"\"\"Lazy loading property for belief propagation + concatenated matching decoder.\"\"\"\n        if self._belief_concat_matching_decoder is None:\n            self._belief_concat_matching_decoder = BeliefConcatMatchingDecoder(\n                dem_manager=self.dem_manager,\n                circuit_type=self.circuit_type,\n                num_obs=self.num_obs,\n                comparative_decoding=self.comparative_decoding,\n                bp_cache_inputs=True,\n            )\n        return self._belief_concat_matching_decoder\n\n    @property\n    def simulator(self) -&gt; Simulator:\n        \"\"\"Lazy loading property for simulator.\"\"\"\n        if self._simulator is None:\n            self._simulator = Simulator(\n                circuit=self.circuit,\n                circuit_type=self.circuit_type,\n            )\n        return self._simulator\n\n    def get_detector_type(self, detector_id: int) -&gt; Tuple[PAULI_LABEL, COLOR_LABEL]:\n        \"\"\"\n        Get the Pauli and color type of a detector.\n\n        Parameters\n        ----------\n        detector_id : int\n            Detector ID to query\n\n        Returns\n        -------\n        pauli : PAULI_LABEL\n            Pauli type of the detector ('X', 'Y', or 'Z')\n        color : COLOR_LABEL\n            Color of the detector ('r', 'g', or 'b')\n        \"\"\"\n        coords = self.circuit.get_detector_coordinates(only=[detector_id])[detector_id]\n        pauli = coords[3]\n        if pauli == 0:\n            pauli = \"X\"\n        elif pauli == 1:\n            pauli = \"Y\"\n        elif pauli == 2:\n            pauli = \"Z\"\n        else:\n            raise ValueError(f\"Invalid pauli: {pauli}\")\n        color = color_val_to_color(coords[4])\n\n        return pauli, color\n\n    def get_observable_pauli(self, observable_id: int) -&gt; PAULI_LABEL:\n        \"\"\"\n        Get the Pauli type of an observable.\n\n        Parameters\n        ----------\n        observable_id : int\n            Observable ID to query\n\n        Returns\n        -------\n        PAULI_LABEL\n            Pauli type of the observable\n        \"\"\"\n        return self.obs_paulis[observable_id]\n\n    def get_decomposed_dems(\n        self, color: COLOR_LABEL\n    ) -&gt; Tuple[stim.DetectorErrorModel, stim.DetectorErrorModel]:\n        \"\"\"Delegate to DEM manager.\"\"\"\n        return self.dem_manager.get_decomposed_dems(color)\n\n    def draw_lattice(\n        self,\n        ax: Optional[plt.Axes] = None,\n        show_axes: bool = False,\n        highlight_qubits: Optional[\n            List[int] | List[Tuple[float, float]] | List[str] | np.ndarray\n        ] = None,\n        highlight_qubits2: Optional[\n            List[int] | List[Tuple[float, float]] | List[str] | np.ndarray\n        ] = None,\n        highlight_faces: Optional[\n            List[int] | List[Tuple[float, float]] | List[str] | np.ndarray\n        ] = None,\n        **kwargs,\n    ) -&gt; plt.Axes:\n        \"\"\"\n        Draws the color code lattice.\n\n        Parameters\n        ----------\n        ax : matplotlib.axes.Axes, optional\n            The axis on which to draw the graph. If None, a new figure and\n            axis will be created.\n        show_axes : bool, default False\n            Whether to show the x- and y-axis.\n        highlight_qubits : list[int] | list[tuple] | list[str] | np.ndarray, optional\n            Data qubits to highlight with orange triangles (by default).\n            Can be a list of data qubit indices (ordered by code.vs.select(pauli=None)),\n            a list of coordinate tuples [(x, y), ...], or a list of qubit names ['x-y', ...].\n        highlight_qubits2 : list[int] | list[tuple] | list[str] | np.ndarray, optional\n            Data qubits to highlight with purple rectangles (by default).\n            Format is the same as highlight_qubits.\n        highlight_faces : list[int] | list[tuple] | list[str] | np.ndarray, optional\n            Z ancillary qubits whose corresponding faces should be highlighted.\n            Can be a list of Z ancillary qubit indices (ordered by code.vs.select(pauli=\"Z\")),\n            a list of coordinate tuples [(x, y), ...], or a list of qubit names ['x-y', ...].\n            Note that for names, the actual stored name includes a '-Z' suffix.\n        edge_color : str, default 'black'\n            Colors for edges.\n        edge_linewidth : float, default 1.0\n            Linewidth for edges.\n        face_lightness : float, default 0.3\n            Controls the lightness of face colors. Lower values make colors lighter.\n        show_data_qubits : bool, default True\n            Whether to draw circles representing data qubits.\n        data_qubit_color : str, default 'black'\n            Color for the data qubit circles (if shown).\n        data_qubit_size : float, default 5.0\n            Size for the data qubit circles (if shown).\n        highlight_qubit_color : str, default 'orange'\n            The color used to highlight qubits in `highlight_qubits`.\n        highlight_qubit_color2 : str, default 'purple'\n            The color used to highlight qubits in `highlight_qubits2`.\n        highlight_qubit_marker : str, default '^' (triangle)\n            The marker used to highlight qubits in `highlight_qubits`.\n        highlight_qubit_marker2 : str, default 's' (square)\n            The marker used to highlight qubits in `highlight_qubits2`.\n        highlight_face_lightness : float, default 1.0\n            Controls the lightness of the highlighted faces.\n\n        Returns\n        -------\n        matplotlib.axes.Axes\n            The axis containing the drawn lattice visualization.\n        \"\"\"\n        return draw_lattice(\n            self,\n            ax=ax,\n            show_axes=show_axes,\n            highlight_qubits=highlight_qubits,\n            highlight_qubits2=highlight_qubits2,\n            highlight_faces=highlight_faces,\n            **kwargs,\n        )\n\n    def draw_tanner_graph(\n        self,\n        ax: Optional[plt.Axes] = None,\n        show_axes: bool = False,\n        show_lattice: bool = False,\n        **kwargs,\n    ) -&gt; plt.Axes:\n        \"\"\"\n        Draw the tanner graph of the code.\n\n        Parameters\n        ----------\n        ax : matplotlib.axes.Axes, optional\n            The axis on which to draw the graph. If None, a new figure and axis will be created.\n        show_axes : bool, default False\n            Whether to show the x- and y-axis.\n        show_lattice : bool, default False\n            Whether to show the lattice edges in addition to the tanner graph edges.\n        **kwargs : dict\n            Additional keyword arguments to pass to igraph.plot.\n\n        Returns\n        -------\n        matplotlib.axes.Axes\n            The axis containing the drawn graph.\n        \"\"\"\n        return draw_tanner_graph(\n            self,\n            ax=ax,\n            show_axes=show_axes,\n            show_lattice=show_lattice,\n            **kwargs,\n        )\n\n    def get_detector(self, detector_id: int) -&gt; Tuple[ig.Vertex, int]:\n        \"\"\"\n        Get the ancillary qubit and round corresponding to a detector from a\n        given detector ID.\n\n        Parameters\n        ----------\n        detector_id : int\n            Detector ID.\n\n        Returns\n        -------\n        anc : ig.Vertex\n            Ancillary qubit involved in the detector.\n        round : int\n            Round that the detector belongs to.\n        \"\"\"\n        try:\n            return self.detectors_checks_map[detector_id]\n        except IndexError:\n            raise ValueError(f\"Detector ID {detector_id} not found.\")\n\n    def errors_to_qubits(\n        self,\n        errors: np.ndarray,\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Convert errors (generated by `sample_with_errors`) or error predictions\n        (generated by decoders) into the corresponding data qubit indices.\n\n        Available only for `tri` and `rec` circuit types with `rounds=1` under\n        bit-flip noise (i.e., probabilities besides `p_bitflip` are 0).\n\n        Note: Errors and error predictions from `sample_with_errors` or decoders\n        follow the ordering of error mechanisms in the circuit's detector error model\n        (`circuit.detector_error_model()`). This function is necessary because this\n        ordering differs from the data qubit ordering in the tanner graph\n        (`tanner_graph.vs.select(pauli=None)`). This conversion is especially helpful\n        when visualizing errors or error predictions on the lattice.\n\n        Parameters\n        ----------\n        errors : 2D numpy array of bool\n            Errors following the ordering of error mechanisms in the DEM of the circuit\n            `circuit.detector_error_model()`.\n\n        Returns\n        -------\n        errors_qubits : 2D numpy array of bool\n            Errors following the ordering of data qubits in the tanner graph\n            `tanner_graph.vs.select(pauli=None)`.\n        \"\"\"\n\n        if self.circuit_type not in {\"tri\", \"rec\"}:\n            raise NotImplementedError(\n                f'errors_to_qubits is not available for \"{self.circuit_type}\" circuit type.'\n            )\n\n        if self.rounds != 1:\n            raise NotImplementedError(\n                \"errors_to_qubits is only available when rounds = 1.\"\n            )\n\n        if any(prob &gt; 0 for key, prob in self.noise_model.items() if key != \"bitflip\"):\n            raise NotImplementedError(\n                \"errors_to_qubits is only available under bit-flip noise \"\n                \"(only p_bitflip is nonzero).\"\n            )\n\n        # set of ancillary qubits - data qubit mapping\n        anc_qids_to_data_qubit_idx = {}\n        data_qubits = self.tanner_graph.vs.select(pauli=None)\n        for i_dq, data_qubit in enumerate(data_qubits):\n            data_qubit: ig.Vertex\n            connected_anc_qubits = data_qubit.neighbors()\n            connected_anc_qubits = [\n                q for q in connected_anc_qubits if q[\"pauli\"] == \"Z\"\n            ]\n            key = frozenset(q.index for q in connected_anc_qubits)\n            assert key not in anc_qids_to_data_qubit_idx\n            anc_qids_to_data_qubit_idx[key] = i_dq\n\n        # data qubit mapping - error mechanism in DEM\n        dem = self.circuit.detector_error_model()\n        data_qubit_idx_to_em = np.full(len(data_qubits), -1, dtype=\"int32\")\n        for i_em, em in enumerate(dem):\n            if em.type == \"error\":\n                det_ids = [\n                    int(str(target)[1:])\n                    for target in em.targets_copy()\n                    if target.is_relative_detector_id()\n                ]\n                anc_qids = [\n                    self.get_detector(det_id)[0].index\n                    for det_id in det_ids\n                    if det_id &lt; len(self.detectors_checks_map)\n                ]\n                anc_qids = frozenset(anc_qids)\n                data_qubit_idx = anc_qids_to_data_qubit_idx[anc_qids]\n                if data_qubit_idx_to_em[data_qubit_idx] != -1:\n                    raise ValueError(\n                        f\"Data qubit {data_qubit_idx} is mapped to multiple error mechanisms: {data_qubit_idx_to_em[data_qubit_idx]} and {i_em}\"\n                    )\n                data_qubit_idx_to_em[data_qubit_idx] = i_em\n        assert np.all(data_qubit_idx_to_em != -1)\n\n        return errors[..., data_qubit_idx_to_em]\n\n    def decode_bp(\n        self,\n        detector_outcomes: np.ndarray,\n        max_iter: int = 10,\n        **kwargs,\n    ):\n        \"\"\"\n        Decode detector outcomes using belief propagation.\n\n        This method delegates to the BPDecoder while maintaining backward compatibility\n        with the _bp_inputs caching mechanism for integration with pre-decoding.\n\n        Parameters\n        ----------\n        detector_outcomes : np.ndarray\n            1D or 2D array of detector measurement outcomes to decode.\n        max_iter : int\n            Maximum number of belief propagation iterations to perform.\n        **kwargs\n            Additional keyword arguments to pass to the BpDecoder constructor.\n\n        Returns\n        -------\n        pred : np.ndarray\n            Predicted error pattern.\n        llrs : np.ndarray\n            Log probability ratios for each bit in the predicted error pattern.\n        converge : bool\n            Whether the belief propagation algorithm converged within max_iter iterations.\n        \"\"\"\n        # Update _bp_inputs cache for compatibility with pre-decoding integration\n        if not self._bp_inputs:\n            if self.comparative_decoding:\n                dem = remove_obs_from_dem(self.dem_xz)\n            else:\n                dem = self.dem_xz\n            H, p = dem_to_parity_check(dem)\n            self._bp_inputs[\"H\"] = H\n            self._bp_inputs[\"p\"] = p\n\n        # Delegate to BP decoder\n        return self.bp_decoder.decode(detector_outcomes, max_iter=max_iter, **kwargs)\n\n    def decode(\n        self,\n        detector_outcomes: np.ndarray,\n        colors: str | List[str] = \"all\",\n        logical_value: bool | Sequence[bool] | None = None,\n        bp_predecoding: bool = False,\n        bp_prms: dict | None = None,\n        erasure_matcher_predecoding: bool = False,\n        partial_correction_by_predecoding: bool = False,\n        full_output: bool = False,\n        check_validity: bool = False,\n        verbose: bool = False,\n    ) -&gt; np.ndarray | Tuple[np.ndarray, dict]:\n        \"\"\"\n        Decode detector outcomes using concatenated MWPM decoding.\n\n        This method delegates to the ConcatMatchingDecoder while preserving backward\n        compatibility and handling BP pre-decoding integration.\n\n        Parameters\n        ----------\n        detector_outcomes : 1D or 2D array-like of bool\n            Array of input detector outcomes for one or multiple samples.\n            If 1D, it is interpreted as a single sample.\n            If 2D, each row corresponds to a sample and each column corresponds to a\n            detector. detector_outcomes[i, j] is True if and only if the detector with\n            id j in the ith sample has the outcome \u22121.\n        colors : str or list of str, default 'all'\n            Colors to use for decoding. Can be 'all', one of {'r', 'g', 'b'},\n            or a list containing any combination of {'r', 'g', 'b'}.\n        logical_value : bool or 1D array-like of bool, optional\n            Logical value(s) to use for decoding. If None, all possible logical value\n            combinations (i.e., logical classes) will be tried and the one with minimum\n            weight will be selected.\n        bp_predecoding : bool, default False\n            Whether to use belief propagation as a pre-decoding step.\n        bp_prms : dict, default None\n            Parameters for the belief propagation decoder.\n        erasure_matcher_predecoding : bool, default False\n            Whether to use erasure matcher as a pre-decoding step.\n        partial_correction_by_predecoding : bool, default False\n            Whether to use the prediction from the erasure matcher predecoding as a\n            partial correction for the second round of decoding, in the case that the predecoding fails to find a valid prediction.\n        full_output : bool, default False\n            Whether to return extra information about the decoding process.\n        check_validity : bool, default False\n            Whether to check the validity of the predicted error patterns.\n        verbose : bool, default False\n            Whether to print additional information during decoding.\n\n        Returns\n        -------\n        obs_preds : 1D or 2D numpy array of bool\n            Predicted observables. It is 1D if there is only one observable and\n            2D if otherwise. obs_preds[i] or obs_preds[i,j] is True if and only\n            if the j-th observable (j=0 when 1D) of the i-th sample is\n            predicted to be -1.\n        extra_outputs : dict, only when full_output is True\n            Dictionary containing additional decoding outputs.\n        \"\"\"\n        # Handle BP pre-decoding by delegating to BeliefConcatMatchingDecoder\n        if bp_predecoding:\n            return self.belief_concat_matching_decoder.decode(\n                detector_outcomes=detector_outcomes,\n                colors=colors,\n                logical_value=logical_value,\n                bp_prms=bp_prms,\n                erasure_matcher_predecoding=erasure_matcher_predecoding,\n                partial_correction_by_predecoding=partial_correction_by_predecoding,\n                full_output=full_output,\n                check_validity=check_validity,\n                verbose=verbose,\n            )\n\n        # Delegate to ConcatMatchingDecoder for standard decoding\n        return self.concat_matching_decoder.decode(\n            detector_outcomes=detector_outcomes,\n            colors=colors,\n            logical_value=logical_value,\n            erasure_matcher_predecoding=erasure_matcher_predecoding,\n            partial_correction_by_predecoding=partial_correction_by_predecoding,\n            full_output=full_output,\n            check_validity=check_validity,\n            verbose=verbose,\n        )\n\n    def sample(\n        self, shots: int, seed: Optional[int] = None\n    ) -&gt; Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Sample detector outcomes and observables from the quantum circuit.\n\n        Parameters\n        ----------\n        shots : int\n            Number of samples to generate\n        seed : int, optional\n            Seed value to initialize the random number generator\n\n        Returns\n        -------\n        det : 2D numpy array of bool\n            Detector outcomes. det[i,j] is True if and only if the detector\n            with id j in the i-th sample has an outcome of \u22121.\n        obs : 1D or 2D numpy array of bool\n            Observable outcomes. If there is only one observable, returns a 1D array;\n            otherwise returns a 2D array. obs[i] or obs[i,j] is True if and only if\n            the j-th observable (j=0 when 1D) of the i-th sample has an outcome of -1.\n        \"\"\"\n        return self.simulator.sample(shots, seed=seed)\n\n    def sample_with_errors(\n        self,\n        shots: int,\n        seed: Optional[int] = None,\n    ) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Sample detector outcomes, observables, and errors from the quantum circuit.\n\n        Parameters\n        ----------\n        shots : int\n            Number of samples to generate\n        seed : int, optional\n            Seed value to initialize the random number generator\n\n        Returns\n        -------\n        det : 2D numpy array of bool\n            Detector outcomes. det[i,j] is True if and only if the detector\n            with id j in the i-th sample has an outcome of \u22121.\n        obs : 1D or 2D numpy array of bool\n            Observable outcomes. If there is only one observable, returns a 1D array;\n            otherwise returns a 2D array. obs[i] or obs[i,j] is True if and only if\n            the j-th observable (j=0 when 1D) of the i-th sample has an outcome of -1.\n        errors : 2D numpy array of bool\n            Errors sampled from the quantum circuit. errors[i,j] is True if and only if\n            the j-th error (in the DEM) of the i-th sample has an outcome of -1.\n        \"\"\"\n        return self.simulator.sample_with_errors(shots, seed=seed)\n\n    def simulate(\n        self,\n        shots: int,\n        *,\n        bp_predecoding: bool = False,\n        bp_prms: dict | None = None,\n        erasure_matcher_predecoding: bool = False,\n        partial_correction_by_predecoding: bool = False,\n        colors: Union[List[str], str] = \"all\",\n        alpha: float = 0.01,\n        confint_method: str = \"wilson\",\n        full_output: bool = False,\n        seed: Optional[int] = None,\n        verbose: bool = False,\n        **kwargs,\n    ) -&gt; Tuple[np.ndarray, dict]:\n        \"\"\"\n        Monte-Carlo simulation of the concatenated MWPM decoder. Delegated to simulator.\n\n        Parameters\n        ----------\n        shots : int\n            Number of shots to simulate.\n        bp_predecoding : bool, default False\n            If True, use belief propagation for predecoding.\n        bp_prms : dict | None, default None\n            Parameters for belief propagation predecoding.\n        erasure_matcher_predecoding : bool, default False\n            If True, use erasure matcher predecoding to identify errors common to all colors.\n        partial_correction_by_predecoding : bool, default False\n            If True, apply partial correction using predecoding results when erasure matcher predecoding fails.\n        colors : Union[List[str], str], default 'all'\n            Colors of the sub-decoding procedures to consider. Can be 'all', one of {'r', 'g', 'b'},\n            or a list containing any combination of {'r', 'g', 'b'}.\n        alpha : float, default 0.01\n            Significance level for the confidence interval calculation.\n        confint_method : str, default 'wilson'\n            Method to calculate the confidence interval.\n            See statsmodels.stats.proportion.proportion_confint for available options.\n        full_output: bool = False,\n            If True, return additional information.\n        seed : Optional[int], default None\n            Seed to initialize the random number generator.\n        verbose : bool, default False\n            If True, print progress information during simulation.\n        **kwargs :\n            Additional keyword arguments for the decoder (see `ColorCode.decode()`).\n\n        Returns\n        -------\n        num_fails : numpy.ndarray\n            Number of failures for each observable.\n        extra_outputs : dict, optional\n            Dictionary containing additional information:\n            - 'stats': Tuple of (pfail, delta_pfail) where pfail is the estimated failure rate\n              and delta_pfail is the half-width of the confidence interval\n            - 'fails': Boolean array indicating which samples failed\n            - 'logical_gaps': Array of logical gaps (only when self.logical_gap is True)\n            - etc.\n        \"\"\"\n\n        # Create decoder function for simulator\n        def decoder_func(detector_outcomes, **decode_kwargs):\n            return self.decode(\n                detector_outcomes,\n                bp_predecoding=bp_predecoding,\n                bp_prms=bp_prms,\n                erasure_matcher_predecoding=erasure_matcher_predecoding,\n                partial_correction_by_predecoding=partial_correction_by_predecoding,\n                **kwargs,  # Original kwargs from simulate\n                **decode_kwargs,  # Additional kwargs from simulator\n            )\n\n        # Delegate to simulator\n        result = self.simulator.simulate(\n            shots=shots,\n            decoder_func=decoder_func,\n            colors=colors,\n            alpha=alpha,\n            confint_method=confint_method,\n            full_output=full_output,\n            seed=seed,\n            verbose=verbose,\n        )\n\n        return result\n\n    # ----- Save/Load Methods -----\n\n    def _test_attribute_picklability(self) -&gt; Tuple[List[str], List[str]]:\n        \"\"\"\n        Test which attributes are picklable and which are not.\n\n        Returns\n        -------\n        picklable : List[str]\n            List of attribute names that can be pickled\n        non_picklable : List[str]\n            List of attribute names that cannot be pickled\n        \"\"\"\n        import pickle\n        import io\n\n        picklable = []\n        non_picklable = []\n\n        for attr_name, attr_value in self.__dict__.items():\n            try:\n                # Try to pickle the attribute\n                buffer = io.BytesIO()\n                pickle.dump(attr_value, buffer)\n                picklable.append(attr_name)\n            except Exception:\n                non_picklable.append(attr_name)\n\n        return picklable, non_picklable\n\n    def save(self, path: str):\n        \"\"\"\n        Save the ColorCode object to a file using pickle.\n\n        Automatically identifies and excludes non-picklable attributes such as igraph objects,\n        complex decoder objects, and lazy-loaded managers. These will be reconstructed upon loading.\n\n        Parameters\n        ----------\n        path : str\n            The file path where the object should be saved.\n        \"\"\"\n        data = self.__dict__.copy()\n\n        # Known non-picklable attributes based on modular architecture\n        known_non_picklable = [\n            # igraph objects\n            \"tanner_graph\",  # igraph.Graph\n            \"qubit_groups\",  # Dict[str, ig.VertexSeq]\n            # Complex manager and decoder objects (lazy-loaded)\n            \"_dem_manager\",  # DemManager with igraph references\n            \"_concat_matching_decoder\",  # ConcatMatchingDecoder\n            \"_bp_decoder\",  # BPDecoder\n            \"_belief_concat_matching_decoder\",  # BeliefConcatMatchingDecoder\n            \"_simulator\",  # Simulator\n            # Cache that should be reconstructed\n            \"_bp_inputs\",  # Dictionary cache\n        ]\n\n        # Test remaining attributes for picklability and get dynamic exclusions\n        temp_data = {k: v for k, v in data.items() if k not in known_non_picklable}\n        _, additional_non_picklable = self._test_remaining_attributes(temp_data)\n\n        # Combine known and discovered non-picklable attributes\n        all_excluded = known_non_picklable + additional_non_picklable\n\n        # Remove non-picklable attributes\n        for key in all_excluded:\n            if key in data:\n                del data[key]\n\n        with open(path, \"wb\") as f:\n            pickle.dump(data, f)\n\n    def _test_remaining_attributes(\n        self, data_dict: dict\n    ) -&gt; Tuple[List[str], List[str]]:\n        \"\"\"\n        Test remaining attributes for picklability after excluding known non-picklable ones.\n\n        Parameters\n        ----------\n        data_dict : dict\n            Dictionary of attributes to test\n\n        Returns\n        -------\n        picklable : List[str]\n            List of attribute names that can be pickled\n        non_picklable : List[str]\n            List of attribute names that cannot be pickled\n        \"\"\"\n        import pickle\n        import io\n\n        picklable = []\n        non_picklable = []\n\n        for attr_name, attr_value in data_dict.items():\n            try:\n                # Try to pickle the attribute\n                buffer = io.BytesIO()\n                pickle.dump(attr_value, buffer)\n                picklable.append(attr_name)\n            except Exception:\n                non_picklable.append(attr_name)\n\n        return picklable, non_picklable\n\n    @classmethod\n    def load(cls, path: str) -&gt; \"ColorCode\":\n        \"\"\"\n        Load a ColorCode object from a file saved by the `save` method.\n\n        Reconstructs non-picklable attributes excluded during saving using the\n        modular architecture approach.\n\n        Parameters\n        ----------\n        path : str\n            The file path from which to load the object.\n\n        Returns\n        -------\n        ColorCode\n            The loaded ColorCode object.\n        \"\"\"\n        with open(path, \"rb\") as f:\n            data = pickle.load(f)\n\n        # Create a new instance without calling __init__\n        instance = cls.__new__(cls)\n        instance.__dict__.update(data)\n\n        # Reconstruct non-picklable attributes in the correct order\n        try:\n            # Step 1: Reconstruct tanner_graph and qubit_groups\n            instance._reconstruct_tanner_graph_and_qubit_groups()\n\n            # Step 2: Clear lazy-loaded object caches (they will be recreated on demand)\n            instance._dem_manager = None\n            instance._concat_matching_decoder = None\n            instance._bp_decoder = None\n            instance._belief_concat_matching_decoder = None\n            instance._simulator = None\n\n            # Step 3: Initialize cache\n            instance._bp_inputs = {}\n\n        except Exception as e:\n            print(f\"Error during reconstruction: {e}\")\n            raise\n\n        return instance\n\n    def _reconstruct_tanner_graph_and_qubit_groups(self):\n        \"\"\"\n        Reconstruct tanner_graph and qubit_groups using TannerGraphBuilder.\n\n        This method recreates the igraph objects that cannot be pickled by using\n        the same TannerGraphBuilder that was used during initialization.\n        \"\"\"\n        # Reconstruct using TannerGraphBuilder with saved parameters\n        graph_builder = TannerGraphBuilder(\n            circuit_type=self.circuit_type,\n            d=self.d,\n            d2=self.d2,\n        )\n        self.tanner_graph, self.qubit_groups = graph_builder.build()\n</code></pre>"},{"location":"api/color_code/#color_code_stim.ColorCode.H","title":"<code>H</code>  <code>property</code>","text":"<p>Delegate to DEM manager.</p>"},{"location":"api/color_code/#color_code_stim.ColorCode.belief_concat_matching_decoder","title":"<code>belief_concat_matching_decoder</code>  <code>property</code>","text":"<p>Lazy loading property for belief propagation + concatenated matching decoder.</p>"},{"location":"api/color_code/#color_code_stim.ColorCode.bp_decoder","title":"<code>bp_decoder</code>  <code>property</code>","text":"<p>Lazy loading property for belief propagation decoder.</p>"},{"location":"api/color_code/#color_code_stim.ColorCode.concat_matching_decoder","title":"<code>concat_matching_decoder</code>  <code>property</code>","text":"<p>Lazy loading property for concatenated matching decoder.</p>"},{"location":"api/color_code/#color_code_stim.ColorCode.cult_detector_ids","title":"<code>cult_detector_ids</code>  <code>property</code>","text":"<p>Delegate to DEM manager.</p>"},{"location":"api/color_code/#color_code_stim.ColorCode.dem_manager","title":"<code>dem_manager</code>  <code>property</code>","text":"<p>Lazy loading property for DEM Manager.</p>"},{"location":"api/color_code/#color_code_stim.ColorCode.dem_xz","title":"<code>dem_xz</code>  <code>property</code>","text":"<p>Delegate to DEM manager.</p>"},{"location":"api/color_code/#color_code_stim.ColorCode.dems_decomposed","title":"<code>dems_decomposed</code>  <code>property</code>","text":"<p>Delegate to DEM manager.</p>"},{"location":"api/color_code/#color_code_stim.ColorCode.detector_ids_by_color","title":"<code>detector_ids_by_color</code>  <code>property</code>","text":"<p>Delegate to DEM manager.</p>"},{"location":"api/color_code/#color_code_stim.ColorCode.detectors_checks_map","title":"<code>detectors_checks_map</code>  <code>property</code>","text":"<p>Delegate to DEM manager.</p>"},{"location":"api/color_code/#color_code_stim.ColorCode.interface_detector_ids","title":"<code>interface_detector_ids</code>  <code>property</code>","text":"<p>Delegate to DEM manager.</p>"},{"location":"api/color_code/#color_code_stim.ColorCode.obs_matrix","title":"<code>obs_matrix</code>  <code>property</code>","text":"<p>Delegate to DEM manager.</p>"},{"location":"api/color_code/#color_code_stim.ColorCode.probs_xz","title":"<code>probs_xz</code>  <code>property</code>","text":"<p>Delegate to DEM manager.</p>"},{"location":"api/color_code/#color_code_stim.ColorCode.simulator","title":"<code>simulator</code>  <code>property</code>","text":"<p>Lazy loading property for simulator.</p>"},{"location":"api/color_code/#color_code_stim.ColorCode.__init__","title":"<code>__init__(*, d, rounds, circuit_type='tri', d2=None, cnot_schedule='tri_optimal', superdense_circuit=False, temp_bdry_type=None, noise_model=None, perfect_logical_initialization=False, perfect_logical_measurement=False, perfect_init_final=False, perfect_first_syndrome_extraction=False, comparative_decoding=False, exclude_non_essential_pauli_detectors=False, cultivation_circuit=None, remove_non_edge_like_errors=True, shape=None, p_bitflip=0.0, p_depol=0.0, p_reset=0.0, p_meas=0.0, p_cnot=0.0, p_idle=0.0, p_circuit=None, p_cult=None, _generate_dem=True, _decompose_dem=True, _benchmarking=False)</code>","text":"<p>Class for constructing a color code circuit and simulating the concatenated MWPM decoder.</p> <p>Examples:</p> <p>Triangular patch with uniform circuit-level noise of 1e-3:</p> <pre><code>&gt;&gt;&gt; from color_code_stim import ColorCode, NoiseModel\n&gt;&gt;&gt; noise = NoiseModel.uniform_circuit_noise(1e-3)\n&gt;&gt;&gt; colorcode = ColorCode(d=5, rounds=5, circuit_type=\"tri\", noise_model=noise)\n&gt;&gt;&gt; num_fails, info = colorcode.simulate(shots=10000, full_output=True)\n</code></pre> <p>See <code>getting_started.ipynb</code> for more detailed usage.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>int &gt;= 3</code> <p>Code distance.</p> required <code>rounds</code> <code>int &gt;= 1</code> <p>Number of syndrome extraction rounds.</p> required <code>circuit_type</code> <code>(triangle, tri, rectangle, rec, rec_stability, growing, cult + growing)</code> <p>Circuit type.</p> <ul> <li> <p>'triangle'/'tri': memory experiment of a triangular patch with distance   <code>d</code>.</p> </li> <li> <p>'rectangle'/'rec': memory experiment of a rectangular patch with distance   <code>d</code> and <code>d2</code>.</p> </li> <li> <p>'rec_stability': stability experiment of a rectangle-like patch with   single-type boundaries. <code>d</code> and <code>d2</code> indicate the size of the patch,   rather than code distances.</p> </li> <li> <p>'growing': growing operation from a triangular patch with distance <code>d</code> to   a larger triangular patch with distance <code>d2</code>. Must be <code>d2 &gt; d</code>.</p> </li> <li> <p>'cult+growing': cultivation on a triangular patch with distance <code>d</code>,   followed by a growing operation to distance <code>d2</code>. Must be <code>d2 &gt; d</code>.</p> </li> </ul> <code>'triangle'</code> <code>d2</code> <code>int &gt;= 3</code> <p>Second code distance required for circuit types 'rec'/'rectangle', 'growing', and 'cult+growing'. If not provided, <code>d2 = d</code> is used.</p> <code>None</code> <code>cnot_schedule</code> <code>(tri_optimal, tri_optimal_reversed, superdense_default)</code> <pre><code>        default 'tri_optimal'\n</code></pre> <p>CNOT schedule.</p> <ul> <li> <p>List of 12 integers: (a, b, ... l) specifying the CNOT schedule.</p> </li> <li> <p>'tri_optimal': (2, 3, 6, 5, 4, 1, 3, 4, 7, 6, 5, 2), which is the optimal schedule for the triangular color code.</p> </li> <li> <p>'tri_optimal_reversed': (3, 4, 7, 6, 5, 2, 2, 3, 6, 5, 4, 1), which has the X- and Z-part reversed from 'tri_optimal'.</p> </li> <li> <p>'superdense_default': (3, 1, 2, 3, 1, 2, 6, 4, 5, 6, 4, 5), which is used for superdense syndrome extraction circuits.</p> </li> </ul> <code>'tri_optimal'</code> <code>superdense_circuit</code> <code>bool</code> <p>Whether to use superdense syndrome extraction circuit. When True, the syndrome extraction follows a 4-step pattern: (1) X-type anc \u2192 Z-type anc CNOTs, (2) data \u2192 anc CNOTs with spatial routing, (3) anc \u2192 data CNOTs, (4) repeat step 1. If True and cnot_schedule is 'tri_optimal', it automatically switches to 'superdense_default'.</p> <code>False</code> <code>temp_bdry_type</code> <code>(X, Y, Z, x, y, z)</code> <p>Type of the temporal boundaries, i.e., the reset/measurement basis of data qubits at the beginning and end of the circuit. Not supported for <code>rec_stability</code> and <code>cult+growing</code> circuits: the types of the temporal boundaries are fixed to red for <code>rec_stability</code> and <code>Y</code> for <code>cult+growing</code>. For the other circuit types, it is <code>Z</code> by default.</p> <code>'X'</code> <code>noise_model</code> <code>NoiseModel</code> <p>Noise model specifying error rates for different operations. If provided, individual noise parameters (p_bitflip, p_depol, etc.) are ignored. If not provided, a NoiseModel is constructed from individual parameters.</p> <code>None</code> <code>perfect_logical_initialization</code> <code>bool</code> <p>Whether logical initialization operations (data qubit reset) are noiseless</p> <code>False</code> <code>perfect_logical_measurement</code> <code>bool</code> <p>Whether logical final measurement operations are noiseless</p> <code>False</code> <code>perfect_init_final</code> <code>bool</code> <p>If True, sets both perfect_logical_initialization and perfect_logical_measurement to True.</p> <code>False</code> <code>perfect_first_syndrome_extraction</code> <code>bool</code> <p>Whether the first syndrome extraction round is noiseless. Useful when starting from a perfect logical state (together with <code>perfect_logical_initialization=True</code>). Note: <code>rounds</code> still includes this perfect round, so set to <code>T + 1</code> where <code>T</code> is the number of actual faulty syndrome extraction rounds you want to consider.</p> <code>False</code> <code>comparative_decoding</code> <code>bool</code> <p>Whether to use the comparative decoding technique. If True, observables are included as additional detectors and decoding can be done by running the decoder for each logical class and choosing the lowest-weight one. This also provides the logical gap information, which quantifies the reliability of decoding.</p> <code>False</code> <code>exclude_non_essential_pauli_detectors</code> <code>bool</code> <p>If True and <code>temp_bdry_type</code> is not \"Y\", detectors with the Pauli type different from the temporal boundary type (e.g., X-type detectors for <code>temp_bdry_type=\"Z\"</code>) are excluded from the circuit. This does not affect the decoding results since X and Z errors are independently decoded in our method and physical errors with the same pauli type as the temporal boundaries do not affect the logical values. If <code>temp_bdry_type=\"Y\"</code> or <code>circuit_type=\"cult+growing\"</code>, both types of detectors are required for decoding, so this option is ignored.</p> <code>False</code> <code>cultivation_circuit</code> <code>Optional[Circuit]</code> <p>If given, it is used as the cultivation circuit for cultivation + growing circuit (<code>circuit_type == 'cult+growing'</code>). WARNING: Its validity is not checked internally.</p> <code>None</code> <code>remove_non_edge_like_errors</code> <code>bool</code> <p>Whether to remove error mechanisms that are not edge-like when decomposing the detector error model.</p> <code>True</code> Parameters (legacy for backward compatibility) <p>shape: str, optional     Same as <code>circuit_type</code>. If given, prioritized over <code>circuit_type</code>. p_bitflip : float, default 0     Bit-flip noise on every data qubit at the start of each round.     Ignored if noise_model is provided. p_depol : float, default 0     Depolarizing noise on every data qubit at the start of each round.     Ignored if noise_model is provided. p_reset : float, default 0     Error rate for each reset (producing an orthogonal state).     Ignored if noise_model is provided. p_meas : float, default 0     Error rate for each measurement (flipped measurement outcome).     Ignored if noise_model is provided. p_cnot : float, default 0     Two-qubit depolarizing noise rate for each CNOT gate.     Ignored if noise_model is provided. p_idle : float, default 0     Single-qubit depolarizing noise rate for each idle gate.     Ignored if noise_model is provided. p_circuit : float, optional     If given, p_reset = p_meas = p_cnot = p_idle = p_circuit.     Ignored if noise_model is provided. p_cult : float, optional     Physical error rate during cultivation (only used for 'cult+growing'     circuits). If not given, <code>p_cult = p_cnot</code> is used.     Ignored if noise_model is provided.</p> Source code in <code>src/color_code_stim/color_code.py</code> <pre><code>def __init__(\n    self,\n    *,\n    d: int,\n    rounds: int,\n    circuit_type: str = \"tri\",\n    d2: int = None,\n    cnot_schedule: Union[str, List[int]] = \"tri_optimal\",\n    superdense_circuit: bool = False,\n    temp_bdry_type: Optional[Literal[\"X\", \"Y\", \"Z\", \"x\", \"y\", \"z\"]] = None,\n    noise_model: Optional[NoiseModel] = None,\n    perfect_logical_initialization: bool = False,\n    perfect_logical_measurement: bool = False,\n    perfect_init_final: bool = False,\n    perfect_first_syndrome_extraction: bool = False,\n    comparative_decoding: bool = False,\n    exclude_non_essential_pauli_detectors: bool = False,\n    cultivation_circuit: Optional[stim.Circuit] = None,\n    remove_non_edge_like_errors: bool = True,\n    shape: str = None,\n    p_bitflip: float = 0.0,\n    p_depol: float = 0.0,\n    p_reset: float = 0.0,\n    p_meas: float = 0.0,\n    p_cnot: float = 0.0,\n    p_idle: float = 0.0,\n    p_circuit: Optional[float] = None,\n    p_cult: Optional[float] = None,\n    _generate_dem: bool = True,\n    _decompose_dem: bool = True,\n    _benchmarking: bool = False,\n):\n    \"\"\"\n    Class for constructing a color code circuit and simulating the\n    concatenated MWPM decoder.\n\n    Examples\n    --------\n    Triangular patch with uniform circuit-level noise of 1e-3:\n\n    &gt;&gt;&gt; from color_code_stim import ColorCode, NoiseModel\n    &gt;&gt;&gt; noise = NoiseModel.uniform_circuit_noise(1e-3)\n    &gt;&gt;&gt; colorcode = ColorCode(d=5, rounds=5, circuit_type=\"tri\", noise_model=noise)\n    &gt;&gt;&gt; num_fails, info = colorcode.simulate(shots=10000, full_output=True)\n\n    See `getting_started.ipynb` for more detailed usage.\n\n    Parameters\n    ----------\n    d : int &gt;= 3\n        Code distance.\n\n    rounds : int &gt;= 1\n        Number of syndrome extraction rounds.\n\n    circuit_type : {'triangle', 'tri', 'rectangle', 'rec', 'rec_stability', 'growing', 'cult+growing'}, default 'tri'\n        Circuit type.\n\n        - 'triangle'/'tri': memory experiment of a triangular patch with distance\n          `d`.\n\n        - 'rectangle'/'rec': memory experiment of a rectangular patch with distance\n          `d` and `d2`.\n\n        - 'rec_stability': stability experiment of a rectangle-like patch with\n          single-type boundaries. `d` and `d2` indicate the size of the patch,\n          rather than code distances.\n\n        - 'growing': growing operation from a triangular patch with distance `d` to\n          a larger triangular patch with distance `d2`. Must be `d2 &gt; d`.\n\n        - 'cult+growing': cultivation on a triangular patch with distance `d`,\n          followed by a growing operation to distance `d2`. Must be `d2 &gt; d`.\n\n    d2 : int &gt;= 3, optional\n        Second code distance required for circuit types 'rec'/'rectangle', 'growing',\n        and 'cult+growing'. If not provided, `d2 = d` is used.\n\n    cnot_schedule : {'tri_optimal', 'tri_optimal_reversed', 'superdense_default'} or list of 12 integers,\n                    default 'tri_optimal'\n        CNOT schedule.\n\n        - List of 12 integers: (a, b, ... l) specifying the CNOT schedule.\n\n        - 'tri_optimal': (2, 3, 6, 5, 4, 1, 3, 4, 7, 6, 5, 2), which is the optimal\n        schedule for the triangular color code.\n\n        - 'tri_optimal_reversed': (3, 4, 7, 6, 5, 2, 2, 3, 6, 5, 4, 1),\n        which has the X- and Z-part reversed from 'tri_optimal'.\n\n        - 'superdense_default': (3, 1, 2, 3, 1, 2, 6, 4, 5, 6, 4, 5),\n        which is used for superdense syndrome extraction circuits.\n\n    superdense_circuit : bool, default False\n        Whether to use superdense syndrome extraction circuit. When True, the syndrome\n        extraction follows a 4-step pattern: (1) X-type anc \u2192 Z-type anc CNOTs,\n        (2) data \u2192 anc CNOTs with spatial routing, (3) anc \u2192 data CNOTs, (4) repeat step 1.\n        If True and cnot_schedule is 'tri_optimal', it automatically switches to\n        'superdense_default'.\n\n    temp_bdry_type : {'X', 'Y', 'Z', 'x', 'y', 'z'}, optional\n        Type of the temporal boundaries, i.e., the reset/measurement basis of\n        data qubits at the beginning and end of the circuit.\n        Not supported for `rec_stability` and `cult+growing` circuits: the types of\n        the temporal boundaries are fixed to red for `rec_stability` and `Y` for\n        `cult+growing`. For the other circuit types, it is `Z` by default.\n\n    noise_model : NoiseModel, optional\n        Noise model specifying error rates for different operations. If provided,\n        individual noise parameters (p_bitflip, p_depol, etc.) are ignored.\n        If not provided, a NoiseModel is constructed from individual parameters.\n\n    perfect_logical_initialization : bool, default False\n        Whether logical initialization operations (data qubit reset) are noiseless\n    perfect_logical_measurement : bool, default False\n        Whether logical final measurement operations are noiseless\n    perfect_init_final : bool, default False\n        If True, sets both perfect_logical_initialization and perfect_logical_measurement\n        to True.\n    perfect_first_syndrome_extraction : bool, default False\n        Whether the first syndrome extraction round is noiseless. Useful when\n        starting from a perfect logical state (together with\n        `perfect_logical_initialization=True`).\n        *Note:* `rounds` still includes this perfect round, so set to `T + 1` where\n        `T` is the number of actual faulty syndrome extraction rounds you want to consider.\n    comparative_decoding : bool, default False\n        Whether to use the comparative decoding technique. If True, observables are\n        included as additional detectors and decoding can be done by running the\n        decoder for each logical class and choosing the lowest-weight one. This also\n        provides the logical gap information, which quantifies the reliability of\n        decoding.\n    exclude_non_essential_pauli_detectors : bool, default False\n        If True and `temp_bdry_type` is not \"Y\", detectors with the Pauli type\n        different from the temporal boundary type (e.g., X-type detectors for\n        `temp_bdry_type=\"Z\"`) are excluded from the circuit. This does not affect the\n        decoding results since X and Z errors are independently decoded in our method\n        and physical errors with the same pauli type as the temporal boundaries do\n        not affect the logical values. If `temp_bdry_type=\"Y\"` or\n        `circuit_type=\"cult+growing\"`, both types of detectors are required for decoding,\n        so this option is ignored.\n    cultivation_circuit: stim.Circuit, optional\n        If given, it is used as the cultivation circuit for cultivation + growing\n        circuit (`circuit_type == 'cult+growing'`). WARNING: Its validity is not\n        checked internally.\n    remove_non_edge_like_errors: bool, default True\n        Whether to remove error mechanisms that are not edge-like when decomposing\n        the detector error model.\n\n    Parameters (legacy for backward compatibility)\n    ----------\n    shape: str, optional\n        Same as `circuit_type`. If given, prioritized over `circuit_type`.\n    p_bitflip : float, default 0\n        Bit-flip noise on every data qubit at the start of each round.\n        Ignored if noise_model is provided.\n    p_depol : float, default 0\n        Depolarizing noise on every data qubit at the start of each round.\n        Ignored if noise_model is provided.\n    p_reset : float, default 0\n        Error rate for each reset (producing an orthogonal state).\n        Ignored if noise_model is provided.\n    p_meas : float, default 0\n        Error rate for each measurement (flipped measurement outcome).\n        Ignored if noise_model is provided.\n    p_cnot : float, default 0\n        Two-qubit depolarizing noise rate for each CNOT gate.\n        Ignored if noise_model is provided.\n    p_idle : float, default 0\n        Single-qubit depolarizing noise rate for each idle gate.\n        Ignored if noise_model is provided.\n    p_circuit : float, optional\n        If given, p_reset = p_meas = p_cnot = p_idle = p_circuit.\n        Ignored if noise_model is provided.\n    p_cult : float, optional\n        Physical error rate during cultivation (only used for 'cult+growing'\n        circuits). If not given, `p_cult = p_cnot` is used.\n        Ignored if noise_model is provided.\n\n    \"\"\"\n    # Automatic cnot_schedule selection for superdense circuits\n    if superdense_circuit and cnot_schedule == \"tri_optimal\":\n        cnot_schedule = \"superdense_default\"\n\n    if isinstance(cnot_schedule, str):\n        if cnot_schedule in CNOT_SCHEDULES:\n            cnot_schedule = CNOT_SCHEDULES[cnot_schedule]\n        else:\n            raise ValueError(f\"Invalid cnot schedule: {cnot_schedule}\")\n    else:\n        cnot_schedule = list(cnot_schedule)\n        assert len(cnot_schedule) == 12\n\n    assert d &gt; 1 and rounds &gt;= 1\n\n    # Handle noise model: use provided NoiseModel or create from individual parameters\n    if noise_model is not None:\n        # Use provided NoiseModel\n        self.noise_model = noise_model\n    else:\n        # Create NoiseModel from individual parameters\n        if p_circuit is not None:\n            p_reset = p_meas = p_cnot = p_idle = p_circuit\n\n        # For cult+growing, validate requirements\n        if circuit_type in {\"cultivation+growing\", \"cult+growing\"}:\n            if p_circuit is None:\n                raise ValueError(\n                    \"p_circuit must be provided for cult+growing circuit type\"\n                )\n            if p_bitflip &gt; 0:\n                raise ValueError(\n                    \"p_bitflip must be 0 for cult+growing circuit type\"\n                )\n\n        # Create NoiseModel from individual parameters\n        self.noise_model = NoiseModel(\n            bitflip=p_bitflip,\n            depol=p_depol,\n            reset=p_reset,\n            meas=p_meas,\n            cnot=p_cnot,\n            idle=p_idle,\n            cult=p_cult,\n        )\n\n    self.d = d\n    d2 = self.d2 = d if d2 is None else d2\n    self.rounds = rounds\n\n    if shape is not None:\n        circuit_type = shape\n\n    if circuit_type in {\"triangle\", \"tri\"}:\n        assert d % 2 == 1\n        self.circuit_type = \"tri\"\n        self.num_obs = 1\n\n    elif circuit_type in {\"rectangle\", \"rec\"}:\n        assert d2 is not None\n        assert d % 2 == 0 and d2 % 2 == 0\n        self.circuit_type = \"rec\"\n        self.num_obs = 2\n\n    elif circuit_type == \"rec_stability\":\n        assert d2 is not None\n        assert d % 2 == 0 and d2 % 2 == 0\n        self.circuit_type = \"rec_stability\"\n        self.num_obs = 2\n\n    elif circuit_type == \"growing\":\n        assert d2 is not None\n        assert d % 2 == 1 and d2 % 2 == 1 and d2 &gt; d\n        self.circuit_type = \"growing\"\n        self.num_obs = 1\n\n    elif circuit_type in {\"cultivation+growing\", \"cult+growing\"}:\n        assert d2 is not None\n        assert d % 2 == 1 and d2 % 2 == 1 and d2 &gt; d\n        self.circuit_type = \"cult+growing\"\n        self.num_obs = 1\n\n    else:\n        raise ValueError(f\"Invalid circuit type: {circuit_type}\")\n\n    if temp_bdry_type is None:\n        if circuit_type == \"rec_stability\":\n            temp_bdry_type = \"r\"\n        elif circuit_type == \"cult+growing\":\n            temp_bdry_type = \"Y\"\n        else:\n            temp_bdry_type = \"Z\"\n    else:\n        assert temp_bdry_type in {\"X\", \"Y\", \"Z\", \"x\", \"y\", \"z\"}\n        assert circuit_type not in {\"rec_stability\", \"cult+growing\"}\n        temp_bdry_type = temp_bdry_type.upper()\n\n    self.temp_bdry_type = temp_bdry_type\n\n    if circuit_type == \"rec_stability\":\n        self.obs_paulis = [\"Z\", \"X\"]\n    else:\n        self.obs_paulis = [temp_bdry_type] * self.num_obs\n\n    self.cnot_schedule = cnot_schedule\n    self.superdense_circuit = superdense_circuit\n    self.perfect_init_final = perfect_init_final\n\n    # Handle backward compatibility: perfect_init_final sets both initialization and measurement\n    if perfect_init_final:\n        perfect_logical_initialization = True\n        perfect_logical_measurement = True\n\n    self.perfect_logical_initialization = perfect_logical_initialization\n    self.perfect_logical_measurement = perfect_logical_measurement\n    self.perfect_first_syndrome_extraction = perfect_first_syndrome_extraction\n\n    self.comparative_decoding = comparative_decoding\n\n    self.exclude_non_essential_pauli_detectors = (\n        exclude_non_essential_pauli_detectors\n    )\n\n    self.remove_non_edge_like_errors = remove_non_edge_like_errors\n\n    if self.comparative_decoding and self.circuit_type == \"rec_stability\":\n        raise NotImplementedError\n\n    if self.circuit_type == \"cult+growing\":\n        if cultivation_circuit is None:\n            cultivation_circuit = _load_cultivation_circuit(\n                d=d, p=self.noise_model[\"cult\"]\n            )\n\n    else:\n        cultivation_circuit = None\n    self.cultivation_circuit = cultivation_circuit\n\n    self._benchmarking = _benchmarking\n\n    # Build Tanner graph using TannerGraphBuilder\n    graph_builder = TannerGraphBuilder(\n        circuit_type=self.circuit_type,\n        d=self.d,\n        d2=self.d2,\n    )\n    self.tanner_graph, self.qubit_groups = graph_builder.build()\n\n    # Generate circuit using CircuitBuilder\n    builder = CircuitBuilder(\n        d=self.d,\n        d2=self.d2,\n        rounds=self.rounds,\n        circuit_type=self.circuit_type,\n        cnot_schedule=self.cnot_schedule,\n        superdense_circuit=self.superdense_circuit,\n        temp_bdry_type=self.temp_bdry_type,\n        noise_model=self.noise_model,\n        perfect_init_final=self.perfect_init_final,\n        perfect_logical_initialization=self.perfect_logical_initialization,\n        perfect_logical_measurement=self.perfect_logical_measurement,\n        perfect_first_syndrome_extraction=self.perfect_first_syndrome_extraction,\n        tanner_graph=self.tanner_graph,\n        qubit_groups=self.qubit_groups,\n        exclude_non_essential_pauli_detectors=self.exclude_non_essential_pauli_detectors,\n        cultivation_circuit=self.cultivation_circuit,\n        comparative_decoding=self.comparative_decoding,\n    )\n    self.circuit = builder.build()\n\n    # Initialize DEM manager (lazy loading)\n    self._dem_manager = None\n    self._generate_dem = _generate_dem\n    self._decompose_dem = _decompose_dem\n\n    # Initialize decoders (lazy loading)\n    self._concat_matching_decoder = None\n    self._bp_decoder = None\n    self._belief_concat_matching_decoder = None\n    self._simulator = None\n\n    self._bp_inputs = {}\n</code></pre>"},{"location":"api/color_code/#color_code_stim.ColorCode.decode","title":"<code>decode(detector_outcomes, colors='all', logical_value=None, bp_predecoding=False, bp_prms=None, erasure_matcher_predecoding=False, partial_correction_by_predecoding=False, full_output=False, check_validity=False, verbose=False)</code>","text":"<p>Decode detector outcomes using concatenated MWPM decoding.</p> <p>This method delegates to the ConcatMatchingDecoder while preserving backward compatibility and handling BP pre-decoding integration.</p> <p>Parameters:</p> Name Type Description Default <code>detector_outcomes</code> <code>1D or 2D array-like of bool</code> <p>Array of input detector outcomes for one or multiple samples. If 1D, it is interpreted as a single sample. If 2D, each row corresponds to a sample and each column corresponds to a detector. detector_outcomes[i, j] is True if and only if the detector with id j in the ith sample has the outcome \u22121.</p> required <code>colors</code> <code>str or list of str</code> <p>Colors to use for decoding. Can be 'all', one of {'r', 'g', 'b'}, or a list containing any combination of {'r', 'g', 'b'}.</p> <code>'all'</code> <code>logical_value</code> <code>bool or 1D array-like of bool</code> <p>Logical value(s) to use for decoding. If None, all possible logical value combinations (i.e., logical classes) will be tried and the one with minimum weight will be selected.</p> <code>None</code> <code>bp_predecoding</code> <code>bool</code> <p>Whether to use belief propagation as a pre-decoding step.</p> <code>False</code> <code>bp_prms</code> <code>dict</code> <p>Parameters for the belief propagation decoder.</p> <code>None</code> <code>erasure_matcher_predecoding</code> <code>bool</code> <p>Whether to use erasure matcher as a pre-decoding step.</p> <code>False</code> <code>partial_correction_by_predecoding</code> <code>bool</code> <p>Whether to use the prediction from the erasure matcher predecoding as a partial correction for the second round of decoding, in the case that the predecoding fails to find a valid prediction.</p> <code>False</code> <code>full_output</code> <code>bool</code> <p>Whether to return extra information about the decoding process.</p> <code>False</code> <code>check_validity</code> <code>bool</code> <p>Whether to check the validity of the predicted error patterns.</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>Whether to print additional information during decoding.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>obs_preds</code> <code>1D or 2D numpy array of bool</code> <p>Predicted observables. It is 1D if there is only one observable and 2D if otherwise. obs_preds[i] or obs_preds[i,j] is True if and only if the j-th observable (j=0 when 1D) of the i-th sample is predicted to be -1.</p> <code>extra_outputs</code> <code>dict, only when full_output is True</code> <p>Dictionary containing additional decoding outputs.</p> Source code in <code>src/color_code_stim/color_code.py</code> <pre><code>def decode(\n    self,\n    detector_outcomes: np.ndarray,\n    colors: str | List[str] = \"all\",\n    logical_value: bool | Sequence[bool] | None = None,\n    bp_predecoding: bool = False,\n    bp_prms: dict | None = None,\n    erasure_matcher_predecoding: bool = False,\n    partial_correction_by_predecoding: bool = False,\n    full_output: bool = False,\n    check_validity: bool = False,\n    verbose: bool = False,\n) -&gt; np.ndarray | Tuple[np.ndarray, dict]:\n    \"\"\"\n    Decode detector outcomes using concatenated MWPM decoding.\n\n    This method delegates to the ConcatMatchingDecoder while preserving backward\n    compatibility and handling BP pre-decoding integration.\n\n    Parameters\n    ----------\n    detector_outcomes : 1D or 2D array-like of bool\n        Array of input detector outcomes for one or multiple samples.\n        If 1D, it is interpreted as a single sample.\n        If 2D, each row corresponds to a sample and each column corresponds to a\n        detector. detector_outcomes[i, j] is True if and only if the detector with\n        id j in the ith sample has the outcome \u22121.\n    colors : str or list of str, default 'all'\n        Colors to use for decoding. Can be 'all', one of {'r', 'g', 'b'},\n        or a list containing any combination of {'r', 'g', 'b'}.\n    logical_value : bool or 1D array-like of bool, optional\n        Logical value(s) to use for decoding. If None, all possible logical value\n        combinations (i.e., logical classes) will be tried and the one with minimum\n        weight will be selected.\n    bp_predecoding : bool, default False\n        Whether to use belief propagation as a pre-decoding step.\n    bp_prms : dict, default None\n        Parameters for the belief propagation decoder.\n    erasure_matcher_predecoding : bool, default False\n        Whether to use erasure matcher as a pre-decoding step.\n    partial_correction_by_predecoding : bool, default False\n        Whether to use the prediction from the erasure matcher predecoding as a\n        partial correction for the second round of decoding, in the case that the predecoding fails to find a valid prediction.\n    full_output : bool, default False\n        Whether to return extra information about the decoding process.\n    check_validity : bool, default False\n        Whether to check the validity of the predicted error patterns.\n    verbose : bool, default False\n        Whether to print additional information during decoding.\n\n    Returns\n    -------\n    obs_preds : 1D or 2D numpy array of bool\n        Predicted observables. It is 1D if there is only one observable and\n        2D if otherwise. obs_preds[i] or obs_preds[i,j] is True if and only\n        if the j-th observable (j=0 when 1D) of the i-th sample is\n        predicted to be -1.\n    extra_outputs : dict, only when full_output is True\n        Dictionary containing additional decoding outputs.\n    \"\"\"\n    # Handle BP pre-decoding by delegating to BeliefConcatMatchingDecoder\n    if bp_predecoding:\n        return self.belief_concat_matching_decoder.decode(\n            detector_outcomes=detector_outcomes,\n            colors=colors,\n            logical_value=logical_value,\n            bp_prms=bp_prms,\n            erasure_matcher_predecoding=erasure_matcher_predecoding,\n            partial_correction_by_predecoding=partial_correction_by_predecoding,\n            full_output=full_output,\n            check_validity=check_validity,\n            verbose=verbose,\n        )\n\n    # Delegate to ConcatMatchingDecoder for standard decoding\n    return self.concat_matching_decoder.decode(\n        detector_outcomes=detector_outcomes,\n        colors=colors,\n        logical_value=logical_value,\n        erasure_matcher_predecoding=erasure_matcher_predecoding,\n        partial_correction_by_predecoding=partial_correction_by_predecoding,\n        full_output=full_output,\n        check_validity=check_validity,\n        verbose=verbose,\n    )\n</code></pre>"},{"location":"api/color_code/#color_code_stim.ColorCode.decode_bp","title":"<code>decode_bp(detector_outcomes, max_iter=10, **kwargs)</code>","text":"<p>Decode detector outcomes using belief propagation.</p> <p>This method delegates to the BPDecoder while maintaining backward compatibility with the _bp_inputs caching mechanism for integration with pre-decoding.</p> <p>Parameters:</p> Name Type Description Default <code>detector_outcomes</code> <code>ndarray</code> <p>1D or 2D array of detector measurement outcomes to decode.</p> required <code>max_iter</code> <code>int</code> <p>Maximum number of belief propagation iterations to perform.</p> <code>10</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the BpDecoder constructor.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>pred</code> <code>ndarray</code> <p>Predicted error pattern.</p> <code>llrs</code> <code>ndarray</code> <p>Log probability ratios for each bit in the predicted error pattern.</p> <code>converge</code> <code>bool</code> <p>Whether the belief propagation algorithm converged within max_iter iterations.</p> Source code in <code>src/color_code_stim/color_code.py</code> <pre><code>def decode_bp(\n    self,\n    detector_outcomes: np.ndarray,\n    max_iter: int = 10,\n    **kwargs,\n):\n    \"\"\"\n    Decode detector outcomes using belief propagation.\n\n    This method delegates to the BPDecoder while maintaining backward compatibility\n    with the _bp_inputs caching mechanism for integration with pre-decoding.\n\n    Parameters\n    ----------\n    detector_outcomes : np.ndarray\n        1D or 2D array of detector measurement outcomes to decode.\n    max_iter : int\n        Maximum number of belief propagation iterations to perform.\n    **kwargs\n        Additional keyword arguments to pass to the BpDecoder constructor.\n\n    Returns\n    -------\n    pred : np.ndarray\n        Predicted error pattern.\n    llrs : np.ndarray\n        Log probability ratios for each bit in the predicted error pattern.\n    converge : bool\n        Whether the belief propagation algorithm converged within max_iter iterations.\n    \"\"\"\n    # Update _bp_inputs cache for compatibility with pre-decoding integration\n    if not self._bp_inputs:\n        if self.comparative_decoding:\n            dem = remove_obs_from_dem(self.dem_xz)\n        else:\n            dem = self.dem_xz\n        H, p = dem_to_parity_check(dem)\n        self._bp_inputs[\"H\"] = H\n        self._bp_inputs[\"p\"] = p\n\n    # Delegate to BP decoder\n    return self.bp_decoder.decode(detector_outcomes, max_iter=max_iter, **kwargs)\n</code></pre>"},{"location":"api/color_code/#color_code_stim.ColorCode.draw_lattice","title":"<code>draw_lattice(ax=None, show_axes=False, highlight_qubits=None, highlight_qubits2=None, highlight_faces=None, **kwargs)</code>","text":"<p>Draws the color code lattice.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>The axis on which to draw the graph. If None, a new figure and axis will be created.</p> <code>None</code> <code>show_axes</code> <code>bool</code> <p>Whether to show the x- and y-axis.</p> <code>False</code> <code>highlight_qubits</code> <code>list[int] | list[tuple] | list[str] | ndarray</code> <p>Data qubits to highlight with orange triangles (by default). Can be a list of data qubit indices (ordered by code.vs.select(pauli=None)), a list of coordinate tuples [(x, y), ...], or a list of qubit names ['x-y', ...].</p> <code>None</code> <code>highlight_qubits2</code> <code>list[int] | list[tuple] | list[str] | ndarray</code> <p>Data qubits to highlight with purple rectangles (by default). Format is the same as highlight_qubits.</p> <code>None</code> <code>highlight_faces</code> <code>list[int] | list[tuple] | list[str] | ndarray</code> <p>Z ancillary qubits whose corresponding faces should be highlighted. Can be a list of Z ancillary qubit indices (ordered by code.vs.select(pauli=\"Z\")), a list of coordinate tuples [(x, y), ...], or a list of qubit names ['x-y', ...]. Note that for names, the actual stored name includes a '-Z' suffix.</p> <code>None</code> <code>edge_color</code> <code>str</code> <p>Colors for edges.</p> <code>'black'</code> <code>edge_linewidth</code> <code>float</code> <p>Linewidth for edges.</p> <code>1.0</code> <code>face_lightness</code> <code>float</code> <p>Controls the lightness of face colors. Lower values make colors lighter.</p> <code>0.3</code> <code>show_data_qubits</code> <code>bool</code> <p>Whether to draw circles representing data qubits.</p> <code>True</code> <code>data_qubit_color</code> <code>str</code> <p>Color for the data qubit circles (if shown).</p> <code>'black'</code> <code>data_qubit_size</code> <code>float</code> <p>Size for the data qubit circles (if shown).</p> <code>5.0</code> <code>highlight_qubit_color</code> <code>str</code> <p>The color used to highlight qubits in <code>highlight_qubits</code>.</p> <code>'orange'</code> <code>highlight_qubit_color2</code> <code>str</code> <p>The color used to highlight qubits in <code>highlight_qubits2</code>.</p> <code>'purple'</code> <code>highlight_qubit_marker</code> <code>str</code> <p>The marker used to highlight qubits in <code>highlight_qubits</code>.</p> <code>'^' (triangle)</code> <code>highlight_qubit_marker2</code> <code>str</code> <p>The marker used to highlight qubits in <code>highlight_qubits2</code>.</p> <code>'s' (square)</code> <code>highlight_face_lightness</code> <code>float</code> <p>Controls the lightness of the highlighted faces.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The axis containing the drawn lattice visualization.</p> Source code in <code>src/color_code_stim/color_code.py</code> <pre><code>def draw_lattice(\n    self,\n    ax: Optional[plt.Axes] = None,\n    show_axes: bool = False,\n    highlight_qubits: Optional[\n        List[int] | List[Tuple[float, float]] | List[str] | np.ndarray\n    ] = None,\n    highlight_qubits2: Optional[\n        List[int] | List[Tuple[float, float]] | List[str] | np.ndarray\n    ] = None,\n    highlight_faces: Optional[\n        List[int] | List[Tuple[float, float]] | List[str] | np.ndarray\n    ] = None,\n    **kwargs,\n) -&gt; plt.Axes:\n    \"\"\"\n    Draws the color code lattice.\n\n    Parameters\n    ----------\n    ax : matplotlib.axes.Axes, optional\n        The axis on which to draw the graph. If None, a new figure and\n        axis will be created.\n    show_axes : bool, default False\n        Whether to show the x- and y-axis.\n    highlight_qubits : list[int] | list[tuple] | list[str] | np.ndarray, optional\n        Data qubits to highlight with orange triangles (by default).\n        Can be a list of data qubit indices (ordered by code.vs.select(pauli=None)),\n        a list of coordinate tuples [(x, y), ...], or a list of qubit names ['x-y', ...].\n    highlight_qubits2 : list[int] | list[tuple] | list[str] | np.ndarray, optional\n        Data qubits to highlight with purple rectangles (by default).\n        Format is the same as highlight_qubits.\n    highlight_faces : list[int] | list[tuple] | list[str] | np.ndarray, optional\n        Z ancillary qubits whose corresponding faces should be highlighted.\n        Can be a list of Z ancillary qubit indices (ordered by code.vs.select(pauli=\"Z\")),\n        a list of coordinate tuples [(x, y), ...], or a list of qubit names ['x-y', ...].\n        Note that for names, the actual stored name includes a '-Z' suffix.\n    edge_color : str, default 'black'\n        Colors for edges.\n    edge_linewidth : float, default 1.0\n        Linewidth for edges.\n    face_lightness : float, default 0.3\n        Controls the lightness of face colors. Lower values make colors lighter.\n    show_data_qubits : bool, default True\n        Whether to draw circles representing data qubits.\n    data_qubit_color : str, default 'black'\n        Color for the data qubit circles (if shown).\n    data_qubit_size : float, default 5.0\n        Size for the data qubit circles (if shown).\n    highlight_qubit_color : str, default 'orange'\n        The color used to highlight qubits in `highlight_qubits`.\n    highlight_qubit_color2 : str, default 'purple'\n        The color used to highlight qubits in `highlight_qubits2`.\n    highlight_qubit_marker : str, default '^' (triangle)\n        The marker used to highlight qubits in `highlight_qubits`.\n    highlight_qubit_marker2 : str, default 's' (square)\n        The marker used to highlight qubits in `highlight_qubits2`.\n    highlight_face_lightness : float, default 1.0\n        Controls the lightness of the highlighted faces.\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The axis containing the drawn lattice visualization.\n    \"\"\"\n    return draw_lattice(\n        self,\n        ax=ax,\n        show_axes=show_axes,\n        highlight_qubits=highlight_qubits,\n        highlight_qubits2=highlight_qubits2,\n        highlight_faces=highlight_faces,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/color_code/#color_code_stim.ColorCode.draw_tanner_graph","title":"<code>draw_tanner_graph(ax=None, show_axes=False, show_lattice=False, **kwargs)</code>","text":"<p>Draw the tanner graph of the code.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>The axis on which to draw the graph. If None, a new figure and axis will be created.</p> <code>None</code> <code>show_axes</code> <code>bool</code> <p>Whether to show the x- and y-axis.</p> <code>False</code> <code>show_lattice</code> <code>bool</code> <p>Whether to show the lattice edges in addition to the tanner graph edges.</p> <code>False</code> <code>**kwargs</code> <code>dict</code> <p>Additional keyword arguments to pass to igraph.plot.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The axis containing the drawn graph.</p> Source code in <code>src/color_code_stim/color_code.py</code> <pre><code>def draw_tanner_graph(\n    self,\n    ax: Optional[plt.Axes] = None,\n    show_axes: bool = False,\n    show_lattice: bool = False,\n    **kwargs,\n) -&gt; plt.Axes:\n    \"\"\"\n    Draw the tanner graph of the code.\n\n    Parameters\n    ----------\n    ax : matplotlib.axes.Axes, optional\n        The axis on which to draw the graph. If None, a new figure and axis will be created.\n    show_axes : bool, default False\n        Whether to show the x- and y-axis.\n    show_lattice : bool, default False\n        Whether to show the lattice edges in addition to the tanner graph edges.\n    **kwargs : dict\n        Additional keyword arguments to pass to igraph.plot.\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The axis containing the drawn graph.\n    \"\"\"\n    return draw_tanner_graph(\n        self,\n        ax=ax,\n        show_axes=show_axes,\n        show_lattice=show_lattice,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/color_code/#color_code_stim.ColorCode.errors_to_qubits","title":"<code>errors_to_qubits(errors)</code>","text":"<p>Convert errors (generated by <code>sample_with_errors</code>) or error predictions (generated by decoders) into the corresponding data qubit indices.</p> <p>Available only for <code>tri</code> and <code>rec</code> circuit types with <code>rounds=1</code> under bit-flip noise (i.e., probabilities besides <code>p_bitflip</code> are 0).</p> <p>Note: Errors and error predictions from <code>sample_with_errors</code> or decoders follow the ordering of error mechanisms in the circuit's detector error model (<code>circuit.detector_error_model()</code>). This function is necessary because this ordering differs from the data qubit ordering in the tanner graph (<code>tanner_graph.vs.select(pauli=None)</code>). This conversion is especially helpful when visualizing errors or error predictions on the lattice.</p> <p>Parameters:</p> Name Type Description Default <code>errors</code> <code>2D numpy array of bool</code> <p>Errors following the ordering of error mechanisms in the DEM of the circuit <code>circuit.detector_error_model()</code>.</p> required <p>Returns:</p> Name Type Description <code>errors_qubits</code> <code>2D numpy array of bool</code> <p>Errors following the ordering of data qubits in the tanner graph <code>tanner_graph.vs.select(pauli=None)</code>.</p> Source code in <code>src/color_code_stim/color_code.py</code> <pre><code>def errors_to_qubits(\n    self,\n    errors: np.ndarray,\n) -&gt; np.ndarray:\n    \"\"\"\n    Convert errors (generated by `sample_with_errors`) or error predictions\n    (generated by decoders) into the corresponding data qubit indices.\n\n    Available only for `tri` and `rec` circuit types with `rounds=1` under\n    bit-flip noise (i.e., probabilities besides `p_bitflip` are 0).\n\n    Note: Errors and error predictions from `sample_with_errors` or decoders\n    follow the ordering of error mechanisms in the circuit's detector error model\n    (`circuit.detector_error_model()`). This function is necessary because this\n    ordering differs from the data qubit ordering in the tanner graph\n    (`tanner_graph.vs.select(pauli=None)`). This conversion is especially helpful\n    when visualizing errors or error predictions on the lattice.\n\n    Parameters\n    ----------\n    errors : 2D numpy array of bool\n        Errors following the ordering of error mechanisms in the DEM of the circuit\n        `circuit.detector_error_model()`.\n\n    Returns\n    -------\n    errors_qubits : 2D numpy array of bool\n        Errors following the ordering of data qubits in the tanner graph\n        `tanner_graph.vs.select(pauli=None)`.\n    \"\"\"\n\n    if self.circuit_type not in {\"tri\", \"rec\"}:\n        raise NotImplementedError(\n            f'errors_to_qubits is not available for \"{self.circuit_type}\" circuit type.'\n        )\n\n    if self.rounds != 1:\n        raise NotImplementedError(\n            \"errors_to_qubits is only available when rounds = 1.\"\n        )\n\n    if any(prob &gt; 0 for key, prob in self.noise_model.items() if key != \"bitflip\"):\n        raise NotImplementedError(\n            \"errors_to_qubits is only available under bit-flip noise \"\n            \"(only p_bitflip is nonzero).\"\n        )\n\n    # set of ancillary qubits - data qubit mapping\n    anc_qids_to_data_qubit_idx = {}\n    data_qubits = self.tanner_graph.vs.select(pauli=None)\n    for i_dq, data_qubit in enumerate(data_qubits):\n        data_qubit: ig.Vertex\n        connected_anc_qubits = data_qubit.neighbors()\n        connected_anc_qubits = [\n            q for q in connected_anc_qubits if q[\"pauli\"] == \"Z\"\n        ]\n        key = frozenset(q.index for q in connected_anc_qubits)\n        assert key not in anc_qids_to_data_qubit_idx\n        anc_qids_to_data_qubit_idx[key] = i_dq\n\n    # data qubit mapping - error mechanism in DEM\n    dem = self.circuit.detector_error_model()\n    data_qubit_idx_to_em = np.full(len(data_qubits), -1, dtype=\"int32\")\n    for i_em, em in enumerate(dem):\n        if em.type == \"error\":\n            det_ids = [\n                int(str(target)[1:])\n                for target in em.targets_copy()\n                if target.is_relative_detector_id()\n            ]\n            anc_qids = [\n                self.get_detector(det_id)[0].index\n                for det_id in det_ids\n                if det_id &lt; len(self.detectors_checks_map)\n            ]\n            anc_qids = frozenset(anc_qids)\n            data_qubit_idx = anc_qids_to_data_qubit_idx[anc_qids]\n            if data_qubit_idx_to_em[data_qubit_idx] != -1:\n                raise ValueError(\n                    f\"Data qubit {data_qubit_idx} is mapped to multiple error mechanisms: {data_qubit_idx_to_em[data_qubit_idx]} and {i_em}\"\n                )\n            data_qubit_idx_to_em[data_qubit_idx] = i_em\n    assert np.all(data_qubit_idx_to_em != -1)\n\n    return errors[..., data_qubit_idx_to_em]\n</code></pre>"},{"location":"api/color_code/#color_code_stim.ColorCode.get_decomposed_dems","title":"<code>get_decomposed_dems(color)</code>","text":"<p>Delegate to DEM manager.</p> Source code in <code>src/color_code_stim/color_code.py</code> <pre><code>def get_decomposed_dems(\n    self, color: COLOR_LABEL\n) -&gt; Tuple[stim.DetectorErrorModel, stim.DetectorErrorModel]:\n    \"\"\"Delegate to DEM manager.\"\"\"\n    return self.dem_manager.get_decomposed_dems(color)\n</code></pre>"},{"location":"api/color_code/#color_code_stim.ColorCode.get_detector","title":"<code>get_detector(detector_id)</code>","text":"<p>Get the ancillary qubit and round corresponding to a detector from a given detector ID.</p> <p>Parameters:</p> Name Type Description Default <code>detector_id</code> <code>int</code> <p>Detector ID.</p> required <p>Returns:</p> Name Type Description <code>anc</code> <code>Vertex</code> <p>Ancillary qubit involved in the detector.</p> <code>round</code> <code>int</code> <p>Round that the detector belongs to.</p> Source code in <code>src/color_code_stim/color_code.py</code> <pre><code>def get_detector(self, detector_id: int) -&gt; Tuple[ig.Vertex, int]:\n    \"\"\"\n    Get the ancillary qubit and round corresponding to a detector from a\n    given detector ID.\n\n    Parameters\n    ----------\n    detector_id : int\n        Detector ID.\n\n    Returns\n    -------\n    anc : ig.Vertex\n        Ancillary qubit involved in the detector.\n    round : int\n        Round that the detector belongs to.\n    \"\"\"\n    try:\n        return self.detectors_checks_map[detector_id]\n    except IndexError:\n        raise ValueError(f\"Detector ID {detector_id} not found.\")\n</code></pre>"},{"location":"api/color_code/#color_code_stim.ColorCode.get_detector_type","title":"<code>get_detector_type(detector_id)</code>","text":"<p>Get the Pauli and color type of a detector.</p> <p>Parameters:</p> Name Type Description Default <code>detector_id</code> <code>int</code> <p>Detector ID to query</p> required <p>Returns:</p> Name Type Description <code>pauli</code> <code>PAULI_LABEL</code> <p>Pauli type of the detector ('X', 'Y', or 'Z')</p> <code>color</code> <code>COLOR_LABEL</code> <p>Color of the detector ('r', 'g', or 'b')</p> Source code in <code>src/color_code_stim/color_code.py</code> <pre><code>def get_detector_type(self, detector_id: int) -&gt; Tuple[PAULI_LABEL, COLOR_LABEL]:\n    \"\"\"\n    Get the Pauli and color type of a detector.\n\n    Parameters\n    ----------\n    detector_id : int\n        Detector ID to query\n\n    Returns\n    -------\n    pauli : PAULI_LABEL\n        Pauli type of the detector ('X', 'Y', or 'Z')\n    color : COLOR_LABEL\n        Color of the detector ('r', 'g', or 'b')\n    \"\"\"\n    coords = self.circuit.get_detector_coordinates(only=[detector_id])[detector_id]\n    pauli = coords[3]\n    if pauli == 0:\n        pauli = \"X\"\n    elif pauli == 1:\n        pauli = \"Y\"\n    elif pauli == 2:\n        pauli = \"Z\"\n    else:\n        raise ValueError(f\"Invalid pauli: {pauli}\")\n    color = color_val_to_color(coords[4])\n\n    return pauli, color\n</code></pre>"},{"location":"api/color_code/#color_code_stim.ColorCode.get_observable_pauli","title":"<code>get_observable_pauli(observable_id)</code>","text":"<p>Get the Pauli type of an observable.</p> <p>Parameters:</p> Name Type Description Default <code>observable_id</code> <code>int</code> <p>Observable ID to query</p> required <p>Returns:</p> Type Description <code>PAULI_LABEL</code> <p>Pauli type of the observable</p> Source code in <code>src/color_code_stim/color_code.py</code> <pre><code>def get_observable_pauli(self, observable_id: int) -&gt; PAULI_LABEL:\n    \"\"\"\n    Get the Pauli type of an observable.\n\n    Parameters\n    ----------\n    observable_id : int\n        Observable ID to query\n\n    Returns\n    -------\n    PAULI_LABEL\n        Pauli type of the observable\n    \"\"\"\n    return self.obs_paulis[observable_id]\n</code></pre>"},{"location":"api/color_code/#color_code_stim.ColorCode.load","title":"<code>load(path)</code>  <code>classmethod</code>","text":"<p>Load a ColorCode object from a file saved by the <code>save</code> method.</p> <p>Reconstructs non-picklable attributes excluded during saving using the modular architecture approach.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The file path from which to load the object.</p> required <p>Returns:</p> Type Description <code>ColorCode</code> <p>The loaded ColorCode object.</p> Source code in <code>src/color_code_stim/color_code.py</code> <pre><code>@classmethod\ndef load(cls, path: str) -&gt; \"ColorCode\":\n    \"\"\"\n    Load a ColorCode object from a file saved by the `save` method.\n\n    Reconstructs non-picklable attributes excluded during saving using the\n    modular architecture approach.\n\n    Parameters\n    ----------\n    path : str\n        The file path from which to load the object.\n\n    Returns\n    -------\n    ColorCode\n        The loaded ColorCode object.\n    \"\"\"\n    with open(path, \"rb\") as f:\n        data = pickle.load(f)\n\n    # Create a new instance without calling __init__\n    instance = cls.__new__(cls)\n    instance.__dict__.update(data)\n\n    # Reconstruct non-picklable attributes in the correct order\n    try:\n        # Step 1: Reconstruct tanner_graph and qubit_groups\n        instance._reconstruct_tanner_graph_and_qubit_groups()\n\n        # Step 2: Clear lazy-loaded object caches (they will be recreated on demand)\n        instance._dem_manager = None\n        instance._concat_matching_decoder = None\n        instance._bp_decoder = None\n        instance._belief_concat_matching_decoder = None\n        instance._simulator = None\n\n        # Step 3: Initialize cache\n        instance._bp_inputs = {}\n\n    except Exception as e:\n        print(f\"Error during reconstruction: {e}\")\n        raise\n\n    return instance\n</code></pre>"},{"location":"api/color_code/#color_code_stim.ColorCode.sample","title":"<code>sample(shots, seed=None)</code>","text":"<p>Sample detector outcomes and observables from the quantum circuit.</p> <p>Parameters:</p> Name Type Description Default <code>shots</code> <code>int</code> <p>Number of samples to generate</p> required <code>seed</code> <code>int</code> <p>Seed value to initialize the random number generator</p> <code>None</code> <p>Returns:</p> Name Type Description <code>det</code> <code>2D numpy array of bool</code> <p>Detector outcomes. det[i,j] is True if and only if the detector with id j in the i-th sample has an outcome of \u22121.</p> <code>obs</code> <code>1D or 2D numpy array of bool</code> <p>Observable outcomes. If there is only one observable, returns a 1D array; otherwise returns a 2D array. obs[i] or obs[i,j] is True if and only if the j-th observable (j=0 when 1D) of the i-th sample has an outcome of -1.</p> Source code in <code>src/color_code_stim/color_code.py</code> <pre><code>def sample(\n    self, shots: int, seed: Optional[int] = None\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Sample detector outcomes and observables from the quantum circuit.\n\n    Parameters\n    ----------\n    shots : int\n        Number of samples to generate\n    seed : int, optional\n        Seed value to initialize the random number generator\n\n    Returns\n    -------\n    det : 2D numpy array of bool\n        Detector outcomes. det[i,j] is True if and only if the detector\n        with id j in the i-th sample has an outcome of \u22121.\n    obs : 1D or 2D numpy array of bool\n        Observable outcomes. If there is only one observable, returns a 1D array;\n        otherwise returns a 2D array. obs[i] or obs[i,j] is True if and only if\n        the j-th observable (j=0 when 1D) of the i-th sample has an outcome of -1.\n    \"\"\"\n    return self.simulator.sample(shots, seed=seed)\n</code></pre>"},{"location":"api/color_code/#color_code_stim.ColorCode.sample_with_errors","title":"<code>sample_with_errors(shots, seed=None)</code>","text":"<p>Sample detector outcomes, observables, and errors from the quantum circuit.</p> <p>Parameters:</p> Name Type Description Default <code>shots</code> <code>int</code> <p>Number of samples to generate</p> required <code>seed</code> <code>int</code> <p>Seed value to initialize the random number generator</p> <code>None</code> <p>Returns:</p> Name Type Description <code>det</code> <code>2D numpy array of bool</code> <p>Detector outcomes. det[i,j] is True if and only if the detector with id j in the i-th sample has an outcome of \u22121.</p> <code>obs</code> <code>1D or 2D numpy array of bool</code> <p>Observable outcomes. If there is only one observable, returns a 1D array; otherwise returns a 2D array. obs[i] or obs[i,j] is True if and only if the j-th observable (j=0 when 1D) of the i-th sample has an outcome of -1.</p> <code>errors</code> <code>2D numpy array of bool</code> <p>Errors sampled from the quantum circuit. errors[i,j] is True if and only if the j-th error (in the DEM) of the i-th sample has an outcome of -1.</p> Source code in <code>src/color_code_stim/color_code.py</code> <pre><code>def sample_with_errors(\n    self,\n    shots: int,\n    seed: Optional[int] = None,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Sample detector outcomes, observables, and errors from the quantum circuit.\n\n    Parameters\n    ----------\n    shots : int\n        Number of samples to generate\n    seed : int, optional\n        Seed value to initialize the random number generator\n\n    Returns\n    -------\n    det : 2D numpy array of bool\n        Detector outcomes. det[i,j] is True if and only if the detector\n        with id j in the i-th sample has an outcome of \u22121.\n    obs : 1D or 2D numpy array of bool\n        Observable outcomes. If there is only one observable, returns a 1D array;\n        otherwise returns a 2D array. obs[i] or obs[i,j] is True if and only if\n        the j-th observable (j=0 when 1D) of the i-th sample has an outcome of -1.\n    errors : 2D numpy array of bool\n        Errors sampled from the quantum circuit. errors[i,j] is True if and only if\n        the j-th error (in the DEM) of the i-th sample has an outcome of -1.\n    \"\"\"\n    return self.simulator.sample_with_errors(shots, seed=seed)\n</code></pre>"},{"location":"api/color_code/#color_code_stim.ColorCode.save","title":"<code>save(path)</code>","text":"<p>Save the ColorCode object to a file using pickle.</p> <p>Automatically identifies and excludes non-picklable attributes such as igraph objects, complex decoder objects, and lazy-loaded managers. These will be reconstructed upon loading.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The file path where the object should be saved.</p> required Source code in <code>src/color_code_stim/color_code.py</code> <pre><code>def save(self, path: str):\n    \"\"\"\n    Save the ColorCode object to a file using pickle.\n\n    Automatically identifies and excludes non-picklable attributes such as igraph objects,\n    complex decoder objects, and lazy-loaded managers. These will be reconstructed upon loading.\n\n    Parameters\n    ----------\n    path : str\n        The file path where the object should be saved.\n    \"\"\"\n    data = self.__dict__.copy()\n\n    # Known non-picklable attributes based on modular architecture\n    known_non_picklable = [\n        # igraph objects\n        \"tanner_graph\",  # igraph.Graph\n        \"qubit_groups\",  # Dict[str, ig.VertexSeq]\n        # Complex manager and decoder objects (lazy-loaded)\n        \"_dem_manager\",  # DemManager with igraph references\n        \"_concat_matching_decoder\",  # ConcatMatchingDecoder\n        \"_bp_decoder\",  # BPDecoder\n        \"_belief_concat_matching_decoder\",  # BeliefConcatMatchingDecoder\n        \"_simulator\",  # Simulator\n        # Cache that should be reconstructed\n        \"_bp_inputs\",  # Dictionary cache\n    ]\n\n    # Test remaining attributes for picklability and get dynamic exclusions\n    temp_data = {k: v for k, v in data.items() if k not in known_non_picklable}\n    _, additional_non_picklable = self._test_remaining_attributes(temp_data)\n\n    # Combine known and discovered non-picklable attributes\n    all_excluded = known_non_picklable + additional_non_picklable\n\n    # Remove non-picklable attributes\n    for key in all_excluded:\n        if key in data:\n            del data[key]\n\n    with open(path, \"wb\") as f:\n        pickle.dump(data, f)\n</code></pre>"},{"location":"api/color_code/#color_code_stim.ColorCode.simulate","title":"<code>simulate(shots, *, bp_predecoding=False, bp_prms=None, erasure_matcher_predecoding=False, partial_correction_by_predecoding=False, colors='all', alpha=0.01, confint_method='wilson', full_output=False, seed=None, verbose=False, **kwargs)</code>","text":"<p>Monte-Carlo simulation of the concatenated MWPM decoder. Delegated to simulator.</p> <p>Parameters:</p> Name Type Description Default <code>shots</code> <code>int</code> <p>Number of shots to simulate.</p> required <code>bp_predecoding</code> <code>bool</code> <p>If True, use belief propagation for predecoding.</p> <code>False</code> <code>bp_prms</code> <code>dict | None</code> <p>Parameters for belief propagation predecoding.</p> <code>None</code> <code>erasure_matcher_predecoding</code> <code>bool</code> <p>If True, use erasure matcher predecoding to identify errors common to all colors.</p> <code>False</code> <code>partial_correction_by_predecoding</code> <code>bool</code> <p>If True, apply partial correction using predecoding results when erasure matcher predecoding fails.</p> <code>False</code> <code>colors</code> <code>Union[List[str], str]</code> <p>Colors of the sub-decoding procedures to consider. Can be 'all', one of {'r', 'g', 'b'}, or a list containing any combination of {'r', 'g', 'b'}.</p> <code>'all'</code> <code>alpha</code> <code>float</code> <p>Significance level for the confidence interval calculation.</p> <code>0.01</code> <code>confint_method</code> <code>str</code> <p>Method to calculate the confidence interval. See statsmodels.stats.proportion.proportion_confint for available options.</p> <code>'wilson'</code> <code>full_output</code> <code>bool</code> <p>If True, return additional information.</p> <code>False</code> <code>seed</code> <code>Optional[int]</code> <p>Seed to initialize the random number generator.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If True, print progress information during simulation.</p> <code>False</code> <code>**kwargs</code> <p>Additional keyword arguments for the decoder (see <code>ColorCode.decode()</code>).</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>num_fails</code> <code>ndarray</code> <p>Number of failures for each observable.</p> <code>extra_outputs</code> <code>(dict, optional)</code> <p>Dictionary containing additional information: - 'stats': Tuple of (pfail, delta_pfail) where pfail is the estimated failure rate   and delta_pfail is the half-width of the confidence interval - 'fails': Boolean array indicating which samples failed - 'logical_gaps': Array of logical gaps (only when self.logical_gap is True) - etc.</p> Source code in <code>src/color_code_stim/color_code.py</code> <pre><code>def simulate(\n    self,\n    shots: int,\n    *,\n    bp_predecoding: bool = False,\n    bp_prms: dict | None = None,\n    erasure_matcher_predecoding: bool = False,\n    partial_correction_by_predecoding: bool = False,\n    colors: Union[List[str], str] = \"all\",\n    alpha: float = 0.01,\n    confint_method: str = \"wilson\",\n    full_output: bool = False,\n    seed: Optional[int] = None,\n    verbose: bool = False,\n    **kwargs,\n) -&gt; Tuple[np.ndarray, dict]:\n    \"\"\"\n    Monte-Carlo simulation of the concatenated MWPM decoder. Delegated to simulator.\n\n    Parameters\n    ----------\n    shots : int\n        Number of shots to simulate.\n    bp_predecoding : bool, default False\n        If True, use belief propagation for predecoding.\n    bp_prms : dict | None, default None\n        Parameters for belief propagation predecoding.\n    erasure_matcher_predecoding : bool, default False\n        If True, use erasure matcher predecoding to identify errors common to all colors.\n    partial_correction_by_predecoding : bool, default False\n        If True, apply partial correction using predecoding results when erasure matcher predecoding fails.\n    colors : Union[List[str], str], default 'all'\n        Colors of the sub-decoding procedures to consider. Can be 'all', one of {'r', 'g', 'b'},\n        or a list containing any combination of {'r', 'g', 'b'}.\n    alpha : float, default 0.01\n        Significance level for the confidence interval calculation.\n    confint_method : str, default 'wilson'\n        Method to calculate the confidence interval.\n        See statsmodels.stats.proportion.proportion_confint for available options.\n    full_output: bool = False,\n        If True, return additional information.\n    seed : Optional[int], default None\n        Seed to initialize the random number generator.\n    verbose : bool, default False\n        If True, print progress information during simulation.\n    **kwargs :\n        Additional keyword arguments for the decoder (see `ColorCode.decode()`).\n\n    Returns\n    -------\n    num_fails : numpy.ndarray\n        Number of failures for each observable.\n    extra_outputs : dict, optional\n        Dictionary containing additional information:\n        - 'stats': Tuple of (pfail, delta_pfail) where pfail is the estimated failure rate\n          and delta_pfail is the half-width of the confidence interval\n        - 'fails': Boolean array indicating which samples failed\n        - 'logical_gaps': Array of logical gaps (only when self.logical_gap is True)\n        - etc.\n    \"\"\"\n\n    # Create decoder function for simulator\n    def decoder_func(detector_outcomes, **decode_kwargs):\n        return self.decode(\n            detector_outcomes,\n            bp_predecoding=bp_predecoding,\n            bp_prms=bp_prms,\n            erasure_matcher_predecoding=erasure_matcher_predecoding,\n            partial_correction_by_predecoding=partial_correction_by_predecoding,\n            **kwargs,  # Original kwargs from simulate\n            **decode_kwargs,  # Additional kwargs from simulator\n        )\n\n    # Delegate to simulator\n    result = self.simulator.simulate(\n        shots=shots,\n        decoder_func=decoder_func,\n        colors=colors,\n        alpha=alpha,\n        confint_method=confint_method,\n        full_output=full_output,\n        seed=seed,\n        verbose=verbose,\n    )\n\n    return result\n</code></pre>"},{"location":"api/graph_builder/","title":"TannerGraphBuilder","text":"<p>Builder class for constructing Tanner graphs for color code patches.</p> <p>The graph structure depends on the patch type: - 'tri': Triangular patches (used for tri, growing, cult+growing circuits) - 'rec': Rectangular patches - 'rec_stability': Stability experiment patches</p> Source code in <code>src/color_code_stim/graph_builder.py</code> <pre><code>class TannerGraphBuilder:\n    \"\"\"\n    Builder class for constructing Tanner graphs for color code patches.\n\n    The graph structure depends on the patch type:\n    - 'tri': Triangular patches (used for tri, growing, cult+growing circuits)\n    - 'rec': Rectangular patches\n    - 'rec_stability': Stability experiment patches\n    \"\"\"\n\n    def __init__(self, circuit_type: CIRCUIT_TYPE, d: int, d2: Optional[int] = None):\n        \"\"\"\n        Initialize the Tanner graph builder.\n\n        Parameters\n        ----------\n        circuit_type : CIRCUIT_TYPE\n            Type of circuit that determines graph structure requirements.\n        d : int\n            Code distance for the initial patch.\n        d2 : int, optional\n            Code distance for the target patch (used in growing/cult+growing).\n        \"\"\"\n        self.circuit_type = circuit_type\n        self.d = d\n        self.d2 = d2 or d\n\n        # Map circuit types to patch types\n        if circuit_type in {\"tri\", \"growing\", \"cult+growing\"}:\n            self.patch_type: PATCH_TYPE = \"tri\"\n        elif circuit_type == \"rec\":\n            self.patch_type = \"rec\"\n        elif circuit_type == \"rec_stability\":\n            self.patch_type = \"rec_stability\"\n        else:\n            raise ValueError(f\"Invalid circuit type: {circuit_type}\")\n\n        self.tanner_graph = ig.Graph()\n        self.qubit_groups: Dict[str, Any] = {}\n\n    def build(self) -&gt; Tuple[ig.Graph, Dict[str, Any]]:\n        \"\"\"\n        Build the complete Tanner graph and qubit groups.\n\n        Returns\n        -------\n        Tuple[ig.Graph, Dict[str, Any]]\n            The constructed Tanner graph and qubit group mappings.\n        \"\"\"\n        # Build vertices based on patch type\n        if self.patch_type == \"tri\":\n            self._build_triangular_graph()\n        elif self.patch_type == \"rec\":\n            self._build_rectangular_graph()\n        elif self.patch_type == \"rec_stability\":\n            self._build_stability_graph()\n        else:\n            raise ValueError(f\"Invalid patch type: {self.patch_type}\")\n\n        # Update qubit groups\n        self._update_qubit_groups()\n\n        # Add edges\n        self._add_tanner_edges()\n\n        # Assign colors to lattice edges\n        self._assign_link_colors()\n\n        return self.tanner_graph, self.qubit_groups\n\n    def _build_triangular_graph(self) -&gt; None:\n        \"\"\"Build vertices for triangular patch geometry.\"\"\"\n        if self.circuit_type == \"tri\":\n            d = self.d\n        else:  # growing, cult+growing\n            d = self.d2\n\n        assert d % 2 == 1\n\n        detid = 0\n        L = round(3 * (d - 1) / 2)\n\n        for y in range(L + 1):\n            if y % 3 == 0:\n                anc_qubit_color = \"g\"\n                anc_qubit_pos = 2\n            elif y % 3 == 1:\n                anc_qubit_color = \"b\"\n                anc_qubit_pos = 0\n            else:\n                anc_qubit_color = \"r\"\n                anc_qubit_pos = 1\n\n            for x in range(2 * y, 4 * L - 2 * y + 1, 4):\n                boundary = []\n                if y == 0:\n                    boundary.append(\"r\")\n                if x == 2 * y:\n                    boundary.append(\"g\")\n                if x == 4 * L - 2 * y:\n                    boundary.append(\"b\")\n                boundary = \"\".join(boundary)\n                if not boundary:\n                    boundary = None\n\n                if self.circuit_type in {\"tri\"}:\n                    obs = boundary in [\"r\", \"rg\", \"rb\"]\n                elif self.circuit_type in {\"growing\", \"cult+growing\"}:\n                    obs = boundary in [\"g\", \"gb\", \"rg\"]\n                else:\n                    obs = False\n\n                if round((x / 2 - y) / 2) % 3 != anc_qubit_pos:\n                    self.tanner_graph.add_vertex(\n                        name=f\"{x}-{y}\",\n                        x=x,\n                        y=y,\n                        qid=self.tanner_graph.vcount(),\n                        pauli=None,\n                        color=None,\n                        obs=obs,\n                        boundary=boundary,\n                    )\n                else:\n                    for pauli in [\"Z\", \"X\"]:\n                        # Calculate ancilla qubit coordinates\n                        anc_x = x - 1 if pauli == \"Z\" else x + 1\n                        self.tanner_graph.add_vertex(\n                            name=f\"{anc_x}-{y}-{pauli}\",\n                            x=anc_x,\n                            y=y,\n                            face_x=x,\n                            face_y=y,\n                            qid=self.tanner_graph.vcount(),\n                            pauli=pauli,\n                            color=anc_qubit_color,\n                            obs=False,\n                            boundary=boundary,\n                        )\n                        detid += 1\n\n    def _build_rectangular_graph(self) -&gt; None:\n        \"\"\"Build vertices for rectangular patch geometry.\"\"\"\n        d, d2 = self.d, self.d2\n        assert d % 2 == 0\n        assert d2 % 2 == 0\n\n        detid = 0\n        L1 = round(3 * d / 2 - 2)\n        L2 = round(3 * d2 / 2 - 2)\n\n        for y in range(L2 + 1):\n            if y % 3 == 0:\n                anc_qubit_color = \"g\"\n                anc_qubit_pos = 2\n            elif y % 3 == 1:\n                anc_qubit_color = \"b\"\n                anc_qubit_pos = 0\n            else:\n                anc_qubit_color = \"r\"\n                anc_qubit_pos = 1\n\n            for x in range(2 * y, 2 * y + 4 * L1 + 1, 4):\n                boundary = []\n                if y == 0 or y == L2:\n                    boundary.append(\"r\")\n                if 2 * y == x or 2 * y == x - 4 * L1:\n                    boundary.append(\"g\")\n                boundary = \"\".join(boundary)\n                if not boundary:\n                    boundary = None\n\n                if round((x / 2 - y) / 2) % 3 != anc_qubit_pos:\n                    obs_g = y == 0\n                    obs_r = x == 2 * y + 4 * L1\n\n                    self.tanner_graph.add_vertex(\n                        name=f\"{x}-{y}\",\n                        x=x,\n                        y=y,\n                        qid=self.tanner_graph.vcount(),\n                        pauli=None,\n                        color=None,\n                        obs_r=obs_r,\n                        obs_g=obs_g,\n                        boundary=boundary,\n                    )\n                else:\n                    for pauli in [\"Z\", \"X\"]:\n                        # Calculate ancilla qubit coordinates\n                        anc_x = x - 1 if pauli == \"Z\" else x + 1\n                        self.tanner_graph.add_vertex(\n                            name=f\"{anc_x}-{y}-{pauli}\",\n                            x=anc_x,\n                            y=y,\n                            face_x=x,\n                            face_y=y,\n                            qid=self.tanner_graph.vcount(),\n                            pauli=pauli,\n                            color=anc_qubit_color,\n                            obs_r=False,\n                            obs_g=False,\n                            boundary=boundary,\n                        )\n                        detid += 1\n\n        # Additional corner vertex for rectangular patches\n        x = 2 * L2 + 2\n        y = L2 + 1\n        self.tanner_graph.add_vertex(\n            name=f\"{x}-{y}\",\n            x=x,\n            y=y,\n            qid=self.tanner_graph.vcount(),\n            pauli=None,\n            color=None,\n            obs_r=False,\n            obs_g=False,\n            boundary=\"rg\",\n        )\n\n    def _build_stability_graph(self) -&gt; None:\n        \"\"\"Build vertices for stability experiment patch geometry.\"\"\"\n        d = self.d\n        d2 = self.d2\n        assert d % 2 == 0\n        assert d2 % 2 == 0\n\n        detid = 0\n        L1 = round(3 * d / 2 - 2)\n        L2 = round(3 * d2 / 2 - 2)\n\n        for y in range(L2 + 1):\n            if y % 3 == 0:\n                anc_qubit_color = \"r\"\n                anc_qubit_pos = 0\n            elif y % 3 == 1:\n                anc_qubit_color = \"b\"\n                anc_qubit_pos = 1\n            else:\n                anc_qubit_color = \"g\"\n                anc_qubit_pos = 2\n\n            if y == 0:\n                x_init_adj = 8\n            elif y == 1:\n                x_init_adj = 4\n            else:\n                x_init_adj = 0\n\n            if y == L2:\n                x_fin_adj = 8\n            elif y == L2 - 1:\n                x_fin_adj = 4\n            else:\n                x_fin_adj = 0\n\n            for x in range(2 * y + x_init_adj, 2 * y + 4 * L1 + 1 - x_fin_adj, 4):\n                if (\n                    y == 0\n                    or y == L2\n                    or x == y * 2\n                    or x == 2 * y + 4 * L1\n                    or (x, y) == (6, 1)\n                    or (x, y) == (2 * L2 + 4 * L1 - 6, L2 - 1)\n                ):\n                    boundary = \"g\"\n                else:\n                    boundary = None\n\n                if round((x / 2 - y) / 2) % 3 != anc_qubit_pos:\n                    self.tanner_graph.add_vertex(\n                        name=f\"{x}-{y}\",\n                        x=x,\n                        y=y,\n                        qid=self.tanner_graph.vcount(),\n                        pauli=None,\n                        color=None,\n                        boundary=boundary,\n                    )\n                else:\n                    for pauli in [\"Z\", \"X\"]:\n                        # Calculate ancilla qubit coordinates\n                        anc_x = x - 1 if pauli == \"Z\" else x + 1\n                        self.tanner_graph.add_vertex(\n                            name=f\"{anc_x}-{y}-{pauli}\",\n                            x=anc_x,\n                            y=y,\n                            face_x=x,\n                            face_y=y,\n                            qid=self.tanner_graph.vcount(),\n                            pauli=pauli,\n                            color=anc_qubit_color,\n                            boundary=boundary,\n                        )\n                        detid += 1\n\n    def _update_qubit_groups(self) -&gt; None:\n        \"\"\"Update qubit group mappings after vertex creation.\"\"\"\n        data_qubits = self.tanner_graph.vs.select(pauli=None)\n        anc_qubits = self.tanner_graph.vs.select(pauli_ne=None)\n        anc_Z_qubits = anc_qubits.select(pauli=\"Z\")\n        anc_X_qubits = anc_qubits.select(pauli=\"X\")\n        anc_red_qubits = anc_qubits.select(color=\"r\")\n        anc_green_qubits = anc_qubits.select(color=\"g\")\n        anc_blue_qubits = anc_qubits.select(color=\"b\")\n\n        self.qubit_groups.update(\n            {\n                \"data\": data_qubits,\n                \"anc\": anc_qubits,\n                \"anc_Z\": anc_Z_qubits,\n                \"anc_X\": anc_X_qubits,\n                \"anc_red\": anc_red_qubits,\n                \"anc_green\": anc_green_qubits,\n                \"anc_blue\": anc_blue_qubits,\n            }\n        )\n\n    def _add_tanner_edges(self) -&gt; None:\n        \"\"\"Add Tanner graph edges between ancilla and data qubits.\"\"\"\n        links = []\n        offsets = [(-2, 1), (2, 1), (4, 0), (2, -1), (-2, -1), (-4, 0)]\n\n        for anc_qubit in self.qubit_groups[\"anc\"]:\n            data_qubits = []\n            for offset in offsets:\n                data_qubit_x = anc_qubit[\"face_x\"] + offset[0]\n                data_qubit_y = anc_qubit[\"face_y\"] + offset[1]\n                data_qubit_name = f\"{data_qubit_x}-{data_qubit_y}\"\n                try:\n                    data_qubit = self.tanner_graph.vs.find(name=data_qubit_name)\n                except ValueError:\n                    continue\n                data_qubits.append(data_qubit)\n                self.tanner_graph.add_edge(\n                    anc_qubit, data_qubit, kind=\"tanner\", color=None\n                )\n\n            if anc_qubit[\"pauli\"] == \"Z\":\n                weight = len(data_qubits)\n                for i in range(weight):\n                    qubit = data_qubits[i]\n                    next_qubit = data_qubits[(i + 1) % weight]\n                    if not self.tanner_graph.are_adjacent(qubit, next_qubit):\n                        link = self.tanner_graph.add_edge(\n                            qubit, next_qubit, kind=\"lattice\", color=None\n                        )\n                        links.append(link)\n\n        self._links = links  # Store for color assignment\n\n    def _assign_link_colors(self) -&gt; None:\n        \"\"\"Assign colors to lattice edges based on neighboring ancilla qubits.\"\"\"\n        for link in self._links:\n            v1, v2 = link.target_vertex, link.source_vertex\n            ngh_ancs_1 = {anc.index for anc in v1.neighbors() if anc[\"pauli\"] == \"Z\"}\n            ngh_ancs_2 = {anc.index for anc in v2.neighbors() if anc[\"pauli\"] == \"Z\"}\n            symmetric_diff = ngh_ancs_1 ^ ngh_ancs_2\n            if symmetric_diff:\n                color = self.tanner_graph.vs[symmetric_diff.pop()][\"color\"]\n                link[\"color\"] = color\n            else:\n                # Handle edge case where no unique ancilla is found\n                link[\"color\"] = None\n</code></pre>"},{"location":"api/graph_builder/#color_code_stim.TannerGraphBuilder.__init__","title":"<code>__init__(circuit_type, d, d2=None)</code>","text":"<p>Initialize the Tanner graph builder.</p> <p>Parameters:</p> Name Type Description Default <code>circuit_type</code> <code>CIRCUIT_TYPE</code> <p>Type of circuit that determines graph structure requirements.</p> required <code>d</code> <code>int</code> <p>Code distance for the initial patch.</p> required <code>d2</code> <code>int</code> <p>Code distance for the target patch (used in growing/cult+growing).</p> <code>None</code> Source code in <code>src/color_code_stim/graph_builder.py</code> <pre><code>def __init__(self, circuit_type: CIRCUIT_TYPE, d: int, d2: Optional[int] = None):\n    \"\"\"\n    Initialize the Tanner graph builder.\n\n    Parameters\n    ----------\n    circuit_type : CIRCUIT_TYPE\n        Type of circuit that determines graph structure requirements.\n    d : int\n        Code distance for the initial patch.\n    d2 : int, optional\n        Code distance for the target patch (used in growing/cult+growing).\n    \"\"\"\n    self.circuit_type = circuit_type\n    self.d = d\n    self.d2 = d2 or d\n\n    # Map circuit types to patch types\n    if circuit_type in {\"tri\", \"growing\", \"cult+growing\"}:\n        self.patch_type: PATCH_TYPE = \"tri\"\n    elif circuit_type == \"rec\":\n        self.patch_type = \"rec\"\n    elif circuit_type == \"rec_stability\":\n        self.patch_type = \"rec_stability\"\n    else:\n        raise ValueError(f\"Invalid circuit type: {circuit_type}\")\n\n    self.tanner_graph = ig.Graph()\n    self.qubit_groups: Dict[str, Any] = {}\n</code></pre>"},{"location":"api/graph_builder/#color_code_stim.TannerGraphBuilder.build","title":"<code>build()</code>","text":"<p>Build the complete Tanner graph and qubit groups.</p> <p>Returns:</p> Type Description <code>Tuple[Graph, Dict[str, Any]]</code> <p>The constructed Tanner graph and qubit group mappings.</p> Source code in <code>src/color_code_stim/graph_builder.py</code> <pre><code>def build(self) -&gt; Tuple[ig.Graph, Dict[str, Any]]:\n    \"\"\"\n    Build the complete Tanner graph and qubit groups.\n\n    Returns\n    -------\n    Tuple[ig.Graph, Dict[str, Any]]\n        The constructed Tanner graph and qubit group mappings.\n    \"\"\"\n    # Build vertices based on patch type\n    if self.patch_type == \"tri\":\n        self._build_triangular_graph()\n    elif self.patch_type == \"rec\":\n        self._build_rectangular_graph()\n    elif self.patch_type == \"rec_stability\":\n        self._build_stability_graph()\n    else:\n        raise ValueError(f\"Invalid patch type: {self.patch_type}\")\n\n    # Update qubit groups\n    self._update_qubit_groups()\n\n    # Add edges\n    self._add_tanner_edges()\n\n    # Assign colors to lattice edges\n    self._assign_link_colors()\n\n    return self.tanner_graph, self.qubit_groups\n</code></pre>"},{"location":"api/noise_model/","title":"NoiseModel","text":"<p>Noise model for color code quantum circuits with dictionary-like access.</p> <p>This class encapsulates all noise parameters used in color code circuits, providing a clean interface for setting.</p> <p>Examples:</p> <p>Uniform circuit-level noise model:</p> <pre><code>&gt;&gt;&gt; noise = NoiseModel.uniform_circuit_noise(0.001)\n&gt;&gt;&gt; print(noise['cnot'])  # 0.001\n</code></pre> <p>Code capacity noise model (depolarizing noise on data qubits before each round):</p> <pre><code>&gt;&gt;&gt; noise = NoiseModel(depol=0.01)\n</code></pre> <p>Bit-flip noise on data qubits before each round:</p> <pre><code>&gt;&gt;&gt; noise = NoiseModel(bitflip=0.01)\n</code></pre> <p>Phenomenological noise model:</p> <pre><code>&gt;&gt;&gt; noise = NoiseModel(depol=0.01, meas=0.01)\n</code></pre> <p>Noise model with specific parameters:</p> <pre><code>&gt;&gt;&gt; noise = NoiseModel(cnot=0.002, idle=0.001, reset=0.005, meas=0.003)\n</code></pre> Source code in <code>src/color_code_stim/noise_model.py</code> <pre><code>class NoiseModel:\n    \"\"\"\n    Noise model for color code quantum circuits with dictionary-like access.\n\n    This class encapsulates all noise parameters used in color code circuits,\n    providing a clean interface for setting.\n\n\n    Examples\n    --------\n    Uniform circuit-level noise model:\n    &gt;&gt;&gt; noise = NoiseModel.uniform_circuit_noise(0.001)\n    &gt;&gt;&gt; print(noise['cnot'])  # 0.001\n\n    Code capacity noise model (depolarizing noise on data qubits before each round):\n    &gt;&gt;&gt; noise = NoiseModel(depol=0.01)\n\n    Bit-flip noise on data qubits before each round:\n    &gt;&gt;&gt; noise = NoiseModel(bitflip=0.01)\n\n    Phenomenological noise model:\n    &gt;&gt;&gt; noise = NoiseModel(depol=0.01, meas=0.01)\n\n    Noise model with specific parameters:\n    &gt;&gt;&gt; noise = NoiseModel(cnot=0.002, idle=0.001, reset=0.005, meas=0.003)\n    \"\"\"\n\n    def __init__(\n        self,\n        bitflip: float = 0.0,\n        depol: float = 0.0,\n        reset: float = 0.0,\n        meas: float = 0.0,\n        cnot: float = 0.0,\n        idle: float = 0.0,\n        cult: Optional[float] = None,\n        initial_data_qubit_depol: float = 0.0,\n        depol1_after_cnot: float = 0.0,\n        idle_during_cnot: Optional[float] = None,\n        idle_during_meas: Optional[float] = None,\n        reset_data: Optional[float] = None,\n        reset_anc_X: Optional[float] = None,\n        reset_anc_Z: Optional[float] = None,\n        meas_data: Optional[float] = None,\n        meas_anc_X: Optional[float] = None,\n        meas_anc_Z: Optional[float] = None,\n    ):\n        \"\"\"\n        Initialize noise model with individual parameters.\n\n        All parameters must be non-negative floats representing error rates.\n\n        Parameters\n        ----------\n        bitflip : float, default 0.0\n            Bit-flip noise rate on data qubits at the start of each round.\n        depol : float, default 0.0\n            Depolarizing noise rate on data qubits at the start of each round.\n        reset : float, default 0.0\n            Error rate for reset operations (producing orthogonal state).\n        meas : float, default 0.0\n            Error rate for measurement operations (flipped outcome).\n        cnot : float, default 0.0\n            Two-qubit depolarizing noise rate for CNOT gates.\n        idle : float, default 0.0\n            Single-qubit depolarizing noise rate for idle operations.\n        cult : float, optional\n            Physical error rate during cultivation (for cult+growing circuits).\n            If not provided, defaults to cnot rate when needed.\n        initial_data_qubit_depol : float, default 0.0\n            Depolarizing noise rate applied to all data qubits after the first\n            syndrome extraction round (if perfect_first_syndrome_extraction=True)\n            or after data qubit initialization (if perfect_first_syndrome_extraction=False).\n        depol1_after_cnot : float, default 0.0\n            Single-qubit depolarizing noise rate applied to each qubit participating\n            in CNOT gates after the gates are applied. If provided and positive,\n            DEPOLARIZE1 is added for each qubit involved in the CNOT operations.\n        idle_during_cnot : float, optional\n            Single-qubit depolarizing noise rate for idle qubits during CNOT operations.\n            If None (default), uses the idle parameter. If set to any value (including 0),\n            overrides idle for qubits not participating in CNOT gates.\n        idle_during_meas : float, optional\n            Single-qubit depolarizing noise rate for idle qubits during measurement operations.\n            If None (default), uses the idle parameter. If set to any value (including 0),\n            overrides idle for qubits not participating in measurement operations.\n        reset_data : float, optional\n            Error rate for reset operations on data qubits (producing orthogonal state).\n            If None (default), uses the reset parameter.\n        reset_anc_X : float, optional\n            Error rate for reset operations on X-type ancilla qubits (producing orthogonal state).\n            If None (default), uses the reset parameter.\n        reset_anc_Z : float, optional\n            Error rate for reset operations on Z-type ancilla qubits (producing orthogonal state).\n            If None (default), uses the reset parameter.\n        meas_data : float, optional\n            Error rate for measurement operations on data qubits (flipped outcome).\n            If None (default), uses the meas parameter.\n        meas_anc_X : float, optional\n            Error rate for measurement operations on X-type ancilla qubits (flipped outcome).\n            If None (default), uses the meas parameter.\n        meas_anc_Z : float, optional\n            Error rate for measurement operations on Z-type ancilla qubits (flipped outcome).\n            If None (default), uses the meas parameter.\n        \"\"\"\n        # Store parameters in internal dict for easy access\n        self._params = {\n            \"bitflip\": float(bitflip),\n            \"depol\": float(depol),\n            \"reset\": float(reset),\n            \"meas\": float(meas),\n            \"cnot\": float(cnot),\n            \"idle\": float(idle),\n            \"initial_data_qubit_depol\": float(initial_data_qubit_depol),\n            \"depol1_after_cnot\": float(depol1_after_cnot),\n        }\n\n        # Handle special parameters that can be None\n        if cult is not None:\n            self._params[\"cult\"] = float(cult)\n        else:\n            self._params[\"cult\"] = None\n\n        if idle_during_cnot is not None:\n            self._params[\"idle_during_cnot\"] = float(idle_during_cnot)\n        else:\n            self._params[\"idle_during_cnot\"] = None\n\n        if idle_during_meas is not None:\n            self._params[\"idle_during_meas\"] = float(idle_during_meas)\n        else:\n            self._params[\"idle_during_meas\"] = None\n\n        # Handle granular reset parameters that can be None\n        if reset_data is not None:\n            self._params[\"reset_data\"] = float(reset_data)\n        else:\n            self._params[\"reset_data\"] = None\n\n        if reset_anc_X is not None:\n            self._params[\"reset_anc_X\"] = float(reset_anc_X)\n        else:\n            self._params[\"reset_anc_X\"] = None\n\n        if reset_anc_Z is not None:\n            self._params[\"reset_anc_Z\"] = float(reset_anc_Z)\n        else:\n            self._params[\"reset_anc_Z\"] = None\n\n        # Handle granular measurement parameters that can be None\n        if meas_data is not None:\n            self._params[\"meas_data\"] = float(meas_data)\n        else:\n            self._params[\"meas_data\"] = None\n\n        if meas_anc_X is not None:\n            self._params[\"meas_anc_X\"] = float(meas_anc_X)\n        else:\n            self._params[\"meas_anc_X\"] = None\n\n        if meas_anc_Z is not None:\n            self._params[\"meas_anc_Z\"] = float(meas_anc_Z)\n        else:\n            self._params[\"meas_anc_Z\"] = None\n\n        # Validate all parameters\n        self.validate()\n\n    @classmethod\n    def uniform_circuit_noise(cls, p_circuit: float) -&gt; Self:\n        \"\"\"\n        Create noise model with uniform circuit-level noise. Equivalent to:\n        &gt;&gt;&gt; NoiseModel(reset=p_circuit, meas=p_circuit, cnot=p_circuit, idle=p_circuit)\n\n        Parameters\n        ----------\n        p_circuit : float\n            Circuit-level error rate to apply uniformly.\n\n        Returns\n        -------\n        NoiseModel\n            New noise model with uniform rates.\n        \"\"\"\n        return cls(\n            bitflip=0.0,  # Not included in circuit-level noise\n            depol=0.0,  # Not included in circuit-level noise\n            reset=p_circuit,\n            meas=p_circuit,\n            cnot=p_circuit,\n            idle=p_circuit,\n            cult=None,  # Will default to cnot when needed\n            initial_data_qubit_depol=0.0,  # Not included in circuit-level noise\n            depol1_after_cnot=0.0,  # Not included in circuit-level noise\n            idle_during_cnot=None,  # Not included in circuit-level noise\n            idle_during_meas=None,  # Not included in circuit-level noise\n            reset_data=None,  # Will default to reset when needed\n            reset_anc_X=None,  # Will default to reset when needed\n            reset_anc_Z=None,  # Will default to reset when needed\n            meas_data=None,  # Will default to meas when needed\n            meas_anc_X=None,  # Will default to meas when needed\n            meas_anc_Z=None,  # Will default to meas when needed\n        )\n\n    def __getitem__(self, key: str) -&gt; float:\n        \"\"\"\n        Enable dictionary-like access: noise_model['depol'].\n\n        Parameters\n        ----------\n        key : str\n            Parameter name to retrieve.\n\n        Returns\n        -------\n        float\n            Parameter value.\n\n        Raises\n        ------\n        KeyError\n            If parameter name is not recognized.\n        \"\"\"\n        if key not in self._params:\n            valid_keys = list(self._params.keys())\n            raise KeyError(\n                f\"Unknown noise parameter '{key}'. Valid parameters: {valid_keys}\"\n            )\n\n        # Handle special cases of parameters that can fallback to other parameters\n        value = self._params[key]\n        if key == \"cult\" and value is None:\n            # Default cult to cnot rate if not explicitly set\n            return self._params[\"cnot\"]\n        elif key == \"idle_during_cnot\" and value is None:\n            # Default idle_during_cnot to idle rate if not explicitly set\n            return self._params[\"idle\"]\n        elif key == \"idle_during_meas\" and value is None:\n            # Default idle_during_meas to idle rate if not explicitly set\n            return self._params[\"idle\"]\n        # Handle granular reset parameters fallback to base reset\n        elif key == \"reset_data\" and value is None:\n            return self._params[\"reset\"]\n        elif key == \"reset_anc_X\" and value is None:\n            return self._params[\"reset\"]\n        elif key == \"reset_anc_Z\" and value is None:\n            return self._params[\"reset\"]\n        # Handle granular measurement parameters fallback to base meas\n        elif key == \"meas_data\" and value is None:\n            return self._params[\"meas\"]\n        elif key == \"meas_anc_X\" and value is None:\n            return self._params[\"meas\"]\n        elif key == \"meas_anc_Z\" and value is None:\n            return self._params[\"meas\"]\n\n        return value\n\n    def __setitem__(self, key: str, value: Optional[float]) -&gt; None:\n        \"\"\"\n        Enable dictionary-like assignment: noise_model['depol'] = 0.01.\n\n        Parameters\n        ----------\n        key : str\n            Parameter name to set.\n        value : float or None\n            Parameter value to assign. None is allowed for certain parameters.\n\n        Raises\n        ------\n        KeyError\n            If parameter name is not recognized.\n        ValueError\n            If value is negative.\n        \"\"\"\n        if key not in self._params:\n            valid_keys = list(self._params.keys())\n            raise KeyError(\n                f\"Unknown noise parameter '{key}'. Valid parameters: {valid_keys}\"\n            )\n\n        # Handle None values for special parameters\n        if value is None:\n            if key in {\n                \"cult\",\n                \"idle_during_cnot\",\n                \"idle_during_meas\",\n                \"reset_data\",\n                \"reset_anc_X\",\n                \"reset_anc_Z\",\n                \"meas_data\",\n                \"meas_anc_X\",\n                \"meas_anc_Z\",\n            }:\n                self._params[key] = None\n                return\n            else:\n                raise ValueError(\n                    f\"Noise parameter '{key}' cannot be None. \"\n                    f\"Only 'cult', 'idle_during_cnot', 'idle_during_meas', \"\n                    f\"and granular reset/measurement parameters can be None.\"\n                )\n\n        # Convert to float and validate\n        float_value = float(value)\n        if float_value &lt; 0:\n            raise ValueError(\n                f\"Noise parameter '{key}' must be non-negative, got {float_value}\"\n            )\n\n        # Special handling for special parameters\n        if key == \"cult\":\n            self._params[key] = float_value if float_value &gt; 0 else None\n        elif key in {\"idle_during_cnot\", \"idle_during_meas\"}:\n            # For idle context parameters, any explicit value (including 0) overrides idle\n            self._params[key] = float_value\n        elif key in {\n            \"reset_data\",\n            \"reset_anc_X\",\n            \"reset_anc_Z\",\n            \"meas_data\",\n            \"meas_anc_X\",\n            \"meas_anc_Z\",\n        }:\n            # For granular reset/measurement parameters, any explicit value (including 0) overrides base parameter\n            self._params[key] = float_value\n        else:\n            self._params[key] = float_value\n\n    def __contains__(self, key: str) -&gt; bool:\n        \"\"\"\n        Enable 'in' operator: 'depol' in noise_model.\n\n        Parameters\n        ----------\n        key : str\n            Parameter name to check.\n\n        Returns\n        -------\n        bool\n            True if parameter exists.\n        \"\"\"\n        return key in self._params\n\n    def keys(self) -&gt; Iterator[str]:\n        \"\"\"\n        Return parameter names.\n\n        Returns\n        -------\n        Iterator[str]\n            Iterator over parameter names.\n        \"\"\"\n        return iter(self._params.keys())\n\n    def values(self) -&gt; Iterator[float]:\n        \"\"\"\n        Return parameter values.\n\n        Returns\n        -------\n        Iterator[float]\n            Iterator over parameter values.\n        \"\"\"\n        for key in self._params:\n            yield self[key]  # Use __getitem__ to handle cult parameter\n\n    def items(self) -&gt; Iterator[Tuple[str, float]]:\n        \"\"\"\n        Return (parameter, value) pairs.\n\n        Returns\n        -------\n        Iterator[Tuple[str, float]]\n            Iterator over (name, value) pairs.\n        \"\"\"\n        for key in self._params:\n            yield (key, self[key])  # Use __getitem__ to handle cult parameter\n\n    def validate(self) -&gt; None:\n        \"\"\"\n        Validate all parameters are non-negative.\n\n        Raises\n        ------\n        ValueError\n            If any parameter is negative.\n        \"\"\"\n        for key, value in self._params.items():\n            if (\n                key\n                in {\n                    \"cult\",\n                    \"idle_during_cnot\",\n                    \"idle_during_meas\",\n                    \"reset_data\",\n                    \"reset_anc_X\",\n                    \"reset_anc_Z\",\n                    \"meas_data\",\n                    \"meas_anc_X\",\n                    \"meas_anc_Z\",\n                }\n                and value is None\n            ):\n                continue  # These parameters can be None\n            if value &lt; 0:\n                raise ValueError(\n                    f\"Noise parameter '{key}' must be non-negative, got {value}\"\n                )\n\n    def is_noiseless(self) -&gt; bool:\n        \"\"\"\n        Check if all noise parameters are zero.\n\n        Returns\n        -------\n        bool\n            True if all parameters are zero (noiseless model).\n        \"\"\"\n        for value in self.values():\n            if value &gt; 0:\n                return False\n        return True\n\n    def __str__(self) -&gt; str:\n        \"\"\"\n        String representation for end users.\n\n        Returns\n        -------\n        str\n            Human-readable string representation.\n        \"\"\"\n        if self.is_noiseless():\n            return \"NoiseModel(noiseless)\"\n\n        # Show only non-zero parameters\n        nonzero_params = []\n        for key, value in self.items():\n            if value &gt; 0:\n                nonzero_params.append(f\"{key}={value}\")\n\n        return f\"NoiseModel({', '.join(nonzero_params)})\"\n\n    def __repr__(self) -&gt; str:\n        \"\"\"\n        Developer representation.\n\n        Returns\n        -------\n        str\n            Detailed string representation for debugging.\n        \"\"\"\n        param_strs = []\n        for key, value in self._params.items():\n            if (\n                key\n                in {\n                    \"cult\",\n                    \"idle_during_cnot\",\n                    \"idle_during_meas\",\n                    \"reset_data\",\n                    \"reset_anc_X\",\n                    \"reset_anc_Z\",\n                    \"meas_data\",\n                    \"meas_anc_X\",\n                    \"meas_anc_Z\",\n                }\n                and value is None\n            ):\n                param_strs.append(f\"{key}=None\")\n            else:\n                param_strs.append(f\"{key}={value}\")\n\n        return f\"NoiseModel({', '.join(param_strs)})\"\n</code></pre>"},{"location":"api/noise_model/#color_code_stim.NoiseModel.__contains__","title":"<code>__contains__(key)</code>","text":"<p>Enable 'in' operator: 'depol' in noise_model.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Parameter name to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if parameter exists.</p> Source code in <code>src/color_code_stim/noise_model.py</code> <pre><code>def __contains__(self, key: str) -&gt; bool:\n    \"\"\"\n    Enable 'in' operator: 'depol' in noise_model.\n\n    Parameters\n    ----------\n    key : str\n        Parameter name to check.\n\n    Returns\n    -------\n    bool\n        True if parameter exists.\n    \"\"\"\n    return key in self._params\n</code></pre>"},{"location":"api/noise_model/#color_code_stim.NoiseModel.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Enable dictionary-like access: noise_model['depol'].</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Parameter name to retrieve.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Parameter value.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If parameter name is not recognized.</p> Source code in <code>src/color_code_stim/noise_model.py</code> <pre><code>def __getitem__(self, key: str) -&gt; float:\n    \"\"\"\n    Enable dictionary-like access: noise_model['depol'].\n\n    Parameters\n    ----------\n    key : str\n        Parameter name to retrieve.\n\n    Returns\n    -------\n    float\n        Parameter value.\n\n    Raises\n    ------\n    KeyError\n        If parameter name is not recognized.\n    \"\"\"\n    if key not in self._params:\n        valid_keys = list(self._params.keys())\n        raise KeyError(\n            f\"Unknown noise parameter '{key}'. Valid parameters: {valid_keys}\"\n        )\n\n    # Handle special cases of parameters that can fallback to other parameters\n    value = self._params[key]\n    if key == \"cult\" and value is None:\n        # Default cult to cnot rate if not explicitly set\n        return self._params[\"cnot\"]\n    elif key == \"idle_during_cnot\" and value is None:\n        # Default idle_during_cnot to idle rate if not explicitly set\n        return self._params[\"idle\"]\n    elif key == \"idle_during_meas\" and value is None:\n        # Default idle_during_meas to idle rate if not explicitly set\n        return self._params[\"idle\"]\n    # Handle granular reset parameters fallback to base reset\n    elif key == \"reset_data\" and value is None:\n        return self._params[\"reset\"]\n    elif key == \"reset_anc_X\" and value is None:\n        return self._params[\"reset\"]\n    elif key == \"reset_anc_Z\" and value is None:\n        return self._params[\"reset\"]\n    # Handle granular measurement parameters fallback to base meas\n    elif key == \"meas_data\" and value is None:\n        return self._params[\"meas\"]\n    elif key == \"meas_anc_X\" and value is None:\n        return self._params[\"meas\"]\n    elif key == \"meas_anc_Z\" and value is None:\n        return self._params[\"meas\"]\n\n    return value\n</code></pre>"},{"location":"api/noise_model/#color_code_stim.NoiseModel.__init__","title":"<code>__init__(bitflip=0.0, depol=0.0, reset=0.0, meas=0.0, cnot=0.0, idle=0.0, cult=None, initial_data_qubit_depol=0.0, depol1_after_cnot=0.0, idle_during_cnot=None, idle_during_meas=None, reset_data=None, reset_anc_X=None, reset_anc_Z=None, meas_data=None, meas_anc_X=None, meas_anc_Z=None)</code>","text":"<p>Initialize noise model with individual parameters.</p> <p>All parameters must be non-negative floats representing error rates.</p> <p>Parameters:</p> Name Type Description Default <code>bitflip</code> <code>float</code> <p>Bit-flip noise rate on data qubits at the start of each round.</p> <code>0.0</code> <code>depol</code> <code>float</code> <p>Depolarizing noise rate on data qubits at the start of each round.</p> <code>0.0</code> <code>reset</code> <code>float</code> <p>Error rate for reset operations (producing orthogonal state).</p> <code>0.0</code> <code>meas</code> <code>float</code> <p>Error rate for measurement operations (flipped outcome).</p> <code>0.0</code> <code>cnot</code> <code>float</code> <p>Two-qubit depolarizing noise rate for CNOT gates.</p> <code>0.0</code> <code>idle</code> <code>float</code> <p>Single-qubit depolarizing noise rate for idle operations.</p> <code>0.0</code> <code>cult</code> <code>float</code> <p>Physical error rate during cultivation (for cult+growing circuits). If not provided, defaults to cnot rate when needed.</p> <code>None</code> <code>initial_data_qubit_depol</code> <code>float</code> <p>Depolarizing noise rate applied to all data qubits after the first syndrome extraction round (if perfect_first_syndrome_extraction=True) or after data qubit initialization (if perfect_first_syndrome_extraction=False).</p> <code>0.0</code> <code>depol1_after_cnot</code> <code>float</code> <p>Single-qubit depolarizing noise rate applied to each qubit participating in CNOT gates after the gates are applied. If provided and positive, DEPOLARIZE1 is added for each qubit involved in the CNOT operations.</p> <code>0.0</code> <code>idle_during_cnot</code> <code>float</code> <p>Single-qubit depolarizing noise rate for idle qubits during CNOT operations. If None (default), uses the idle parameter. If set to any value (including 0), overrides idle for qubits not participating in CNOT gates.</p> <code>None</code> <code>idle_during_meas</code> <code>float</code> <p>Single-qubit depolarizing noise rate for idle qubits during measurement operations. If None (default), uses the idle parameter. If set to any value (including 0), overrides idle for qubits not participating in measurement operations.</p> <code>None</code> <code>reset_data</code> <code>float</code> <p>Error rate for reset operations on data qubits (producing orthogonal state). If None (default), uses the reset parameter.</p> <code>None</code> <code>reset_anc_X</code> <code>float</code> <p>Error rate for reset operations on X-type ancilla qubits (producing orthogonal state). If None (default), uses the reset parameter.</p> <code>None</code> <code>reset_anc_Z</code> <code>float</code> <p>Error rate for reset operations on Z-type ancilla qubits (producing orthogonal state). If None (default), uses the reset parameter.</p> <code>None</code> <code>meas_data</code> <code>float</code> <p>Error rate for measurement operations on data qubits (flipped outcome). If None (default), uses the meas parameter.</p> <code>None</code> <code>meas_anc_X</code> <code>float</code> <p>Error rate for measurement operations on X-type ancilla qubits (flipped outcome). If None (default), uses the meas parameter.</p> <code>None</code> <code>meas_anc_Z</code> <code>float</code> <p>Error rate for measurement operations on Z-type ancilla qubits (flipped outcome). If None (default), uses the meas parameter.</p> <code>None</code> Source code in <code>src/color_code_stim/noise_model.py</code> <pre><code>def __init__(\n    self,\n    bitflip: float = 0.0,\n    depol: float = 0.0,\n    reset: float = 0.0,\n    meas: float = 0.0,\n    cnot: float = 0.0,\n    idle: float = 0.0,\n    cult: Optional[float] = None,\n    initial_data_qubit_depol: float = 0.0,\n    depol1_after_cnot: float = 0.0,\n    idle_during_cnot: Optional[float] = None,\n    idle_during_meas: Optional[float] = None,\n    reset_data: Optional[float] = None,\n    reset_anc_X: Optional[float] = None,\n    reset_anc_Z: Optional[float] = None,\n    meas_data: Optional[float] = None,\n    meas_anc_X: Optional[float] = None,\n    meas_anc_Z: Optional[float] = None,\n):\n    \"\"\"\n    Initialize noise model with individual parameters.\n\n    All parameters must be non-negative floats representing error rates.\n\n    Parameters\n    ----------\n    bitflip : float, default 0.0\n        Bit-flip noise rate on data qubits at the start of each round.\n    depol : float, default 0.0\n        Depolarizing noise rate on data qubits at the start of each round.\n    reset : float, default 0.0\n        Error rate for reset operations (producing orthogonal state).\n    meas : float, default 0.0\n        Error rate for measurement operations (flipped outcome).\n    cnot : float, default 0.0\n        Two-qubit depolarizing noise rate for CNOT gates.\n    idle : float, default 0.0\n        Single-qubit depolarizing noise rate for idle operations.\n    cult : float, optional\n        Physical error rate during cultivation (for cult+growing circuits).\n        If not provided, defaults to cnot rate when needed.\n    initial_data_qubit_depol : float, default 0.0\n        Depolarizing noise rate applied to all data qubits after the first\n        syndrome extraction round (if perfect_first_syndrome_extraction=True)\n        or after data qubit initialization (if perfect_first_syndrome_extraction=False).\n    depol1_after_cnot : float, default 0.0\n        Single-qubit depolarizing noise rate applied to each qubit participating\n        in CNOT gates after the gates are applied. If provided and positive,\n        DEPOLARIZE1 is added for each qubit involved in the CNOT operations.\n    idle_during_cnot : float, optional\n        Single-qubit depolarizing noise rate for idle qubits during CNOT operations.\n        If None (default), uses the idle parameter. If set to any value (including 0),\n        overrides idle for qubits not participating in CNOT gates.\n    idle_during_meas : float, optional\n        Single-qubit depolarizing noise rate for idle qubits during measurement operations.\n        If None (default), uses the idle parameter. If set to any value (including 0),\n        overrides idle for qubits not participating in measurement operations.\n    reset_data : float, optional\n        Error rate for reset operations on data qubits (producing orthogonal state).\n        If None (default), uses the reset parameter.\n    reset_anc_X : float, optional\n        Error rate for reset operations on X-type ancilla qubits (producing orthogonal state).\n        If None (default), uses the reset parameter.\n    reset_anc_Z : float, optional\n        Error rate for reset operations on Z-type ancilla qubits (producing orthogonal state).\n        If None (default), uses the reset parameter.\n    meas_data : float, optional\n        Error rate for measurement operations on data qubits (flipped outcome).\n        If None (default), uses the meas parameter.\n    meas_anc_X : float, optional\n        Error rate for measurement operations on X-type ancilla qubits (flipped outcome).\n        If None (default), uses the meas parameter.\n    meas_anc_Z : float, optional\n        Error rate for measurement operations on Z-type ancilla qubits (flipped outcome).\n        If None (default), uses the meas parameter.\n    \"\"\"\n    # Store parameters in internal dict for easy access\n    self._params = {\n        \"bitflip\": float(bitflip),\n        \"depol\": float(depol),\n        \"reset\": float(reset),\n        \"meas\": float(meas),\n        \"cnot\": float(cnot),\n        \"idle\": float(idle),\n        \"initial_data_qubit_depol\": float(initial_data_qubit_depol),\n        \"depol1_after_cnot\": float(depol1_after_cnot),\n    }\n\n    # Handle special parameters that can be None\n    if cult is not None:\n        self._params[\"cult\"] = float(cult)\n    else:\n        self._params[\"cult\"] = None\n\n    if idle_during_cnot is not None:\n        self._params[\"idle_during_cnot\"] = float(idle_during_cnot)\n    else:\n        self._params[\"idle_during_cnot\"] = None\n\n    if idle_during_meas is not None:\n        self._params[\"idle_during_meas\"] = float(idle_during_meas)\n    else:\n        self._params[\"idle_during_meas\"] = None\n\n    # Handle granular reset parameters that can be None\n    if reset_data is not None:\n        self._params[\"reset_data\"] = float(reset_data)\n    else:\n        self._params[\"reset_data\"] = None\n\n    if reset_anc_X is not None:\n        self._params[\"reset_anc_X\"] = float(reset_anc_X)\n    else:\n        self._params[\"reset_anc_X\"] = None\n\n    if reset_anc_Z is not None:\n        self._params[\"reset_anc_Z\"] = float(reset_anc_Z)\n    else:\n        self._params[\"reset_anc_Z\"] = None\n\n    # Handle granular measurement parameters that can be None\n    if meas_data is not None:\n        self._params[\"meas_data\"] = float(meas_data)\n    else:\n        self._params[\"meas_data\"] = None\n\n    if meas_anc_X is not None:\n        self._params[\"meas_anc_X\"] = float(meas_anc_X)\n    else:\n        self._params[\"meas_anc_X\"] = None\n\n    if meas_anc_Z is not None:\n        self._params[\"meas_anc_Z\"] = float(meas_anc_Z)\n    else:\n        self._params[\"meas_anc_Z\"] = None\n\n    # Validate all parameters\n    self.validate()\n</code></pre>"},{"location":"api/noise_model/#color_code_stim.NoiseModel.__repr__","title":"<code>__repr__()</code>","text":"<p>Developer representation.</p> <p>Returns:</p> Type Description <code>str</code> <p>Detailed string representation for debugging.</p> Source code in <code>src/color_code_stim/noise_model.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"\n    Developer representation.\n\n    Returns\n    -------\n    str\n        Detailed string representation for debugging.\n    \"\"\"\n    param_strs = []\n    for key, value in self._params.items():\n        if (\n            key\n            in {\n                \"cult\",\n                \"idle_during_cnot\",\n                \"idle_during_meas\",\n                \"reset_data\",\n                \"reset_anc_X\",\n                \"reset_anc_Z\",\n                \"meas_data\",\n                \"meas_anc_X\",\n                \"meas_anc_Z\",\n            }\n            and value is None\n        ):\n            param_strs.append(f\"{key}=None\")\n        else:\n            param_strs.append(f\"{key}={value}\")\n\n    return f\"NoiseModel({', '.join(param_strs)})\"\n</code></pre>"},{"location":"api/noise_model/#color_code_stim.NoiseModel.__setitem__","title":"<code>__setitem__(key, value)</code>","text":"<p>Enable dictionary-like assignment: noise_model['depol'] = 0.01.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Parameter name to set.</p> required <code>value</code> <code>float or None</code> <p>Parameter value to assign. None is allowed for certain parameters.</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>If parameter name is not recognized.</p> <code>ValueError</code> <p>If value is negative.</p> Source code in <code>src/color_code_stim/noise_model.py</code> <pre><code>def __setitem__(self, key: str, value: Optional[float]) -&gt; None:\n    \"\"\"\n    Enable dictionary-like assignment: noise_model['depol'] = 0.01.\n\n    Parameters\n    ----------\n    key : str\n        Parameter name to set.\n    value : float or None\n        Parameter value to assign. None is allowed for certain parameters.\n\n    Raises\n    ------\n    KeyError\n        If parameter name is not recognized.\n    ValueError\n        If value is negative.\n    \"\"\"\n    if key not in self._params:\n        valid_keys = list(self._params.keys())\n        raise KeyError(\n            f\"Unknown noise parameter '{key}'. Valid parameters: {valid_keys}\"\n        )\n\n    # Handle None values for special parameters\n    if value is None:\n        if key in {\n            \"cult\",\n            \"idle_during_cnot\",\n            \"idle_during_meas\",\n            \"reset_data\",\n            \"reset_anc_X\",\n            \"reset_anc_Z\",\n            \"meas_data\",\n            \"meas_anc_X\",\n            \"meas_anc_Z\",\n        }:\n            self._params[key] = None\n            return\n        else:\n            raise ValueError(\n                f\"Noise parameter '{key}' cannot be None. \"\n                f\"Only 'cult', 'idle_during_cnot', 'idle_during_meas', \"\n                f\"and granular reset/measurement parameters can be None.\"\n            )\n\n    # Convert to float and validate\n    float_value = float(value)\n    if float_value &lt; 0:\n        raise ValueError(\n            f\"Noise parameter '{key}' must be non-negative, got {float_value}\"\n        )\n\n    # Special handling for special parameters\n    if key == \"cult\":\n        self._params[key] = float_value if float_value &gt; 0 else None\n    elif key in {\"idle_during_cnot\", \"idle_during_meas\"}:\n        # For idle context parameters, any explicit value (including 0) overrides idle\n        self._params[key] = float_value\n    elif key in {\n        \"reset_data\",\n        \"reset_anc_X\",\n        \"reset_anc_Z\",\n        \"meas_data\",\n        \"meas_anc_X\",\n        \"meas_anc_Z\",\n    }:\n        # For granular reset/measurement parameters, any explicit value (including 0) overrides base parameter\n        self._params[key] = float_value\n    else:\n        self._params[key] = float_value\n</code></pre>"},{"location":"api/noise_model/#color_code_stim.NoiseModel.__str__","title":"<code>__str__()</code>","text":"<p>String representation for end users.</p> <p>Returns:</p> Type Description <code>str</code> <p>Human-readable string representation.</p> Source code in <code>src/color_code_stim/noise_model.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"\n    String representation for end users.\n\n    Returns\n    -------\n    str\n        Human-readable string representation.\n    \"\"\"\n    if self.is_noiseless():\n        return \"NoiseModel(noiseless)\"\n\n    # Show only non-zero parameters\n    nonzero_params = []\n    for key, value in self.items():\n        if value &gt; 0:\n            nonzero_params.append(f\"{key}={value}\")\n\n    return f\"NoiseModel({', '.join(nonzero_params)})\"\n</code></pre>"},{"location":"api/noise_model/#color_code_stim.NoiseModel.is_noiseless","title":"<code>is_noiseless()</code>","text":"<p>Check if all noise parameters are zero.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if all parameters are zero (noiseless model).</p> Source code in <code>src/color_code_stim/noise_model.py</code> <pre><code>def is_noiseless(self) -&gt; bool:\n    \"\"\"\n    Check if all noise parameters are zero.\n\n    Returns\n    -------\n    bool\n        True if all parameters are zero (noiseless model).\n    \"\"\"\n    for value in self.values():\n        if value &gt; 0:\n            return False\n    return True\n</code></pre>"},{"location":"api/noise_model/#color_code_stim.NoiseModel.items","title":"<code>items()</code>","text":"<p>Return (parameter, value) pairs.</p> <p>Returns:</p> Type Description <code>Iterator[Tuple[str, float]]</code> <p>Iterator over (name, value) pairs.</p> Source code in <code>src/color_code_stim/noise_model.py</code> <pre><code>def items(self) -&gt; Iterator[Tuple[str, float]]:\n    \"\"\"\n    Return (parameter, value) pairs.\n\n    Returns\n    -------\n    Iterator[Tuple[str, float]]\n        Iterator over (name, value) pairs.\n    \"\"\"\n    for key in self._params:\n        yield (key, self[key])  # Use __getitem__ to handle cult parameter\n</code></pre>"},{"location":"api/noise_model/#color_code_stim.NoiseModel.keys","title":"<code>keys()</code>","text":"<p>Return parameter names.</p> <p>Returns:</p> Type Description <code>Iterator[str]</code> <p>Iterator over parameter names.</p> Source code in <code>src/color_code_stim/noise_model.py</code> <pre><code>def keys(self) -&gt; Iterator[str]:\n    \"\"\"\n    Return parameter names.\n\n    Returns\n    -------\n    Iterator[str]\n        Iterator over parameter names.\n    \"\"\"\n    return iter(self._params.keys())\n</code></pre>"},{"location":"api/noise_model/#color_code_stim.NoiseModel.uniform_circuit_noise","title":"<code>uniform_circuit_noise(p_circuit)</code>  <code>classmethod</code>","text":"<p>Create noise model with uniform circuit-level noise. Equivalent to:</p> <p>NoiseModel(reset=p_circuit, meas=p_circuit, cnot=p_circuit, idle=p_circuit)</p> <p>Parameters:</p> Name Type Description Default <code>p_circuit</code> <code>float</code> <p>Circuit-level error rate to apply uniformly.</p> required <p>Returns:</p> Type Description <code>NoiseModel</code> <p>New noise model with uniform rates.</p> Source code in <code>src/color_code_stim/noise_model.py</code> <pre><code>@classmethod\ndef uniform_circuit_noise(cls, p_circuit: float) -&gt; Self:\n    \"\"\"\n    Create noise model with uniform circuit-level noise. Equivalent to:\n    &gt;&gt;&gt; NoiseModel(reset=p_circuit, meas=p_circuit, cnot=p_circuit, idle=p_circuit)\n\n    Parameters\n    ----------\n    p_circuit : float\n        Circuit-level error rate to apply uniformly.\n\n    Returns\n    -------\n    NoiseModel\n        New noise model with uniform rates.\n    \"\"\"\n    return cls(\n        bitflip=0.0,  # Not included in circuit-level noise\n        depol=0.0,  # Not included in circuit-level noise\n        reset=p_circuit,\n        meas=p_circuit,\n        cnot=p_circuit,\n        idle=p_circuit,\n        cult=None,  # Will default to cnot when needed\n        initial_data_qubit_depol=0.0,  # Not included in circuit-level noise\n        depol1_after_cnot=0.0,  # Not included in circuit-level noise\n        idle_during_cnot=None,  # Not included in circuit-level noise\n        idle_during_meas=None,  # Not included in circuit-level noise\n        reset_data=None,  # Will default to reset when needed\n        reset_anc_X=None,  # Will default to reset when needed\n        reset_anc_Z=None,  # Will default to reset when needed\n        meas_data=None,  # Will default to meas when needed\n        meas_anc_X=None,  # Will default to meas when needed\n        meas_anc_Z=None,  # Will default to meas when needed\n    )\n</code></pre>"},{"location":"api/noise_model/#color_code_stim.NoiseModel.validate","title":"<code>validate()</code>","text":"<p>Validate all parameters are non-negative.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If any parameter is negative.</p> Source code in <code>src/color_code_stim/noise_model.py</code> <pre><code>def validate(self) -&gt; None:\n    \"\"\"\n    Validate all parameters are non-negative.\n\n    Raises\n    ------\n    ValueError\n        If any parameter is negative.\n    \"\"\"\n    for key, value in self._params.items():\n        if (\n            key\n            in {\n                \"cult\",\n                \"idle_during_cnot\",\n                \"idle_during_meas\",\n                \"reset_data\",\n                \"reset_anc_X\",\n                \"reset_anc_Z\",\n                \"meas_data\",\n                \"meas_anc_X\",\n                \"meas_anc_Z\",\n            }\n            and value is None\n        ):\n            continue  # These parameters can be None\n        if value &lt; 0:\n            raise ValueError(\n                f\"Noise parameter '{key}' must be non-negative, got {value}\"\n            )\n</code></pre>"},{"location":"api/noise_model/#color_code_stim.NoiseModel.values","title":"<code>values()</code>","text":"<p>Return parameter values.</p> <p>Returns:</p> Type Description <code>Iterator[float]</code> <p>Iterator over parameter values.</p> Source code in <code>src/color_code_stim/noise_model.py</code> <pre><code>def values(self) -&gt; Iterator[float]:\n    \"\"\"\n    Return parameter values.\n\n    Returns\n    -------\n    Iterator[float]\n        Iterator over parameter values.\n    \"\"\"\n    for key in self._params:\n        yield self[key]  # Use __getitem__ to handle cult parameter\n</code></pre>"},{"location":"api/stim_utils/","title":"Stim Utilities","text":""},{"location":"api/stim_utils/#color_code_stim.stim_utils.dem_to_parity_check","title":"<code>dem_to_parity_check(dem)</code>","text":"<p>Convert a detector error model (DEM) into a parity check matrix, observable matrix, and probability vector.</p> <p>Parameters:</p> Name Type Description Default <code>dem</code> <code>DetectorErrorModel</code> <p>The detector error model to convert.</p> required <p>Returns:</p> Name Type Description <code>H</code> <code>csc_matrix</code> <p>A boolean matrix of shape (number of detectors, number of errors) where H[i, j] = True if detector i is involved in error j.</p> <code>obs_matrix</code> <code>csc_matrix</code> <p>A boolean matrix of shape (number of observables, number of errors) where obs_matrix[i, j] = True if observable i is involved in error j.</p> <code>p</code> <code>ndarray</code> <p>A 1D numpy array of probabilities corresponding to each error.</p> Source code in <code>src/color_code_stim/stim_utils.py</code> <pre><code>def dem_to_parity_check(\n    dem: stim.DetectorErrorModel,\n) -&gt; Tuple[csc_matrix, csc_matrix, np.ndarray]:\n    \"\"\"\n    Convert a detector error model (DEM) into a parity check matrix, observable matrix,\n    and probability vector.\n\n    Parameters\n    ----------\n    dem : stim.DetectorErrorModel\n        The detector error model to convert.\n\n    Returns\n    -------\n    H : csc_matrix\n        A boolean matrix of shape (number of detectors, number of errors)\n        where H[i, j] = True if detector i is involved in error j.\n    obs_matrix : csc_matrix\n        A boolean matrix of shape (number of observables, number of errors)\n        where obs_matrix[i, j] = True if observable i is involved in error j.\n    p : np.ndarray\n        A 1D numpy array of probabilities corresponding to each error.\n    \"\"\"\n    dem = dem.flattened()\n\n    probabilities = []\n    det_ids_in_ems = []\n    obs_ids_in_ems = []\n\n    for _, instruction in enumerate(dem):\n        if instruction.type == \"error\":\n            det_ids = []\n            obs_ids = []\n            det_ids_in_ems.append(det_ids)\n            obs_ids_in_ems.append(obs_ids)\n\n            # Extract probability\n            prob = float(instruction.args_copy()[0])\n            probabilities.append(prob)\n\n            for target in instruction.targets_copy():\n                if target.is_relative_detector_id():\n                    det_ids.append(int(str(target)[1:]))\n                elif target.is_logical_observable_id():\n                    obs_ids.append(int(str(target)[1:]))\n                else:\n                    raise ValueError(f\"Unknown target type: {target}\")\n\n    p = np.array(probabilities)\n\n    # Create the parity check matrix H\n    if det_ids_in_ems:\n        num_detectors = dem.num_detectors\n        num_errors = len(det_ids_in_ems)\n\n        # Prepare data for CSC matrix construction\n        row_indices = []\n        col_indices = []\n        data = []\n\n        for error_idx, det_ids in enumerate(det_ids_in_ems):\n            for det_id in det_ids:\n                row_indices.append(det_id)\n                col_indices.append(error_idx)\n                data.append(True)\n\n        H = csc_matrix(\n            (data, (row_indices, col_indices)),\n            shape=(num_detectors, num_errors),\n            dtype=bool,\n        )\n    else:\n        H = csc_matrix((0, 0), dtype=bool)\n\n    # Create the observable matrix\n    if obs_ids_in_ems:\n        # Find the maximum observable ID\n        num_observables = dem.num_observables\n        num_errors = len(obs_ids_in_ems)\n\n        # Prepare data for CSC matrix construction\n        row_indices = []\n        col_indices = []\n        data = []\n\n        for error_idx, obs_ids in enumerate(obs_ids_in_ems):\n            for obs_id in obs_ids:\n                row_indices.append(obs_id)\n                col_indices.append(error_idx)\n                data.append(True)\n\n        obs_matrix = csc_matrix(\n            (data, (row_indices, col_indices)),\n            shape=(num_observables, num_errors),\n            dtype=bool,\n        )\n    else:\n        obs_matrix = csc_matrix((0, 0), dtype=bool)\n\n    return H, obs_matrix, p\n</code></pre>"},{"location":"api/stim_utils/#color_code_stim.stim_utils.dem_to_str","title":"<code>dem_to_str(dem)</code>","text":"<p>Convert a detector error model to its string representation.</p> <p>Parameters:</p> Name Type Description Default <code>dem</code> <code>DetectorErrorModel</code> <p>The detector error model to convert.</p> required <p>Returns:</p> Type Description <code>str</code> <p>String representation of the detector error model.</p> Source code in <code>src/color_code_stim/stim_utils.py</code> <pre><code>def dem_to_str(dem: stim.DetectorErrorModel) -&gt; str:\n    \"\"\"\n    Convert a detector error model to its string representation.\n\n    Parameters\n    ----------\n    dem : stim.DetectorErrorModel\n        The detector error model to convert.\n\n    Returns\n    -------\n    str\n        String representation of the detector error model.\n    \"\"\"\n    buffer = io.StringIO()\n    dem.to_file(buffer)\n    s = buffer.getvalue()\n    return s\n</code></pre>"},{"location":"api/stim_utils/#color_code_stim.stim_utils.remove_obs_from_dem","title":"<code>remove_obs_from_dem(dem)</code>","text":"<p>Remove detectors acting as observables from a detector error model.</p> <p>Parameters:</p> Name Type Description Default <code>dem</code> <code>DetectorErrorModel</code> <p>The detector error model to process.</p> required <p>Returns:</p> Type Description <code>DetectorErrorModel</code> <p>A new detector error model with all detectors acting as observables removed.</p> Source code in <code>src/color_code_stim/stim_utils.py</code> <pre><code>def remove_obs_from_dem(dem: stim.DetectorErrorModel) -&gt; stim.DetectorErrorModel:\n    \"\"\"\n    Remove detectors acting as observables from a detector error model.\n\n    Parameters\n    ----------\n    dem : stim.DetectorErrorModel\n        The detector error model to process.\n\n    Returns\n    -------\n    stim.DetectorErrorModel\n        A new detector error model with all detectors acting as observables removed.\n    \"\"\"\n    num_dets = dem.num_detectors\n    num_obss = dem.num_observables\n    s = dem_to_str(dem)\n\n    # Remove last lines corresponding to observables\n    s = \"\\n\".join(s.splitlines()[:-num_obss]) + \"\\n\"\n\n    # Build a regex pattern to match the exact text \"D{num_dets - 1}\"\n    patterns = [r\"\\bD\" + str(num_dets - num_obss + i) + r\"\\b\" for i in range(num_obss)]\n    # Remove all occurrences of that pattern\n    for pattern in patterns:\n        s = re.sub(pattern, \"\", s)\n\n    # Clean up extra spaces in each line (e.g. converting \"D0  D1  L0\" to \"D0 D1 L0\")\n    s = \"\\n\".join(\" \".join(line.split()) for line in s.splitlines())\n\n    return str_to_dem(s)\n</code></pre>"},{"location":"api/stim_utils/#color_code_stim.stim_utils.save_circuit_diagram","title":"<code>save_circuit_diagram(circuit, path, type='timeline-svg')</code>","text":"<p>Save a textual diagram of <code>circuit</code> to <code>path</code>.</p> <p>Parameters:</p> Name Type Description Default <code>circuit</code> <code>Circuit</code> <p>Circuit whose diagram will be saved.</p> required <code>path</code> <code>str</code> <p>File path for the output diagram.</p> required <code>type</code> <code>str</code> <p>Format used by <code>stim.Circuit.diagram</code>.</p> <code>'timeline-svg'</code> <p>Returns:</p> Type Description <code>None</code> <p>This function writes to disk and does not return a value.</p> Source code in <code>src/color_code_stim/stim_utils.py</code> <pre><code>def save_circuit_diagram(\n    circuit: stim.Circuit, path: str, type: str = \"timeline-svg\"\n) -&gt; None:\n    \"\"\"\n    Save a textual diagram of ``circuit`` to ``path``.\n\n    Parameters\n    ----------\n    circuit : stim.Circuit\n        Circuit whose diagram will be saved.\n    path : str\n        File path for the output diagram.\n    type : str, default 'timeline-svg'\n        Format used by ``stim.Circuit.diagram``.\n\n    Returns\n    -------\n    None\n        This function writes to disk and does not return a value.\n    \"\"\"\n\n    print(circuit.diagram(type=type), file=open(path, \"w\"))\n</code></pre>"},{"location":"api/stim_utils/#color_code_stim.stim_utils.separate_depolarizing_errors","title":"<code>separate_depolarizing_errors(circuit)</code>","text":"<p>Separates depolarizing errors in a Stim circuit into X and Z error components using modified probability calculations.</p> <p>DEPOLARIZE1(p) is replaced by X_ERROR(pxz) Z_ERROR(pxz). pxz = 2q1(1 - q1), where q1 = (1 - sqrt(1 - 4p/3))/2.</p> <p>DEPOLARIZE2(p) on qubits A and B is replaced by a sequence of: X_ERROR(p_comp) on A Z_ERROR(p_comp) on A X_ERROR(p_comp) on B Z_ERROR(p_comp) on B CORRELATED_ERROR(p_comp) XAXB CORRELATED_ERROR(p_comp) ZAZB p_comp = 4q2(1 - q2)(1 - 2q2 + 2q22), where q2 = (1 - (1 - 16p/15)*(1/8))/2.</p> <p>Parameters:</p> Name Type Description Default <code>circuit</code> <code>Circuit</code> <p>The input circuit containing depolarizing errors to be separated.</p> required <p>Returns:</p> Type Description <code>Circuit</code> <p>A new circuit with DEPOLARIZE1 and DEPOLARIZE2 instructions replaced by sequences of X and Z type errors according to the specified formulas.</p> <p>Raises:</p> Type Description <code>ValueError</code> <ul> <li>If DEPOLARIZE1 probability <code>p</code> is not in the range <code>[0, 0.75]</code>.</li> <li>If DEPOLARIZE2 probability <code>p</code> is not in the range <code>[0, 15/16]</code>.</li> <li>If DEPOLARIZE1 or DEPOLARIZE2 targets non-qubit values.</li> <li>If DEPOLARIZE2 has an odd number of targets.</li> </ul> Source code in <code>src/color_code_stim/stim_utils.py</code> <pre><code>def separate_depolarizing_errors(circuit: stim.Circuit) -&gt; stim.Circuit:\n    \"\"\"\n    Separates depolarizing errors in a Stim circuit into X and Z error components\n    using modified probability calculations.\n\n    DEPOLARIZE1(p) is replaced by X_ERROR(pxz) Z_ERROR(pxz).\n    pxz = 2*q1*(1 - q1), where q1 = (1 - sqrt(1 - 4p/3))/2.\n\n    DEPOLARIZE2(p) on qubits A and B is replaced by a sequence of:\n    X_ERROR(p_comp) on A\n    Z_ERROR(p_comp) on A\n    X_ERROR(p_comp) on B\n    Z_ERROR(p_comp) on B\n    CORRELATED_ERROR(p_comp) XA*XB\n    CORRELATED_ERROR(p_comp) ZA*ZB\n    p_comp = 4*q2*(1 - q2)*(1 - 2*q2 + 2*q2**2), where q2 = (1 - (1 - 16p/15)**(1/8))/2.\n\n    Parameters\n    ----------\n    circuit : stim.Circuit\n        The input circuit containing depolarizing errors to be separated.\n\n    Returns\n    -------\n    stim.Circuit\n        A new circuit with DEPOLARIZE1 and DEPOLARIZE2 instructions replaced\n        by sequences of X and Z type errors according to the specified formulas.\n\n    Raises\n    ------\n    ValueError\n        - If DEPOLARIZE1 probability `p` is not in the range `[0, 0.75]`.\n        - If DEPOLARIZE2 probability `p` is not in the range `[0, 15/16]`.\n        - If DEPOLARIZE1 or DEPOLARIZE2 targets non-qubit values.\n        - If DEPOLARIZE2 has an odd number of targets.\n    \"\"\"\n    new_circuit = stim.Circuit()\n\n    for instruction in circuit:\n        if isinstance(instruction, stim.CircuitInstruction):\n            name = instruction.name\n            targets = instruction.targets_copy()\n            args = instruction.gate_args_copy()\n\n            if name == \"DEPOLARIZE1\":\n                if len(args) != 1:\n                    raise ValueError(\n                        f\"Instruction {instruction} DEPOLARIZE1 must have exactly one argument (probability).\"\n                    )\n                p = args[0]\n                if not (0 &lt;= p &lt;= 0.75):\n                    raise ValueError(\n                        f\"DEPOLARIZE1 probability p={p} must be in [0, 0.75] for this decomposition. Found in instruction: {instruction}\"\n                    )\n\n                # Handle p=0 case explicitly\n                if p == 0:\n                    q1 = 0.0\n                    pxz = 0.0\n                else:\n                    term_under_sqrt = 1.0 - 4.0 * p / 3.0\n                    # Clamp negative due to potential floating point error\n                    if term_under_sqrt &lt; 0:\n                        term_under_sqrt = 0\n                    q1 = (1.0 - math.sqrt(term_under_sqrt)) / 2.0\n                    pxz = 2.0 * q1 * (1.0 - q1)\n\n                if pxz &gt; 1e-15:  # Add errors only if probability is non-negligible\n                    for target in targets:\n                        if not target.is_qubit_target:\n                            raise ValueError(\n                                f\"DEPOLARIZE1 target must be a qubit target. Found {target} in instruction: {instruction}\"\n                            )\n                        q = target.value\n                        new_circuit.append(\"X_ERROR\", [q], pxz)\n                        new_circuit.append(\"Z_ERROR\", [q], pxz)\n\n            elif name == \"DEPOLARIZE2\":\n                if len(args) != 1:\n                    raise ValueError(\n                        f\"Instruction {instruction} DEPOLARIZE2 must have exactly one argument (probability).\"\n                    )\n                p = args[0]\n                if not (0 &lt;= p &lt;= 15.0 / 16.0):\n                    raise ValueError(\n                        f\"DEPOLARIZE2 probability p={p} must be in [0, 15/16] for this decomposition. Found in instruction: {instruction}\"\n                    )\n\n                # Handle p=0 case explicitly\n                if p == 0:\n                    q2 = 0.0\n                    p_component = 0.0\n                else:\n                    term_in_power = 1.0 - 16.0 * p / 15.0\n                    # Clamp negative due to potential floating point error\n                    if term_in_power &lt; 0:\n                        term_in_power = 0\n                    q2 = (1.0 - term_in_power ** (1.0 / 8.0)) / 2.0\n                    # Probability of odd number of successes in 4 trials with prob q2\n                    # P(k=1) + P(k=3) = C(4,1)q^1(1-q)^3 + C(4,3)q^3(1-q)^1\n                    p_component = 4.0 * q2 * (1.0 - q2) ** 3 + 4.0 * q2**3 * (1.0 - q2)\n                    # Simplified form: 4*q2*(1-q2)*( (1-q2)^2 + q2^2 ) = 4*q2*(1-q2)*(1 - 2*q2 + 2*q2**2)\n\n                if (\n                    p_component &gt; 1e-15\n                ):  # Add errors only if probability is non-negligible\n                    if len(targets) % 2 != 0:\n                        raise ValueError(\n                            f\"DEPOLARIZE2 requires an even number of targets. Found {len(targets)} in instruction: {instruction}\"\n                        )\n\n                    for i in range(0, len(targets), 2):\n                        t_a = targets[i]\n                        t_b = targets[i + 1]\n                        if not t_a.is_qubit_target or not t_b.is_qubit_target:\n                            raise ValueError(\n                                f\"DEPOLARIZE2 targets must be qubit targets. Found {t_a}, {t_b} in instruction: {instruction}\"\n                            )\n                        qA = t_a.value\n                        qB = t_b.value\n\n                        # Single qubit X/Z errors\n                        new_circuit.append(\"X_ERROR\", [qA], p_component)\n                        new_circuit.append(\"Z_ERROR\", [qA], p_component)\n                        new_circuit.append(\"X_ERROR\", [qB], p_component)\n                        new_circuit.append(\"Z_ERROR\", [qB], p_component)\n\n                        # Two qubit X/Z errors\n                        new_circuit.append(\n                            \"CORRELATED_ERROR\",\n                            [stim.target_x(qA), stim.target_x(qB)],\n                            p_component,\n                        )\n                        new_circuit.append(\n                            \"CORRELATED_ERROR\",\n                            [stim.target_z(qA), stim.target_z(qB)],\n                            p_component,\n                        )\n            else:\n                # Copy other instructions directly\n                new_circuit.append(instruction)\n\n        elif isinstance(instruction, stim.CircuitRepeatBlock):\n            # Recursively process the body of the repeat block\n            new_body = separate_depolarizing_errors(instruction.body_copy())\n            # Create a new repeat block with the processed body\n            new_block = stim.CircuitRepeatBlock(instruction.repeat_count, new_body)\n            new_circuit.append(new_block)\n        else:\n            # Should not happen with current stim versions but good practice\n            raise TypeError(f\"Unknown object in circuit: {instruction}\")\n\n    return new_circuit\n</code></pre>"},{"location":"api/stim_utils/#color_code_stim.stim_utils.str_to_dem","title":"<code>str_to_dem(s)</code>","text":"<p>Convert a string representation back to a detector error model.</p> <p>Parameters:</p> Name Type Description Default <code>s</code> <code>str</code> <p>String representation of a detector error model.</p> required <p>Returns:</p> Type Description <code>DetectorErrorModel</code> <p>The reconstructed detector error model.</p> Source code in <code>src/color_code_stim/stim_utils.py</code> <pre><code>def str_to_dem(s: str) -&gt; stim.DetectorErrorModel:\n    \"\"\"\n    Convert a string representation back to a detector error model.\n\n    Parameters\n    ----------\n    s : str\n        String representation of a detector error model.\n\n    Returns\n    -------\n    stim.DetectorErrorModel\n        The reconstructed detector error model.\n    \"\"\"\n    buffer = io.StringIO(s)\n    return stim.DetectorErrorModel.from_file(buffer)\n</code></pre>"},{"location":"api/visualization/","title":"Visualization","text":""},{"location":"api/visualization/#color_code_stim.visualization.draw_lattice","title":"<code>draw_lattice(code, ax=None, show_axes=False, edge_color='black', edge_linewidth=1.0, face_lightness=0.3, show_data_qubits=True, data_qubit_color='black', data_qubit_size=100.0, highlight_qubits=None, highlight_qubit_color='orange', highlight_qubit_marker='^', highlight_qubits2=None, highlight_qubit_color2='purple', highlight_qubit_marker2='s', highlight_faces=None, highlight_face_lightness=1, figsize=(6, 5))</code>","text":"<p>Draws the color code lattice.</p> <p>Parameters:</p> Name Type Description Default <code>code</code> <code>ColorCode</code> <p>The ColorCode object containing the Tanner graph.</p> required <code>ax</code> <code>Axes</code> <p>The axis on which to draw the graph. If None, a new figure and axis will be created.</p> <code>None</code> <code>show_axes</code> <code>bool</code> <p>Whether to show the x- and y-axis.</p> <code>False</code> <code>edge_color</code> <code>str</code> <p>Colors for edges.</p> <code>'black'</code> <code>edge_linewidth</code> <code>float</code> <p>Linewidth for edges.</p> <code>1.0</code> <code>face_lightness</code> <code>float</code> <p>Controls the lightness of face colors. Lower values make colors lighter.</p> <code>0.3</code> <code>show_data_qubits</code> <code>bool</code> <p>Whether to draw circles representing data qubits.</p> <code>True</code> <code>data_qubit_color</code> <code>str</code> <p>Color for the data qubit circles (if shown).</p> <code>'black'</code> <code>data_qubit_size</code> <code>float</code> <p>Size for the data qubit circles (if shown).</p> <code>100.0</code> <code>highlight_qubits</code> <code>list[int] | list[tuple] | list[str] | ndarray</code> <p>Data qubits to highlight with orange triangles (by default). Can be a list of data qubit indices (ordered by code.vs.select(pauli=None)), a list of coordinate tuples [(x, y), ...], or a list of qubit names ['x-y', ...].</p> <code>None</code> <code>highlight_qubit_color</code> <code>str</code> <p>The color used to highlight specified data qubits.</p> <code>'orange'</code> <code>highlight_qubit_marker</code> <code>str</code> <p>The marker used to highlight specified data qubits.</p> <code>'^' (triangle)</code> <code>highlight_qubits2</code> <code>list[int] | list[tuple] | list[str] | ndarray</code> <p>Data qubits to highlight with purple squares (by default). Format is the same as highlight_qubits.</p> <code>None</code> <code>highlight_qubit_color2</code> <code>str</code> <p>The color used to highlight the second set of specified data qubits.</p> <code>'purple'</code> <code>highlight_qubit_marker2</code> <code>str</code> <p>The marker used to highlight the second set of specified data qubits.</p> <code>'s' (square)</code> <code>highlight_faces</code> <code>list[int] | list[tuple] | list[str] | ndarray</code> <p>Z ancillary qubits whose corresponding faces should be highlighted. Can be a list of Z ancillary qubit indices (ordered by code.vs.select(pauli=\"Z\")), a list of coordinate tuples [(x, y), ...], or a list of qubit names ['x-y', ...]. Note that for names, the actual stored name includes a '-Z' suffix.</p> <code>None</code> <code>highlight_face_lightness</code> <code>float</code> <p>Controls the lightness of highlighted faces. Higher values make colors more vibrant.</p> <code>0.7</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The axis containing the drawn lattice visualization.</p> Source code in <code>src/color_code_stim/visualization.py</code> <pre><code>def draw_lattice(\n    code: \"ColorCode\",\n    ax: Optional[plt.Axes] = None,\n    show_axes: bool = False,\n    edge_color: str = \"black\",\n    edge_linewidth: float = 1.0,\n    face_lightness: float = 0.3,\n    show_data_qubits: bool = True,\n    data_qubit_color: str = \"black\",\n    data_qubit_size: float = 100.0,\n    highlight_qubits: Optional[\n        List[int] | List[Tuple[float, float]] | List[str] | np.ndarray\n    ] = None,\n    highlight_qubit_color: str = \"orange\",\n    highlight_qubit_marker: str = \"^\",\n    highlight_qubits2: Optional[\n        List[int] | List[Tuple[float, float]] | List[str] | np.ndarray\n    ] = None,\n    highlight_qubit_color2: str = \"purple\",\n    highlight_qubit_marker2: str = \"s\",\n    highlight_faces: Optional[\n        List[int] | List[Tuple[float, float]] | List[str] | np.ndarray\n    ] = None,\n    highlight_face_lightness: float = 1,\n    figsize: Tuple[float, float] = (6, 5),\n) -&gt; plt.Axes:\n    \"\"\"\n    Draws the color code lattice.\n\n    Parameters\n    ----------\n    code : ColorCode\n        The ColorCode object containing the Tanner graph.\n    ax : matplotlib.axes.Axes, optional\n        The axis on which to draw the graph. If None, a new figure and\n        axis will be created.\n    show_axes : bool, default False\n        Whether to show the x- and y-axis.\n    edge_color : str, default 'black'\n        Colors for edges.\n    edge_linewidth : float, default 1.0\n        Linewidth for edges.\n    face_lightness : float, default 0.3\n        Controls the lightness of face colors. Lower values make colors lighter.\n    show_data_qubits : bool, default True\n        Whether to draw circles representing data qubits.\n    data_qubit_color : str, default 'black'\n        Color for the data qubit circles (if shown).\n    data_qubit_size : float, default 100.0\n        Size for the data qubit circles (if shown).\n    highlight_qubits : list[int] | list[tuple] | list[str] | np.ndarray, optional\n        Data qubits to highlight with orange triangles (by default).\n        Can be a list of data qubit indices (ordered by code.vs.select(pauli=None)),\n        a list of coordinate tuples [(x, y), ...], or a list of qubit names ['x-y', ...].\n    highlight_qubit_color : str, default 'orange'\n        The color used to highlight specified data qubits.\n    highlight_qubit_marker : str, default '^' (triangle)\n        The marker used to highlight specified data qubits.\n    highlight_qubits2 : list[int] | list[tuple] | list[str] | np.ndarray, optional\n        Data qubits to highlight with purple squares (by default).\n        Format is the same as highlight_qubits.\n    highlight_qubit_color2 : str, default 'purple'\n        The color used to highlight the second set of specified data qubits.\n    highlight_qubit_marker2 : str, default 's' (square)\n        The marker used to highlight the second set of specified data qubits.\n    highlight_faces : list[int] | list[tuple] | list[str] | np.ndarray, optional\n        Z ancillary qubits whose corresponding faces should be highlighted.\n        Can be a list of Z ancillary qubit indices (ordered by code.vs.select(pauli=\"Z\")),\n        a list of coordinate tuples [(x, y), ...], or a list of qubit names ['x-y', ...].\n        Note that for names, the actual stored name includes a '-Z' suffix.\n    highlight_face_lightness : float, default 0.7\n        Controls the lightness of highlighted faces. Higher values make colors more vibrant.\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The axis containing the drawn lattice visualization.\n    \"\"\"\n    if ax is None:\n        # figsize is set when calling plt.subplots(), not here directly\n        fig, ax = plt.subplots(figsize=figsize)\n\n    graph = code.tanner_graph\n    data_qubits = graph.vs.select(pauli=None)\n    anc_Z_qubits = graph.vs.select(pauli=\"Z\")\n\n    # --- Pre-process highlight_qubits ---\n    highlight_indices = set()\n    if isinstance(highlight_qubits, np.ndarray):\n        highlight_qubits = highlight_qubits.tolist()\n    if highlight_qubits:\n        coords_to_vid = {(v[\"x\"], v[\"y\"]): v.index for v in data_qubits}\n        name_to_vid = {v[\"name\"]: v.index for v in data_qubits}\n        data_qubit_indices = [\n            v.index for v in data_qubits\n        ]  # For index-based highlighting\n\n        for hq in highlight_qubits:\n            found_vid = None\n            if isinstance(hq, int):\n                if 0 &lt;= hq &lt; len(data_qubit_indices):\n                    found_vid = data_qubit_indices[hq]\n                else:\n                    print(f\"Warning: Highlight index {hq} is out of range.\")\n            elif isinstance(hq, tuple) and len(hq) == 2:\n                found_vid = coords_to_vid.get(hq)\n                if found_vid is None:\n                    print(f\"Warning: Highlight coordinate {hq} not found.\")\n            elif isinstance(hq, str):\n                found_vid = name_to_vid.get(hq)\n                if found_vid is None:\n                    print(f\"Warning: Highlight name '{hq}' not found.\")\n            else:\n                print(f\"Warning: Invalid highlight format: {hq}. Skipping.\")\n\n            if found_vid is not None:\n                highlight_indices.add(found_vid)\n\n    # --- Pre-process highlight_qubits2 ---\n    highlight_indices2 = set()\n    if isinstance(highlight_qubits2, np.ndarray):\n        highlight_qubits2 = highlight_qubits2.tolist()\n    if highlight_qubits2:\n        coords_to_vid = {(v[\"x\"], v[\"y\"]): v.index for v in data_qubits}\n        name_to_vid = {v[\"name\"]: v.index for v in data_qubits}\n        data_qubit_indices = [\n            v.index for v in data_qubits\n        ]  # For index-based highlighting\n\n        for hq in highlight_qubits2:\n            found_vid = None\n            if isinstance(hq, int):\n                if 0 &lt;= hq &lt; len(data_qubit_indices):\n                    found_vid = data_qubit_indices[hq]\n                else:\n                    print(f\"Warning: Highlight index {hq} is out of range.\")\n            elif isinstance(hq, tuple) and len(hq) == 2:\n                found_vid = coords_to_vid.get(hq)\n                if found_vid is None:\n                    print(f\"Warning: Highlight coordinate {hq} not found.\")\n            elif isinstance(hq, str):\n                found_vid = name_to_vid.get(hq)\n                if found_vid is None:\n                    print(f\"Warning: Highlight name '{hq}' not found.\")\n            else:\n                print(f\"Warning: Invalid highlight format: {hq}. Skipping.\")\n\n            if found_vid is not None:\n                highlight_indices2.add(found_vid)\n\n    # --- Pre-process highlight_faces ---\n    highlight_face_indices = set()\n    if isinstance(highlight_faces, np.ndarray):\n        highlight_faces = highlight_faces.tolist()\n    if highlight_faces:\n        z_coords_to_vid = {(v[\"face_x\"], v[\"face_y\"]): v.index for v in anc_Z_qubits}\n        z_name_to_vid = {v[\"name\"]: v.index for v in anc_Z_qubits}\n        # For Z qubits with name format \"x-y\", also add a mapping for \"x-y-Z\"\n        z_name_to_vid.update(\n            {\n                n.replace(\"-Z\", \"\"): idx\n                for n, idx in z_name_to_vid.items()\n                if n.endswith(\"-Z\")\n            }\n        )\n        z_qubit_indices = [\n            v.index for v in anc_Z_qubits\n        ]  # For index-based highlighting\n\n        for hf in highlight_faces:\n            found_vid = None\n            if isinstance(hf, int):\n                if 0 &lt;= hf &lt; len(z_qubit_indices):\n                    found_vid = z_qubit_indices[hf]\n                else:\n                    print(f\"Warning: Highlight face index {hf} is out of range.\")\n            elif isinstance(hf, tuple) and len(hf) == 2:\n                found_vid = z_coords_to_vid.get(hf)\n                if found_vid is None:\n                    print(f\"Warning: Highlight face coordinate {hf} not found.\")\n            elif isinstance(hf, str):\n                # Try with and without the \"-Z\" suffix\n                found_vid = z_name_to_vid.get(hf)\n                if found_vid is None:\n                    print(f\"Warning: Highlight face name '{hf}' not found.\")\n            else:\n                print(f\"Warning: Invalid highlight face format: {hf}. Skipping.\")\n\n            if found_vid is not None:\n                highlight_face_indices.add(found_vid)\n\n    # --- Color mapping ---\n    color_map = {\"r\": \"red\", \"g\": \"green\", \"b\": \"blue\"}\n\n    # Function to lighten a color based on alpha value\n    def lighten_color(color: str, alpha_factor: float) -&gt; Tuple[float, float, float]:\n        \"\"\"\n        Return a lighter version of ``color`` controlled by ``alpha_factor``.\n\n        Parameters\n        ----------\n        color : str\n            Matplotlib-compatible color specification.\n        alpha_factor : float\n            Value in ``[0, 1]`` controlling the blend with white. ``0`` yields the\n            lightest color.\n\n        Returns\n        -------\n        r, g, b : 3-tuple of float\n            Lightened RGB color values.\n        \"\"\"\n\n        r, g, b = to_rgb(color)\n        r = r + (1 - r) * (1 - alpha_factor)\n        g = g + (1 - g) * (1 - alpha_factor)\n        b = b + (1 - b) * (1 - alpha_factor)\n        return (r, g, b)\n\n    # --- Draw Polygons ---\n    all_coords = []\n    for anc_z in anc_Z_qubits:\n        anc_color_label = anc_z[\"color\"]\n        base_color = color_map.get(anc_color_label, \"gray\")\n\n        # Use highlight_face_lightness for highlighted faces\n        if anc_z.index in highlight_face_indices:\n            current_lightness = highlight_face_lightness\n        else:\n            current_lightness = face_lightness\n\n        # Lighten the color based on alpha but keep opacity at 1\n        fill_color = lighten_color(base_color, current_lightness)\n\n        neighbors = [v for v in anc_z.neighbors() if v[\"pauli\"] is None]\n\n        if len(neighbors) &lt; 3:\n            continue\n\n        ordered_vertices = []\n        if neighbors:\n            visited_edges = set()\n            current_dq = neighbors[0]\n            ordered_vertices.append(current_dq)\n            remaining_neighbors = set(neighbors[1:])\n\n            while len(ordered_vertices) &lt; len(neighbors):\n                found_next = False\n                for edge_id in graph.incident(current_dq, mode=\"all\"):\n                    edge = graph.es[edge_id]\n                    if edge[\"kind\"] == \"lattice\" and edge.index not in visited_edges:\n                        other_vertex_index = (\n                            edge.target\n                            if edge.source == current_dq.index\n                            else edge.source\n                        )\n                        other_vertex = graph.vs[other_vertex_index]\n                        if other_vertex in remaining_neighbors:\n                            ordered_vertices.append(other_vertex)\n                            remaining_neighbors.remove(other_vertex)\n                            visited_edges.add(edge.index)\n                            current_dq = other_vertex\n                            found_next = True\n                            break\n                if not found_next:\n                    break\n\n        if len(ordered_vertices) &lt; 3:\n            continue\n\n        polygon_coords = [(v[\"x\"], v[\"y\"]) for v in ordered_vertices]\n        all_coords.extend(polygon_coords)\n\n        polygon = mpl_Polygon(\n            polygon_coords,\n            closed=True,\n            edgecolor=edge_color,\n            facecolor=fill_color,\n            linewidth=edge_linewidth,\n            alpha=1.0,  # Fully opaque\n            zorder=1,  # Draw polygons behind qubits\n        )\n        ax.add_patch(polygon)\n\n    # --- Draw Data Qubits ---\n    if show_data_qubits:\n        data_x = [v[\"x\"] for v in data_qubits]\n        data_y = [v[\"y\"] for v in data_qubits]\n\n        # Draw regular data qubits (those not highlighted)\n        regular_indices = [\n            i\n            for i, v in enumerate(data_qubits)\n            if v.index not in highlight_indices and v.index not in highlight_indices2\n        ]\n        if regular_indices:\n            regular_x = [data_x[i] for i in regular_indices]\n            regular_y = [data_y[i] for i in regular_indices]\n            ax.scatter(\n                regular_x,\n                regular_y,\n                c=data_qubit_color,\n                s=data_qubit_size,\n                edgecolors=\"none\",\n                linewidths=1,\n                marker=\"o\",\n                zorder=2,\n            )\n\n        # Draw highlight_qubits with triangles (drawn last to appear on top)\n        if highlight_indices:\n            highlight1_indices = [\n                i for i, v in enumerate(data_qubits) if v.index in highlight_indices\n            ]\n            highlight1_x = [data_x[i] for i in highlight1_indices]\n            highlight1_y = [data_y[i] for i in highlight1_indices]\n            ax.scatter(\n                highlight1_x,\n                highlight1_y,\n                c=highlight_qubit_color,\n                s=data_qubit_size * 1.2,  # Slightly larger for visibility\n                edgecolors=\"black\",\n                linewidths=1,\n                marker=highlight_qubit_marker,  # Triangle marker\n                zorder=4,  # Higher zorder to appear on top of squares\n            )\n\n        # Draw highlight_qubits2 with squares\n        if highlight_indices2:\n            highlight2_indices = [\n                i for i, v in enumerate(data_qubits) if v.index in highlight_indices2\n            ]\n            highlight2_x = [data_x[i] for i in highlight2_indices]\n            highlight2_y = [data_y[i] for i in highlight2_indices]\n            ax.scatter(\n                highlight2_x,\n                highlight2_y,\n                c=highlight_qubit_color2,\n                s=data_qubit_size * 1.2,  # Slightly larger for visibility\n                edgecolors=\"black\",\n                linewidths=1,\n                marker=highlight_qubit_marker2,  # Square marker\n                zorder=3,\n            )\n\n        all_coords.extend(zip(data_x, data_y))\n\n    # --- Final Axis Adjustments ---\n    if all_coords:\n        coords_array = np.array(all_coords)\n        min_x, min_y = coords_array.min(axis=0)\n        max_x, max_y = coords_array.max(axis=0)\n        span_x = max_x - min_x\n        span_y = max_y - min_y\n\n        # Add padding based on each axis' span\n        padding_factor = 0.1  # 10% padding\n        padding_x = max(span_x * padding_factor, 1.0)  # Minimum padding\n        padding_y = max(span_y * padding_factor, 1.0)  # Minimum padding\n\n        ax.set_xlim(min_x - padding_x, max_x + padding_x)\n        ax.set_ylim(min_y - padding_y, max_y + padding_y)\n\n    # ax.set_aspect('equal', adjustable='box') # REMOVED or COMMENTED OUT\n\n    # 'auto' lets the aspect ratio be determined by data limits and figure size\n    # 'box' forces the box aspect ratio to match figsize, potentially distorting data scale\n    # 'datalim' forces the data aspect ratio to match figsize, potentially leaving whitespace\n    # Choose 'auto' or 'box' depending on desired behavior when figsize is not square\n    # Let's try 'auto' first as it's the default. If the user wants the box forced\n    # into the figsize shape, change to 'box'.\n    ax.set_aspect(\"auto\", adjustable=\"box\")  # Allows aspect ratio to follow figsize\n\n    if not show_axes:\n        ax.axis(\"off\")\n    else:\n        for spine in ax.spines.values():\n            spine.set_visible(True)\n\n    return ax\n</code></pre>"},{"location":"api/visualization/#color_code_stim.visualization.draw_tanner_graph","title":"<code>draw_tanner_graph(code, ax=None, show_axes=False, show_lattice=False, figsize=(6, 5), pauli='X', **kwargs)</code>","text":"<p>Draw the tanner graph of the code.</p> <p>Parameters:</p> Name Type Description Default <code>code</code> <code>ColorCode</code> <p>The ColorCode object containing the Tanner graph.</p> required <code>ax</code> <code>Axes</code> <p>The axis on which to draw the graph. If None, a new figure and axis will be created.</p> <code>None</code> <code>show_axes</code> <code>bool</code> <p>Whether to show the x- and y-axis.</p> <code>False</code> <code>show_lattice</code> <code>bool</code> <p>Whether to show the lattice edges in addition to the tanner graph edges.</p> <code>False</code> <code>figsize</code> <code>tuple(float, float)</code> <p>Figure size (width, height) in inches when creating a new figure.</p> <code>(6, 5)</code> <code>pauli</code> <code>Literal['Z', 'X', 'both']</code> <p>Pauli type of ancillary qubits to include in the graph.</p> <code>'X'</code> <code>**kwargs</code> <code>dict</code> <p>Additional keyword arguments to pass to igraph.plot.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>The axis containing the drawn graph.</p> Source code in <code>src/color_code_stim/visualization.py</code> <pre><code>def draw_tanner_graph(\n    code: \"ColorCode\",\n    ax: Optional[plt.Axes] = None,\n    show_axes: bool = False,\n    show_lattice: bool = False,\n    figsize: Tuple[float, float] = (6, 5),\n    pauli: Literal[\"Z\", \"X\", \"both\"] = \"X\",\n    **kwargs,\n) -&gt; plt.Axes:\n    \"\"\"\n    Draw the tanner graph of the code.\n\n    Parameters\n    ----------\n    code : ColorCode\n        The ColorCode object containing the Tanner graph.\n    ax : matplotlib.axes.Axes, optional\n        The axis on which to draw the graph. If None, a new figure and axis will be created.\n    show_axes : bool, default False\n        Whether to show the x- and y-axis.\n    show_lattice : bool, default False\n        Whether to show the lattice edges in addition to the tanner graph edges.\n    figsize : tuple(float, float), default (6, 5)\n        Figure size (width, height) in inches when creating a new figure.\n    pauli: Literal[\"Z\", \"X\", \"both\"], default \"X\"\n        Pauli type of ancillary qubits to include in the graph.\n    **kwargs : dict\n        Additional keyword arguments to pass to igraph.plot.\n\n    Returns\n    -------\n    matplotlib.axes.Axes\n        The axis containing the drawn graph.\n    \"\"\"\n    if ax is None:\n        _, ax = plt.subplots(figsize=figsize)\n\n    tanner_graph = code.tanner_graph\n    g: ig.Graph\n    if pauli == \"Z\":\n        g = tanner_graph.subgraph(tanner_graph.vs.select(pauli_ne=\"X\"))\n    elif pauli == \"X\":\n        g = tanner_graph.subgraph(tanner_graph.vs.select(pauli_ne=\"Z\"))\n    elif pauli == \"both\":\n        g = tanner_graph\n    else:\n        raise ValueError(f\"Invalid pauli: {pauli}\")\n\n    if not show_lattice:\n        g = g.subgraph_edges(g.es.select(kind=\"tanner\"))\n\n    color_dict = {\"r\": \"red\", \"g\": \"green\", \"b\": \"blue\"}\n    g.vs[\"color\"] = [\"black\" if c is None else color_dict[c] for c in g.vs[\"color\"]]\n    if show_lattice:\n        links = g.es.select(kind=\"lattice\")\n        links[\"color\"] = [color_dict[c] for c in links[\"color\"]]\n\n    ig.plot(g, target=ax, **kwargs)\n    if show_axes:\n        ax.spines[\"top\"].set_visible(True)\n        ax.spines[\"bottom\"].set_visible(True)\n        ax.spines[\"left\"].set_visible(True)\n        ax.spines[\"right\"].set_visible(True)\n        ax.xaxis.set_major_locator(AutoLocator())\n        ax.yaxis.set_major_locator(AutoLocator())\n\n    return ax\n</code></pre>"},{"location":"api/decoders/base/","title":"BaseDecoder","text":"<p>               Bases: <code>ABC</code></p> <p>Simple base interface for quantum error correction decoders.</p> <p>This is a pragmatic base class that provides a common interface for different decoding strategies without being overly abstract. Each decoder implementation handles its specific requirements while maintaining a consistent API.</p> Source code in <code>src/color_code_stim/decoders/base.py</code> <pre><code>class BaseDecoder(ABC):\n    \"\"\"\n    Simple base interface for quantum error correction decoders.\n\n    This is a pragmatic base class that provides a common interface for\n    different decoding strategies without being overly abstract. Each decoder\n    implementation handles its specific requirements while maintaining a\n    consistent API.\n    \"\"\"\n\n    @abstractmethod\n    def decode(self, detector_outcomes: np.ndarray, **kwargs) -&gt; np.ndarray:\n        \"\"\"\n        Decode detector outcomes to predict observables.\n\n        Parameters\n        ----------\n        detector_outcomes : np.ndarray\n            1D or 2D array of detector measurement outcomes.\n            If 1D, interpreted as a single sample.\n            If 2D, each row is a sample, each column a detector.\n\n        **kwargs\n            Additional decoder-specific parameters.\n\n        Returns\n        -------\n        np.ndarray\n            Predicted observable outcomes. Shape depends on the decoder\n            implementation and input dimensions.\n        \"\"\"\n        pass\n\n    def supports_comparative_decoding(self) -&gt; bool:\n        \"\"\"\n        Check if this decoder supports comparative decoding.\n\n        Returns\n        -------\n        bool\n            True if the decoder can test multiple logical classes\n            and return logical gaps for magic state distillation.\n        \"\"\"\n        return False\n\n    def supports_predecoding(self) -&gt; bool:\n        \"\"\"\n        Check if this decoder supports pre-decoding strategies.\n\n        Returns\n        -------\n        bool\n            True if the decoder supports erasure matching or\n            belief propagation pre-decoding.\n        \"\"\"\n        return False\n</code></pre>"},{"location":"api/decoders/base/#color_code_stim.decoders.BaseDecoder.decode","title":"<code>decode(detector_outcomes, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Decode detector outcomes to predict observables.</p> <p>Parameters:</p> Name Type Description Default <code>detector_outcomes</code> <code>ndarray</code> <p>1D or 2D array of detector measurement outcomes. If 1D, interpreted as a single sample. If 2D, each row is a sample, each column a detector.</p> required <code>**kwargs</code> <p>Additional decoder-specific parameters.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Predicted observable outcomes. Shape depends on the decoder implementation and input dimensions.</p> Source code in <code>src/color_code_stim/decoders/base.py</code> <pre><code>@abstractmethod\ndef decode(self, detector_outcomes: np.ndarray, **kwargs) -&gt; np.ndarray:\n    \"\"\"\n    Decode detector outcomes to predict observables.\n\n    Parameters\n    ----------\n    detector_outcomes : np.ndarray\n        1D or 2D array of detector measurement outcomes.\n        If 1D, interpreted as a single sample.\n        If 2D, each row is a sample, each column a detector.\n\n    **kwargs\n        Additional decoder-specific parameters.\n\n    Returns\n    -------\n    np.ndarray\n        Predicted observable outcomes. Shape depends on the decoder\n        implementation and input dimensions.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/decoders/base/#color_code_stim.decoders.BaseDecoder.supports_comparative_decoding","title":"<code>supports_comparative_decoding()</code>","text":"<p>Check if this decoder supports comparative decoding.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the decoder can test multiple logical classes and return logical gaps for magic state distillation.</p> Source code in <code>src/color_code_stim/decoders/base.py</code> <pre><code>def supports_comparative_decoding(self) -&gt; bool:\n    \"\"\"\n    Check if this decoder supports comparative decoding.\n\n    Returns\n    -------\n    bool\n        True if the decoder can test multiple logical classes\n        and return logical gaps for magic state distillation.\n    \"\"\"\n    return False\n</code></pre>"},{"location":"api/decoders/base/#color_code_stim.decoders.BaseDecoder.supports_predecoding","title":"<code>supports_predecoding()</code>","text":"<p>Check if this decoder supports pre-decoding strategies.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the decoder supports erasure matching or belief propagation pre-decoding.</p> Source code in <code>src/color_code_stim/decoders/base.py</code> <pre><code>def supports_predecoding(self) -&gt; bool:\n    \"\"\"\n    Check if this decoder supports pre-decoding strategies.\n\n    Returns\n    -------\n    bool\n        True if the decoder supports erasure matching or\n        belief propagation pre-decoding.\n    \"\"\"\n    return False\n</code></pre>"},{"location":"api/decoders/belief_concat_matching_decoder/","title":"BeliefConcatMatchingDecoder","text":"<p>               Bases: <code>BaseDecoder</code></p> <p>Composite decoder combining belief propagation pre-decoding with concatenated matching.</p> <p>This decoder implements the sophisticated workflow where belief propagation is used as a pre-decoding step to update DEM probabilities, followed by concatenated matching decoding using the updated probabilities. This approach can improve decoding performance by incorporating soft information from BP.</p> <p>Key Features: - BP pre-decoding with probability updates - Seamless integration with ConcatMatchingDecoder - Batch processing support - Full backward compatibility with existing parameters - Numerical stability with probability clipping</p> <p>Attributes:</p> Name Type Description <code>dem_manager</code> <code>DemManager</code> <p>Manager for detector error models and decompositions</p> <code>circuit_type</code> <code>str</code> <p>Type of circuit being decoded</p> <code>num_obs</code> <code>int</code> <p>Number of observables</p> <code>comparative_decoding</code> <code>bool</code> <p>Whether comparative decoding is enabled</p> <code>bp_decoder</code> <code>BPDecoder</code> <p>Internal belief propagation decoder instance</p> <code>concat_decoder</code> <code>ConcatMatchingDecoder</code> <p>Internal concatenated matching decoder instance</p> Source code in <code>src/color_code_stim/decoders/belief_concat_matching_decoder.py</code> <pre><code>class BeliefConcatMatchingDecoder(BaseDecoder):\n    \"\"\"\n    Composite decoder combining belief propagation pre-decoding with concatenated matching.\n\n    This decoder implements the sophisticated workflow where belief propagation is used\n    as a pre-decoding step to update DEM probabilities, followed by concatenated matching\n    decoding using the updated probabilities. This approach can improve decoding performance\n    by incorporating soft information from BP.\n\n    Key Features:\n    - BP pre-decoding with probability updates\n    - Seamless integration with ConcatMatchingDecoder\n    - Batch processing support\n    - Full backward compatibility with existing parameters\n    - Numerical stability with probability clipping\n\n    Attributes\n    ----------\n    dem_manager : DemManager\n        Manager for detector error models and decompositions\n    circuit_type : str\n        Type of circuit being decoded\n    num_obs : int\n        Number of observables\n    comparative_decoding : bool\n        Whether comparative decoding is enabled\n    bp_decoder : BPDecoder\n        Internal belief propagation decoder instance\n    concat_decoder : ConcatMatchingDecoder\n        Internal concatenated matching decoder instance\n    \"\"\"\n\n    def __init__(\n        self,\n        dem_manager: DemManager,\n        circuit_type: str,\n        num_obs: int,\n        comparative_decoding: bool = False,\n        bp_cache_inputs: bool = True,\n    ):\n        \"\"\"\n        Initialize the belief concatenated matching decoder.\n\n        Parameters\n        ----------\n        dem_manager : DemManager\n            Manager providing access to decomposed DEMs and matrices\n        circuit_type : str\n            Type of circuit (tri, rec, rec_stability, growing, cult+growing)\n        num_obs : int\n            Number of observables in the quantum code\n        comparative_decoding : bool, default False\n            Whether to enable comparative decoding for logical gap calculation\n        bp_cache_inputs : bool, default True\n            Whether to cache BP inputs for efficiency\n        \"\"\"\n        self.dem_manager = dem_manager\n        self.circuit_type = circuit_type\n        self.num_obs = num_obs\n        self.comparative_decoding = comparative_decoding\n\n        # Create internal decoder instances\n        self.bp_decoder = BPDecoder(\n            dem_manager=dem_manager,\n            comparative_decoding=comparative_decoding,\n            cache_inputs=bp_cache_inputs,\n        )\n\n        self.concat_decoder = ConcatMatchingDecoder(\n            dem_manager=dem_manager,\n            circuit_type=circuit_type,\n            num_obs=num_obs,\n            comparative_decoding=comparative_decoding,\n        )\n\n        # Cache for BP inputs (for compatibility with existing code)\n        self._bp_inputs: Dict[str, np.ndarray] = {}\n\n    def supports_comparative_decoding(self) -&gt; bool:\n        \"\"\"Return True - this decoder supports comparative decoding.\"\"\"\n        return True\n\n    def supports_predecoding(self) -&gt; bool:\n        \"\"\"Return True - this decoder supports pre-decoding strategies.\"\"\"\n        return True\n\n    def decode(\n        self,\n        detector_outcomes: np.ndarray,\n        colors: Union[str, List[str]] = \"all\",\n        logical_value: Union[bool, Sequence[bool], None] = None,\n        bp_prms: Optional[Dict] = None,\n        erasure_matcher_predecoding: bool = False,\n        partial_correction_by_predecoding: bool = False,\n        full_output: bool = False,\n        check_validity: bool = False,\n        verbose: bool = False,\n        **kwargs\n    ) -&gt; Union[np.ndarray, Tuple[np.ndarray, dict]]:\n        \"\"\"\n        Decode detector outcomes using BP pre-decoding + concatenated MWPM decoding.\n\n        This method first runs belief propagation to obtain soft information (log-likelihood\n        ratios), converts these to probabilities, updates the DEM probabilities accordingly,\n        and then runs concatenated matching decoding with the updated DEMs.\n\n        Parameters\n        ----------\n        detector_outcomes : np.ndarray\n            1D or 2D array of detector measurement outcomes.\n            If 1D, interpreted as a single sample.\n            If 2D, each row is a sample, each column a detector.\n        colors : str or list of str, default 'all'\n            Colors to use for decoding. Can be 'all', one of {'r', 'g', 'b'},\n            or a list containing any combination of {'r', 'g', 'b'}.\n        logical_value : bool or sequence of bool, optional\n            Logical value(s) to use for decoding. If None and comparative_decoding\n            is True, all possible logical value combinations will be tested.\n        bp_prms : dict, optional\n            Parameters for the belief propagation decoder (e.g., max_iter).\n        erasure_matcher_predecoding : bool, default False\n            Whether to use erasure matcher as a pre-decoding step.\n        partial_correction_by_predecoding : bool, default False\n            Whether to apply partial correction from erasure matcher predecoding.\n        full_output : bool, default False\n            Whether to return extra information about the decoding process.\n        check_validity : bool, default False\n            Whether to check the validity of predicted error patterns.\n        verbose : bool, default False\n            Whether to print additional information during decoding.\n        **kwargs\n            Additional parameters for compatibility.\n\n        Returns\n        -------\n        np.ndarray or tuple\n            If full_output is False: predicted observables as bool array.\n            If full_output is True: tuple of (predictions, extra_outputs_dict).\n        \"\"\"\n        if bp_prms is None:\n            bp_prms = {}\n\n        # Ensure detector_outcomes is 2D for batch processing\n        detector_outcomes = np.asarray(detector_outcomes, dtype=bool)\n        original_shape_1d = detector_outcomes.ndim == 1\n        if original_shape_1d:\n            detector_outcomes = detector_outcomes.reshape(1, -1)\n\n        # Process color selection\n        if colors == \"all\":\n            colors = [\"r\", \"g\", \"b\"]\n        elif colors in [\"r\", \"g\", \"b\"]:\n            colors = [colors]\n\n        if verbose:\n            print(\"Running BP pre-decoding...\")\n\n        # Step 1: Run BP pre-decoding to get log-likelihood ratios\n        _, llrs, _ = self.bp_decoder.decode(detector_outcomes, **bp_prms)\n\n        # Step 2: Convert LLRs to probabilities with numerical stability\n        bp_probs = 1 / (1 + np.exp(llrs))\n        eps = 1e-14\n        bp_probs = bp_probs.clip(eps, 1 - eps)\n\n        # Update BP inputs cache (for compatibility with existing code)\n        self._update_bp_inputs_cache()\n\n        # Step 3: Process each sample with updated DEM probabilities\n        results = []\n        extra_outputs_list = []\n\n        for i, det_outcomes_single in enumerate(detector_outcomes):\n            if verbose:\n                print(f\"Processing sample {i+1}/{len(detector_outcomes)} with updated DEMs...\")\n\n            # Step 4: Create updated DEMs using BP probabilities\n            updated_dems = self._create_updated_dems(colors, bp_probs[i] if bp_probs.ndim &gt; 1 else bp_probs)\n\n            # Step 5: Run concatenated matching with updated DEMs\n            sample_result = self._decode_with_updated_dems(\n                det_outcomes_single.reshape(1, -1),\n                updated_dems,\n                colors=colors,\n                logical_value=logical_value,\n                erasure_matcher_predecoding=erasure_matcher_predecoding,\n                partial_correction_by_predecoding=partial_correction_by_predecoding,\n                full_output=full_output,\n                check_validity=check_validity,\n                verbose=verbose,\n            )\n\n            if full_output:\n                obs_pred, extra_output = sample_result\n                results.append(obs_pred)\n                extra_outputs_list.append(extra_output)\n            else:\n                results.append(sample_result)\n\n        # Step 6: Aggregate results\n        final_results = np.concatenate(results, axis=0)\n\n        if original_shape_1d and final_results.ndim &gt; 1 and final_results.shape[0] == 1:\n            final_results = final_results.ravel()\n\n        if full_output:\n            # Aggregate extra outputs\n            aggregated_extra = {}\n            for key in extra_outputs_list[0].keys():\n                try:\n                    aggregated_extra[key] = np.concatenate([eo[key] for eo in extra_outputs_list], axis=0)\n                except (ValueError, np.AxisError):\n                    # Handle cases where concatenation fails (e.g., different shapes)\n                    aggregated_extra[key] = [eo[key] for eo in extra_outputs_list]\n\n            return final_results, aggregated_extra\n        else:\n            return final_results\n\n    def _update_bp_inputs_cache(self):\n        \"\"\"Update BP inputs cache for compatibility with existing code.\"\"\"\n        if not self._bp_inputs:\n            if self.comparative_decoding:\n                dem = remove_obs_from_dem(self.dem_manager.dem_xz)\n            else:\n                dem = self.dem_manager.dem_xz\n            H, _, p = dem_to_parity_check(dem)\n            self._bp_inputs[\"H\"] = H\n            self._bp_inputs[\"p\"] = p\n\n    def _create_updated_dems(self, colors: List[str], bp_probs: np.ndarray) -&gt; Dict[str, Tuple[Tuple, Tuple]]:\n        \"\"\"\n        Create updated DEM matrices and probabilities using BP probabilities for each color.\n\n        Parameters\n        ----------\n        colors : list of str\n            Colors to create updated DEMs for\n        bp_probs : np.ndarray\n            BP probabilities to use for DEM updates\n\n        Returns\n        -------\n        dict\n            Dictionary mapping color to ((H1, p1), (H2, p2)) tuples where:\n            - H1, H2 are parity check matrices for stages 1 and 2\n            - p1, p2 are probability arrays for stages 1 and 2\n        \"\"\"\n        updated_dem_data = {}\n\n        for c in colors:\n            dem1_sym, dem2_sym = self.dem_manager.dems_decomposed[c].dems_symbolic\n\n            # Create updated DEMs using BP probabilities  \n            dem1, _ = dem1_sym.to_dem(bp_probs)\n            dem2, _ = dem2_sym.to_dem(bp_probs, sort=True)\n\n            # Extract parity check matrices and probabilities\n            H1, _, p1 = dem_to_parity_check(dem1)\n            H2, _, p2 = dem_to_parity_check(dem2)\n\n            # Store in the format expected by ConcatMatchingDecoder\n            updated_dem_data[c] = ((H1, p1), (H2, p2))\n\n        return updated_dem_data\n\n    def _decode_with_updated_dems(\n        self,\n        detector_outcomes: np.ndarray,\n        updated_dem_data: Dict[str, Tuple[Tuple, Tuple]],\n        **kwargs\n    ) -&gt; Union[np.ndarray, Tuple[np.ndarray, dict]]:\n        \"\"\"\n        Run concatenated matching decoding with updated DEM data.\n\n        This method passes custom DEM matrices and probabilities to the\n        ConcatMatchingDecoder, avoiding any modification of shared state.\n\n        Parameters\n        ----------\n        detector_outcomes : np.ndarray\n            Single sample detector outcomes (2D with shape (1, n_detectors))\n        updated_dem_data : dict\n            Dictionary mapping color to ((H1, p1), (H2, p2)) tuples\n        **kwargs\n            Additional arguments to pass to the concatenated decoder\n\n        Returns\n        -------\n        Union[np.ndarray, Tuple[np.ndarray, dict]]\n            Decoding results from concatenated matching decoder\n        \"\"\"\n        # Pass custom DEM data to the concatenated decoder\n        return self.concat_decoder.decode(\n            detector_outcomes, \n            custom_dem_data=updated_dem_data,\n            **kwargs\n        )\n\n    def get_bp_decoder(self) -&gt; BPDecoder:\n        \"\"\"Get access to the internal BP decoder.\"\"\"\n        return self.bp_decoder\n\n    def get_concat_decoder(self) -&gt; ConcatMatchingDecoder:\n        \"\"\"Get access to the internal concatenated matching decoder.\"\"\"\n        return self.concat_decoder\n</code></pre>"},{"location":"api/decoders/belief_concat_matching_decoder/#color_code_stim.decoders.BeliefConcatMatchingDecoder.__init__","title":"<code>__init__(dem_manager, circuit_type, num_obs, comparative_decoding=False, bp_cache_inputs=True)</code>","text":"<p>Initialize the belief concatenated matching decoder.</p> <p>Parameters:</p> Name Type Description Default <code>dem_manager</code> <code>DemManager</code> <p>Manager providing access to decomposed DEMs and matrices</p> required <code>circuit_type</code> <code>str</code> <p>Type of circuit (tri, rec, rec_stability, growing, cult+growing)</p> required <code>num_obs</code> <code>int</code> <p>Number of observables in the quantum code</p> required <code>comparative_decoding</code> <code>bool</code> <p>Whether to enable comparative decoding for logical gap calculation</p> <code>False</code> <code>bp_cache_inputs</code> <code>bool</code> <p>Whether to cache BP inputs for efficiency</p> <code>True</code> Source code in <code>src/color_code_stim/decoders/belief_concat_matching_decoder.py</code> <pre><code>def __init__(\n    self,\n    dem_manager: DemManager,\n    circuit_type: str,\n    num_obs: int,\n    comparative_decoding: bool = False,\n    bp_cache_inputs: bool = True,\n):\n    \"\"\"\n    Initialize the belief concatenated matching decoder.\n\n    Parameters\n    ----------\n    dem_manager : DemManager\n        Manager providing access to decomposed DEMs and matrices\n    circuit_type : str\n        Type of circuit (tri, rec, rec_stability, growing, cult+growing)\n    num_obs : int\n        Number of observables in the quantum code\n    comparative_decoding : bool, default False\n        Whether to enable comparative decoding for logical gap calculation\n    bp_cache_inputs : bool, default True\n        Whether to cache BP inputs for efficiency\n    \"\"\"\n    self.dem_manager = dem_manager\n    self.circuit_type = circuit_type\n    self.num_obs = num_obs\n    self.comparative_decoding = comparative_decoding\n\n    # Create internal decoder instances\n    self.bp_decoder = BPDecoder(\n        dem_manager=dem_manager,\n        comparative_decoding=comparative_decoding,\n        cache_inputs=bp_cache_inputs,\n    )\n\n    self.concat_decoder = ConcatMatchingDecoder(\n        dem_manager=dem_manager,\n        circuit_type=circuit_type,\n        num_obs=num_obs,\n        comparative_decoding=comparative_decoding,\n    )\n\n    # Cache for BP inputs (for compatibility with existing code)\n    self._bp_inputs: Dict[str, np.ndarray] = {}\n</code></pre>"},{"location":"api/decoders/belief_concat_matching_decoder/#color_code_stim.decoders.BeliefConcatMatchingDecoder.decode","title":"<code>decode(detector_outcomes, colors='all', logical_value=None, bp_prms=None, erasure_matcher_predecoding=False, partial_correction_by_predecoding=False, full_output=False, check_validity=False, verbose=False, **kwargs)</code>","text":"<p>Decode detector outcomes using BP pre-decoding + concatenated MWPM decoding.</p> <p>This method first runs belief propagation to obtain soft information (log-likelihood ratios), converts these to probabilities, updates the DEM probabilities accordingly, and then runs concatenated matching decoding with the updated DEMs.</p> <p>Parameters:</p> Name Type Description Default <code>detector_outcomes</code> <code>ndarray</code> <p>1D or 2D array of detector measurement outcomes. If 1D, interpreted as a single sample. If 2D, each row is a sample, each column a detector.</p> required <code>colors</code> <code>str or list of str</code> <p>Colors to use for decoding. Can be 'all', one of {'r', 'g', 'b'}, or a list containing any combination of {'r', 'g', 'b'}.</p> <code>'all'</code> <code>logical_value</code> <code>bool or sequence of bool</code> <p>Logical value(s) to use for decoding. If None and comparative_decoding is True, all possible logical value combinations will be tested.</p> <code>None</code> <code>bp_prms</code> <code>dict</code> <p>Parameters for the belief propagation decoder (e.g., max_iter).</p> <code>None</code> <code>erasure_matcher_predecoding</code> <code>bool</code> <p>Whether to use erasure matcher as a pre-decoding step.</p> <code>False</code> <code>partial_correction_by_predecoding</code> <code>bool</code> <p>Whether to apply partial correction from erasure matcher predecoding.</p> <code>False</code> <code>full_output</code> <code>bool</code> <p>Whether to return extra information about the decoding process.</p> <code>False</code> <code>check_validity</code> <code>bool</code> <p>Whether to check the validity of predicted error patterns.</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>Whether to print additional information during decoding.</p> <code>False</code> <code>**kwargs</code> <p>Additional parameters for compatibility.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray or tuple</code> <p>If full_output is False: predicted observables as bool array. If full_output is True: tuple of (predictions, extra_outputs_dict).</p> Source code in <code>src/color_code_stim/decoders/belief_concat_matching_decoder.py</code> <pre><code>def decode(\n    self,\n    detector_outcomes: np.ndarray,\n    colors: Union[str, List[str]] = \"all\",\n    logical_value: Union[bool, Sequence[bool], None] = None,\n    bp_prms: Optional[Dict] = None,\n    erasure_matcher_predecoding: bool = False,\n    partial_correction_by_predecoding: bool = False,\n    full_output: bool = False,\n    check_validity: bool = False,\n    verbose: bool = False,\n    **kwargs\n) -&gt; Union[np.ndarray, Tuple[np.ndarray, dict]]:\n    \"\"\"\n    Decode detector outcomes using BP pre-decoding + concatenated MWPM decoding.\n\n    This method first runs belief propagation to obtain soft information (log-likelihood\n    ratios), converts these to probabilities, updates the DEM probabilities accordingly,\n    and then runs concatenated matching decoding with the updated DEMs.\n\n    Parameters\n    ----------\n    detector_outcomes : np.ndarray\n        1D or 2D array of detector measurement outcomes.\n        If 1D, interpreted as a single sample.\n        If 2D, each row is a sample, each column a detector.\n    colors : str or list of str, default 'all'\n        Colors to use for decoding. Can be 'all', one of {'r', 'g', 'b'},\n        or a list containing any combination of {'r', 'g', 'b'}.\n    logical_value : bool or sequence of bool, optional\n        Logical value(s) to use for decoding. If None and comparative_decoding\n        is True, all possible logical value combinations will be tested.\n    bp_prms : dict, optional\n        Parameters for the belief propagation decoder (e.g., max_iter).\n    erasure_matcher_predecoding : bool, default False\n        Whether to use erasure matcher as a pre-decoding step.\n    partial_correction_by_predecoding : bool, default False\n        Whether to apply partial correction from erasure matcher predecoding.\n    full_output : bool, default False\n        Whether to return extra information about the decoding process.\n    check_validity : bool, default False\n        Whether to check the validity of predicted error patterns.\n    verbose : bool, default False\n        Whether to print additional information during decoding.\n    **kwargs\n        Additional parameters for compatibility.\n\n    Returns\n    -------\n    np.ndarray or tuple\n        If full_output is False: predicted observables as bool array.\n        If full_output is True: tuple of (predictions, extra_outputs_dict).\n    \"\"\"\n    if bp_prms is None:\n        bp_prms = {}\n\n    # Ensure detector_outcomes is 2D for batch processing\n    detector_outcomes = np.asarray(detector_outcomes, dtype=bool)\n    original_shape_1d = detector_outcomes.ndim == 1\n    if original_shape_1d:\n        detector_outcomes = detector_outcomes.reshape(1, -1)\n\n    # Process color selection\n    if colors == \"all\":\n        colors = [\"r\", \"g\", \"b\"]\n    elif colors in [\"r\", \"g\", \"b\"]:\n        colors = [colors]\n\n    if verbose:\n        print(\"Running BP pre-decoding...\")\n\n    # Step 1: Run BP pre-decoding to get log-likelihood ratios\n    _, llrs, _ = self.bp_decoder.decode(detector_outcomes, **bp_prms)\n\n    # Step 2: Convert LLRs to probabilities with numerical stability\n    bp_probs = 1 / (1 + np.exp(llrs))\n    eps = 1e-14\n    bp_probs = bp_probs.clip(eps, 1 - eps)\n\n    # Update BP inputs cache (for compatibility with existing code)\n    self._update_bp_inputs_cache()\n\n    # Step 3: Process each sample with updated DEM probabilities\n    results = []\n    extra_outputs_list = []\n\n    for i, det_outcomes_single in enumerate(detector_outcomes):\n        if verbose:\n            print(f\"Processing sample {i+1}/{len(detector_outcomes)} with updated DEMs...\")\n\n        # Step 4: Create updated DEMs using BP probabilities\n        updated_dems = self._create_updated_dems(colors, bp_probs[i] if bp_probs.ndim &gt; 1 else bp_probs)\n\n        # Step 5: Run concatenated matching with updated DEMs\n        sample_result = self._decode_with_updated_dems(\n            det_outcomes_single.reshape(1, -1),\n            updated_dems,\n            colors=colors,\n            logical_value=logical_value,\n            erasure_matcher_predecoding=erasure_matcher_predecoding,\n            partial_correction_by_predecoding=partial_correction_by_predecoding,\n            full_output=full_output,\n            check_validity=check_validity,\n            verbose=verbose,\n        )\n\n        if full_output:\n            obs_pred, extra_output = sample_result\n            results.append(obs_pred)\n            extra_outputs_list.append(extra_output)\n        else:\n            results.append(sample_result)\n\n    # Step 6: Aggregate results\n    final_results = np.concatenate(results, axis=0)\n\n    if original_shape_1d and final_results.ndim &gt; 1 and final_results.shape[0] == 1:\n        final_results = final_results.ravel()\n\n    if full_output:\n        # Aggregate extra outputs\n        aggregated_extra = {}\n        for key in extra_outputs_list[0].keys():\n            try:\n                aggregated_extra[key] = np.concatenate([eo[key] for eo in extra_outputs_list], axis=0)\n            except (ValueError, np.AxisError):\n                # Handle cases where concatenation fails (e.g., different shapes)\n                aggregated_extra[key] = [eo[key] for eo in extra_outputs_list]\n\n        return final_results, aggregated_extra\n    else:\n        return final_results\n</code></pre>"},{"location":"api/decoders/belief_concat_matching_decoder/#color_code_stim.decoders.BeliefConcatMatchingDecoder.get_bp_decoder","title":"<code>get_bp_decoder()</code>","text":"<p>Get access to the internal BP decoder.</p> Source code in <code>src/color_code_stim/decoders/belief_concat_matching_decoder.py</code> <pre><code>def get_bp_decoder(self) -&gt; BPDecoder:\n    \"\"\"Get access to the internal BP decoder.\"\"\"\n    return self.bp_decoder\n</code></pre>"},{"location":"api/decoders/belief_concat_matching_decoder/#color_code_stim.decoders.BeliefConcatMatchingDecoder.get_concat_decoder","title":"<code>get_concat_decoder()</code>","text":"<p>Get access to the internal concatenated matching decoder.</p> Source code in <code>src/color_code_stim/decoders/belief_concat_matching_decoder.py</code> <pre><code>def get_concat_decoder(self) -&gt; ConcatMatchingDecoder:\n    \"\"\"Get access to the internal concatenated matching decoder.\"\"\"\n    return self.concat_decoder\n</code></pre>"},{"location":"api/decoders/belief_concat_matching_decoder/#color_code_stim.decoders.BeliefConcatMatchingDecoder.supports_comparative_decoding","title":"<code>supports_comparative_decoding()</code>","text":"<p>Return True - this decoder supports comparative decoding.</p> Source code in <code>src/color_code_stim/decoders/belief_concat_matching_decoder.py</code> <pre><code>def supports_comparative_decoding(self) -&gt; bool:\n    \"\"\"Return True - this decoder supports comparative decoding.\"\"\"\n    return True\n</code></pre>"},{"location":"api/decoders/belief_concat_matching_decoder/#color_code_stim.decoders.BeliefConcatMatchingDecoder.supports_predecoding","title":"<code>supports_predecoding()</code>","text":"<p>Return True - this decoder supports pre-decoding strategies.</p> Source code in <code>src/color_code_stim/decoders/belief_concat_matching_decoder.py</code> <pre><code>def supports_predecoding(self) -&gt; bool:\n    \"\"\"Return True - this decoder supports pre-decoding strategies.\"\"\"\n    return True\n</code></pre>"},{"location":"api/decoders/bp_decoder/","title":"BPDecoder","text":"<p>               Bases: <code>BaseDecoder</code></p> <p>Belief propagation decoder for color codes.</p> <p>This decoder uses the LDPC belief propagation algorithm to decode detector outcomes. It requires the optional 'ldpc' package and provides an alternative to the concatenated matching decoder, particularly useful for pre-decoding in hybrid strategies.</p> <p>Key Features: - LDPC belief propagation with configurable iterations - Support for both 1D and 2D detector outcome arrays - Optional DEM observable removal for comparative decoding - Returns predictions, log-likelihood ratios, and convergence information - Graceful handling of missing ldpc dependency</p> <p>Attributes:</p> Name Type Description <code>dem_manager</code> <code>DEMManager</code> <p>Manager for detector error models and matrices</p> <code>comparative_decoding</code> <code>bool</code> <p>Whether to remove observables from DEM before decoding</p> <code>_cached_inputs</code> <code>dict or None</code> <p>Cached parity check matrix and probabilities for efficiency</p> Source code in <code>src/color_code_stim/decoders/bp_decoder.py</code> <pre><code>class BPDecoder(BaseDecoder):\n    \"\"\"\n    Belief propagation decoder for color codes.\n\n    This decoder uses the LDPC belief propagation algorithm to decode detector\n    outcomes. It requires the optional 'ldpc' package and provides an alternative\n    to the concatenated matching decoder, particularly useful for pre-decoding\n    in hybrid strategies.\n\n    Key Features:\n    - LDPC belief propagation with configurable iterations\n    - Support for both 1D and 2D detector outcome arrays\n    - Optional DEM observable removal for comparative decoding\n    - Returns predictions, log-likelihood ratios, and convergence information\n    - Graceful handling of missing ldpc dependency\n\n    Attributes\n    ----------\n    dem_manager : DEMManager\n        Manager for detector error models and matrices\n    comparative_decoding : bool\n        Whether to remove observables from DEM before decoding\n    _cached_inputs : dict or None\n        Cached parity check matrix and probabilities for efficiency\n    \"\"\"\n\n    def __init__(\n        self,\n        dem_manager: DemManager,\n        comparative_decoding: bool = False,\n        cache_inputs: bool = True,\n    ):\n        \"\"\"\n        Initialize the belief propagation decoder.\n\n        Parameters\n        ----------\n        dem_manager : DEMManager\n            Manager providing access to detector error models\n        comparative_decoding : bool, default False\n            Whether to remove observables from DEM before decoding\n        cache_inputs : bool, default True\n            Whether to cache the parity check matrix and probabilities\n        \"\"\"\n        self.dem_manager = dem_manager\n        self.comparative_decoding = comparative_decoding\n        self.cache_inputs = cache_inputs\n        self._cached_inputs: Optional[Dict[str, np.ndarray]] = None\n\n    def supports_comparative_decoding(self) -&gt; bool:\n        \"\"\"Return True - this decoder can work with comparative decoding.\"\"\"\n        return True\n\n    def supports_predecoding(self) -&gt; bool:\n        \"\"\"Return False - this decoder is typically used as pre-decoding itself.\"\"\"\n        return False\n\n    def decode(\n        self, detector_outcomes: np.ndarray, max_iter: int = 10, **kwargs\n    ) -&gt; Tuple[np.ndarray, np.ndarray, Union[bool, np.ndarray]]:\n        \"\"\"\n        Decode detector outcomes using belief propagation.\n\n        This method uses the LDPC belief propagation decoder to decode detector\n        outcomes. It handles both single samples (1D) and multiple samples (2D).\n\n        Parameters\n        ----------\n        detector_outcomes : np.ndarray\n            1D or 2D array of detector measurement outcomes to decode.\n            For 1D: single sample with detector outcomes.\n            For 2D: multiple samples, each row is a sample.\n        max_iter : int, default 10\n            Maximum number of belief propagation iterations to perform.\n        **kwargs\n            Additional keyword arguments to pass to the BpDecoder constructor.\n\n        Returns\n        -------\n        tuple\n            (pred, llrs, converge) where:\n            - pred: Predicted error pattern (same dimensionality as input)\n            - llrs: Log probability ratios for each bit\n            - converge: Convergence status (bool for 1D, array for 2D)\n\n        Raises\n        ------\n        ImportError\n            If the 'ldpc' package is not installed.\n        ValueError\n            If detector_outcomes has invalid dimensions (not 1D or 2D).\n        \"\"\"\n        try:\n            from ldpc import BpDecoder\n        except ImportError:\n            raise ImportError(\n                \"The 'ldpc' package is required for belief propagation decoding. \"\n                \"Please install it using: pip install ldpc\"\n            )\n\n        # Get or compute parity check matrix and probabilities\n        if self.cache_inputs and self._cached_inputs is not None:\n            H = self._cached_inputs[\"H\"]\n            p = self._cached_inputs[\"p\"]\n        else:\n            H, p = self._prepare_bp_inputs()\n            if self.cache_inputs:\n                self._cached_inputs = {\"H\": H, \"p\": p}\n\n        detector_outcomes = np.asarray(detector_outcomes)\n\n        # Filter detector outcomes to match the DEM dimensions when observables are removed\n        if self.comparative_decoding:\n            expected_detectors = H.shape[0]\n            if detector_outcomes.shape[-1] != expected_detectors:\n                # Truncate to match the number of detectors in the filtered DEM\n                detector_outcomes = detector_outcomes[..., :expected_detectors]\n\n        # Filter kwargs to only include valid BpDecoder parameters\n        bp_kwargs = {k: v for k, v in kwargs.items() if k in ['bp_method', 'schedule', 'ms_scaling_factor', 'bp_method_type']}\n\n        if detector_outcomes.ndim == 1:\n            # Single sample decoding\n            bpd = BpDecoder(H, error_channel=p, max_iter=max_iter, **bp_kwargs)\n            pred = bpd.decode(detector_outcomes)\n            llrs = bpd.log_prob_ratios\n            converge = bpd.converge\n\n        elif detector_outcomes.ndim == 2:\n            # Multi-sample decoding\n            pred = []\n            llrs = []\n            converge = []\n\n            for det_sng in detector_outcomes:\n                bpd = BpDecoder(H, error_channel=p, max_iter=max_iter, **bp_kwargs)\n                pred.append(bpd.decode(det_sng))\n                llrs.append(bpd.log_prob_ratios)\n                converge.append(bpd.converge)\n\n            pred = np.stack(pred, axis=0)\n            llrs = np.stack(llrs, axis=0)\n            converge = np.stack(converge, axis=0)\n\n        else:\n            raise ValueError(\n                f\"detector_outcomes must be 1D or 2D, got shape {detector_outcomes.shape}\"\n            )\n\n        return pred, llrs, converge\n\n    def _prepare_bp_inputs(self) -&gt; Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Prepare parity check matrix and probabilities for BP decoding.\n\n        Returns\n        -------\n        tuple\n            (H, p) where H is the parity check matrix and p is the error probabilities\n        \"\"\"\n        dem = self.dem_manager.dem_xz\n\n        if self.comparative_decoding:\n            # Remove observables from DEM for comparative decoding\n            dem = remove_obs_from_dem(dem)\n\n        # Convert DEM to parity check matrix and probabilities\n        H, _, p = dem_to_parity_check(dem)\n\n        # Convert H to uint8 as required by ldpc.BpDecoder\n        H = H.astype('uint8')\n\n        return H, p\n\n    def clear_cache(self):\n        \"\"\"Clear cached inputs to force recomputation on next decode.\"\"\"\n        self._cached_inputs = None\n\n    def get_parity_check_info(self) -&gt; Dict[str, Union[int, float]]:\n        \"\"\"\n        Get information about the parity check matrix.\n\n        Returns\n        -------\n        dict\n            Dictionary containing matrix dimensions, density, and statistics\n        \"\"\"\n        if self._cached_inputs is None:\n            H, p = self._prepare_bp_inputs()\n        else:\n            H = self._cached_inputs[\"H\"]\n            p = self._cached_inputs[\"p\"]\n\n        return {\n            \"matrix_shape\": H.shape,\n            \"num_checks\": H.shape[0],\n            \"num_variables\": H.shape[1],\n            \"density\": H.nnz / (H.shape[0] * H.shape[1]),\n            \"avg_check_degree\": H.sum(axis=1).mean(),\n            \"avg_variable_degree\": H.sum(axis=0).mean(),\n            \"min_probability\": p.min(),\n            \"max_probability\": p.max(),\n            \"avg_probability\": p.mean(),\n        }\n</code></pre>"},{"location":"api/decoders/bp_decoder/#color_code_stim.decoders.BPDecoder.__init__","title":"<code>__init__(dem_manager, comparative_decoding=False, cache_inputs=True)</code>","text":"<p>Initialize the belief propagation decoder.</p> <p>Parameters:</p> Name Type Description Default <code>dem_manager</code> <code>DEMManager</code> <p>Manager providing access to detector error models</p> required <code>comparative_decoding</code> <code>bool</code> <p>Whether to remove observables from DEM before decoding</p> <code>False</code> <code>cache_inputs</code> <code>bool</code> <p>Whether to cache the parity check matrix and probabilities</p> <code>True</code> Source code in <code>src/color_code_stim/decoders/bp_decoder.py</code> <pre><code>def __init__(\n    self,\n    dem_manager: DemManager,\n    comparative_decoding: bool = False,\n    cache_inputs: bool = True,\n):\n    \"\"\"\n    Initialize the belief propagation decoder.\n\n    Parameters\n    ----------\n    dem_manager : DEMManager\n        Manager providing access to detector error models\n    comparative_decoding : bool, default False\n        Whether to remove observables from DEM before decoding\n    cache_inputs : bool, default True\n        Whether to cache the parity check matrix and probabilities\n    \"\"\"\n    self.dem_manager = dem_manager\n    self.comparative_decoding = comparative_decoding\n    self.cache_inputs = cache_inputs\n    self._cached_inputs: Optional[Dict[str, np.ndarray]] = None\n</code></pre>"},{"location":"api/decoders/bp_decoder/#color_code_stim.decoders.BPDecoder.clear_cache","title":"<code>clear_cache()</code>","text":"<p>Clear cached inputs to force recomputation on next decode.</p> Source code in <code>src/color_code_stim/decoders/bp_decoder.py</code> <pre><code>def clear_cache(self):\n    \"\"\"Clear cached inputs to force recomputation on next decode.\"\"\"\n    self._cached_inputs = None\n</code></pre>"},{"location":"api/decoders/bp_decoder/#color_code_stim.decoders.BPDecoder.decode","title":"<code>decode(detector_outcomes, max_iter=10, **kwargs)</code>","text":"<p>Decode detector outcomes using belief propagation.</p> <p>This method uses the LDPC belief propagation decoder to decode detector outcomes. It handles both single samples (1D) and multiple samples (2D).</p> <p>Parameters:</p> Name Type Description Default <code>detector_outcomes</code> <code>ndarray</code> <p>1D or 2D array of detector measurement outcomes to decode. For 1D: single sample with detector outcomes. For 2D: multiple samples, each row is a sample.</p> required <code>max_iter</code> <code>int</code> <p>Maximum number of belief propagation iterations to perform.</p> <code>10</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the BpDecoder constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>tuple</code> <p>(pred, llrs, converge) where: - pred: Predicted error pattern (same dimensionality as input) - llrs: Log probability ratios for each bit - converge: Convergence status (bool for 1D, array for 2D)</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If the 'ldpc' package is not installed.</p> <code>ValueError</code> <p>If detector_outcomes has invalid dimensions (not 1D or 2D).</p> Source code in <code>src/color_code_stim/decoders/bp_decoder.py</code> <pre><code>def decode(\n    self, detector_outcomes: np.ndarray, max_iter: int = 10, **kwargs\n) -&gt; Tuple[np.ndarray, np.ndarray, Union[bool, np.ndarray]]:\n    \"\"\"\n    Decode detector outcomes using belief propagation.\n\n    This method uses the LDPC belief propagation decoder to decode detector\n    outcomes. It handles both single samples (1D) and multiple samples (2D).\n\n    Parameters\n    ----------\n    detector_outcomes : np.ndarray\n        1D or 2D array of detector measurement outcomes to decode.\n        For 1D: single sample with detector outcomes.\n        For 2D: multiple samples, each row is a sample.\n    max_iter : int, default 10\n        Maximum number of belief propagation iterations to perform.\n    **kwargs\n        Additional keyword arguments to pass to the BpDecoder constructor.\n\n    Returns\n    -------\n    tuple\n        (pred, llrs, converge) where:\n        - pred: Predicted error pattern (same dimensionality as input)\n        - llrs: Log probability ratios for each bit\n        - converge: Convergence status (bool for 1D, array for 2D)\n\n    Raises\n    ------\n    ImportError\n        If the 'ldpc' package is not installed.\n    ValueError\n        If detector_outcomes has invalid dimensions (not 1D or 2D).\n    \"\"\"\n    try:\n        from ldpc import BpDecoder\n    except ImportError:\n        raise ImportError(\n            \"The 'ldpc' package is required for belief propagation decoding. \"\n            \"Please install it using: pip install ldpc\"\n        )\n\n    # Get or compute parity check matrix and probabilities\n    if self.cache_inputs and self._cached_inputs is not None:\n        H = self._cached_inputs[\"H\"]\n        p = self._cached_inputs[\"p\"]\n    else:\n        H, p = self._prepare_bp_inputs()\n        if self.cache_inputs:\n            self._cached_inputs = {\"H\": H, \"p\": p}\n\n    detector_outcomes = np.asarray(detector_outcomes)\n\n    # Filter detector outcomes to match the DEM dimensions when observables are removed\n    if self.comparative_decoding:\n        expected_detectors = H.shape[0]\n        if detector_outcomes.shape[-1] != expected_detectors:\n            # Truncate to match the number of detectors in the filtered DEM\n            detector_outcomes = detector_outcomes[..., :expected_detectors]\n\n    # Filter kwargs to only include valid BpDecoder parameters\n    bp_kwargs = {k: v for k, v in kwargs.items() if k in ['bp_method', 'schedule', 'ms_scaling_factor', 'bp_method_type']}\n\n    if detector_outcomes.ndim == 1:\n        # Single sample decoding\n        bpd = BpDecoder(H, error_channel=p, max_iter=max_iter, **bp_kwargs)\n        pred = bpd.decode(detector_outcomes)\n        llrs = bpd.log_prob_ratios\n        converge = bpd.converge\n\n    elif detector_outcomes.ndim == 2:\n        # Multi-sample decoding\n        pred = []\n        llrs = []\n        converge = []\n\n        for det_sng in detector_outcomes:\n            bpd = BpDecoder(H, error_channel=p, max_iter=max_iter, **bp_kwargs)\n            pred.append(bpd.decode(det_sng))\n            llrs.append(bpd.log_prob_ratios)\n            converge.append(bpd.converge)\n\n        pred = np.stack(pred, axis=0)\n        llrs = np.stack(llrs, axis=0)\n        converge = np.stack(converge, axis=0)\n\n    else:\n        raise ValueError(\n            f\"detector_outcomes must be 1D or 2D, got shape {detector_outcomes.shape}\"\n        )\n\n    return pred, llrs, converge\n</code></pre>"},{"location":"api/decoders/bp_decoder/#color_code_stim.decoders.BPDecoder.get_parity_check_info","title":"<code>get_parity_check_info()</code>","text":"<p>Get information about the parity check matrix.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing matrix dimensions, density, and statistics</p> Source code in <code>src/color_code_stim/decoders/bp_decoder.py</code> <pre><code>def get_parity_check_info(self) -&gt; Dict[str, Union[int, float]]:\n    \"\"\"\n    Get information about the parity check matrix.\n\n    Returns\n    -------\n    dict\n        Dictionary containing matrix dimensions, density, and statistics\n    \"\"\"\n    if self._cached_inputs is None:\n        H, p = self._prepare_bp_inputs()\n    else:\n        H = self._cached_inputs[\"H\"]\n        p = self._cached_inputs[\"p\"]\n\n    return {\n        \"matrix_shape\": H.shape,\n        \"num_checks\": H.shape[0],\n        \"num_variables\": H.shape[1],\n        \"density\": H.nnz / (H.shape[0] * H.shape[1]),\n        \"avg_check_degree\": H.sum(axis=1).mean(),\n        \"avg_variable_degree\": H.sum(axis=0).mean(),\n        \"min_probability\": p.min(),\n        \"max_probability\": p.max(),\n        \"avg_probability\": p.mean(),\n    }\n</code></pre>"},{"location":"api/decoders/bp_decoder/#color_code_stim.decoders.BPDecoder.supports_comparative_decoding","title":"<code>supports_comparative_decoding()</code>","text":"<p>Return True - this decoder can work with comparative decoding.</p> Source code in <code>src/color_code_stim/decoders/bp_decoder.py</code> <pre><code>def supports_comparative_decoding(self) -&gt; bool:\n    \"\"\"Return True - this decoder can work with comparative decoding.\"\"\"\n    return True\n</code></pre>"},{"location":"api/decoders/bp_decoder/#color_code_stim.decoders.BPDecoder.supports_predecoding","title":"<code>supports_predecoding()</code>","text":"<p>Return False - this decoder is typically used as pre-decoding itself.</p> Source code in <code>src/color_code_stim/decoders/bp_decoder.py</code> <pre><code>def supports_predecoding(self) -&gt; bool:\n    \"\"\"Return False - this decoder is typically used as pre-decoding itself.\"\"\"\n    return False\n</code></pre>"},{"location":"api/decoders/concat_matching_decoder/","title":"ConcatMatchingDecoder","text":"<p>               Bases: <code>BaseDecoder</code></p> <p>Concatenated minimum-weight perfect matching decoder for color codes.</p> <p>This decoder implements the sophisticated concatenated decoding strategy where each color is decoded in two stages, and the results are combined to find the minimum-weight error correction. It supports comparative decoding for magic state distillation and various pre-decoding strategies.</p> <p>Key Features: - Two-stage MWPM decoding per color (stage 1: local errors, stage 2: global errors) - Comparative decoding: test all logical classes, return minimum weight - Logical gap calculation for post-selection in magic state distillation - Erasure matcher pre-decoding for improved performance - BP pre-decoding integration (when available) - Color-specific decoding with flexible color selection</p> <p>Attributes:</p> Name Type Description <code>dem_manager</code> <code>DEMManager</code> <p>Manager for detector error models and decompositions</p> <code>circuit_type</code> <code>str</code> <p>Type of circuit being decoded</p> <code>num_obs</code> <code>int</code> <p>Number of observables</p> <code>comparative_decoding</code> <code>bool</code> <p>Whether comparative decoding is enabled</p> Source code in <code>src/color_code_stim/decoders/concat_matching_decoder.py</code> <pre><code>class ConcatMatchingDecoder(BaseDecoder):\n    \"\"\"\n    Concatenated minimum-weight perfect matching decoder for color codes.\n\n    This decoder implements the sophisticated concatenated decoding strategy where\n    each color is decoded in two stages, and the results are combined to find the\n    minimum-weight error correction. It supports comparative decoding for magic\n    state distillation and various pre-decoding strategies.\n\n    Key Features:\n    - Two-stage MWPM decoding per color (stage 1: local errors, stage 2: global errors)\n    - Comparative decoding: test all logical classes, return minimum weight\n    - Logical gap calculation for post-selection in magic state distillation\n    - Erasure matcher pre-decoding for improved performance\n    - BP pre-decoding integration (when available)\n    - Color-specific decoding with flexible color selection\n\n    Attributes\n    ----------\n    dem_manager : DEMManager\n        Manager for detector error models and decompositions\n    circuit_type : str\n        Type of circuit being decoded\n    num_obs : int\n        Number of observables\n    comparative_decoding : bool\n        Whether comparative decoding is enabled\n    \"\"\"\n\n    def __init__(\n        self,\n        dem_manager: DemManager,\n    ):\n        \"\"\"\n        Initialize the concatenated matching decoder.\n\n        Parameters\n        ----------\n        dem_manager : DEMManager\n            Manager providing access to decomposed DEMs and matrices\n        \"\"\"\n        self.dem_manager = dem_manager\n        self.circuit_type = dem_manager.circuit_type\n        self.num_obs = dem_manager.circuit.num_observables\n        self.comparative_decoding = dem_manager.comparative_decoding\n\n    def supports_comparative_decoding(self) -&gt; bool:\n        \"\"\"Return True - this decoder supports comparative decoding.\"\"\"\n        return True\n\n    def supports_predecoding(self) -&gt; bool:\n        \"\"\"Return True - this decoder supports pre-decoding strategies.\"\"\"\n        return True\n\n    def decode(\n        self,\n        detector_outcomes: np.ndarray,\n        colors: Union[str, List[str]] = \"all\",\n        logical_value: Union[bool, Sequence[bool], None] = None,\n        erasure_matcher_predecoding: bool = False,\n        partial_correction_by_predecoding: bool = False,\n        full_output: bool = False,\n        check_validity: bool = False,\n        verbose: bool = False,\n        custom_dem_data: Optional[Dict[str, Tuple[Tuple, Tuple]]] = None,\n        **kwargs,\n    ) -&gt; Union[np.ndarray, Tuple[np.ndarray, dict]]:\n        \"\"\"\n        Decode detector outcomes using concatenated MWPM decoding.\n\n        Parameters\n        ----------\n        detector_outcomes : np.ndarray\n            1D or 2D array of detector measurement outcomes.\n            If 1D, interpreted as a single sample.\n            If 2D, each row is a sample, each column a detector.\n        colors : str or list of str, default 'all'\n            Colors to use for decoding. Can be 'all', one of {'r', 'g', 'b'},\n            or a list containing any combination of {'r', 'g', 'b'}.\n        logical_value : bool or sequence of bool, optional\n            Logical value(s) to use for decoding. If None and comparative_decoding\n            is True, all possible logical value combinations will be tested.\n        erasure_matcher_predecoding : bool, default False\n            Whether to use erasure matcher as a pre-decoding step.\n        partial_correction_by_predecoding : bool, default False\n            Whether to apply partial correction from erasure matcher predecoding.\n        full_output : bool, default False\n            Whether to return extra information about the decoding process.\n        check_validity : bool, default False\n            Whether to check the validity of predicted error patterns.\n        verbose : bool, default False\n            Whether to print additional information during decoding.\n        custom_dem_data : dict, optional\n            Custom DEM matrices and probabilities for BP predecoding.\n            Format: {color: ((H1, p1), (H2, p2))} where H1,H2 are parity check\n            matrices and p1,p2 are probability arrays for stages 1 and 2.\n        **kwargs\n            Additional parameters (for compatibility).\n\n        Returns\n        -------\n        np.ndarray or tuple\n            If full_output is False: predicted observables as bool array.\n            If full_output is True: tuple of (predictions, extra_outputs_dict).\n        \"\"\"\n        if erasure_matcher_predecoding:\n            if not self.comparative_decoding:\n                raise ValueError(\n                    \"Erasure matcher predecoding requires comparative_decoding=True\"\n                )\n\n        # Ensure detector_outcomes is 2D\n        detector_outcomes = np.asarray(detector_outcomes, dtype=bool)\n        if detector_outcomes.ndim == 1:\n            detector_outcomes = detector_outcomes.reshape(1, -1)\n\n        # Process color selection\n        if colors == \"all\":\n            colors = [\"r\", \"g\", \"b\"]\n        elif colors in [\"r\", \"g\", \"b\"]:\n            colors = [colors]\n\n        # Generate all logical value combinations for comparative decoding\n        all_logical_values = np.array(\n            list(itertools.product([False, True], repeat=self.num_obs))\n        )\n\n        if logical_value is not None:\n            logical_value = np.asarray(logical_value, dtype=bool).ravel()\n            if len(logical_value) != self.num_obs:\n                raise ValueError(f\"logical_value must have length {self.num_obs}\")\n\n        # Handle cultivation circuit post-selection\n        if self.circuit_type == \"cult+growing\":\n            cult_interface_det_ids = (\n                self.dem_manager.cult_detector_ids\n                + self.dem_manager.interface_detector_ids\n            )\n            cult_success = ~np.any(detector_outcomes[:, cult_interface_det_ids], axis=1)\n            detector_outcomes = detector_outcomes[cult_success, :]\n\n        # Determine number of logical classes to test\n        num_logical_classes = (\n            len(all_logical_values)\n            if self.comparative_decoding and logical_value is None\n            else 1\n        )\n\n        # Stage 1 decoding for all logical classes and colors\n        error_preds_stage1_all = []\n        if verbose:\n            print(\"First-round decoding:\")\n\n        for i in range(num_logical_classes):\n            error_preds_stage1_all.append({})\n            for c in colors:\n                if verbose:\n                    print(f\"    &gt; logical class {i}, color {c}...\")\n\n                if self.comparative_decoding:\n                    detector_outcomes_copy = detector_outcomes.copy()\n                    if logical_value is not None:\n                        detector_outcomes_copy[:, -self.num_obs :] = logical_value\n                    else:\n                        detector_outcomes_copy[:, -self.num_obs :] = all_logical_values[\n                            i\n                        ]\n                    error_preds_stage1_all[i][c] = self._decode_stage1(\n                        detector_outcomes_copy, c, custom_dem_data\n                    )\n                else:\n                    error_preds_stage1_all[i][c] = self._decode_stage1(\n                        detector_outcomes, c, custom_dem_data\n                    )\n\n        # Erasure matcher predecoding\n        if erasure_matcher_predecoding:\n            if len(error_preds_stage1_all) &lt;= 1:\n                raise ValueError(\n                    \"Erasure matcher predecoding requires multiple logical classes\"\n                )\n\n            if verbose:\n                print(\"Erasure matcher predecoding:\")\n\n            (\n                predecoding_obs_preds,\n                predecoding_error_preds,\n                predecoding_weights,\n                predecoding_success,\n            ) = self._erasure_matcher_predecoding(\n                error_preds_stage1_all, detector_outcomes\n            )\n\n            predecoding_failure = ~predecoding_success\n            detector_outcomes_left = detector_outcomes[predecoding_failure, :]\n            error_preds_stage1_left = [\n                {\n                    c: arr[predecoding_failure, :]\n                    for c, arr in error_preds_stage1_all[i].items()\n                }\n                for i in range(len(error_preds_stage1_all))\n            ]\n\n            if verbose:\n                print(\n                    f\"    &gt; # of samples with successful predecoding: {predecoding_success.sum()}\"\n                )\n        else:\n            detector_outcomes_left = detector_outcomes\n            error_preds_stage1_left = error_preds_stage1_all\n\n        # Stage 2 decoding\n        if verbose:\n            print(\"Second-round decoding:\")\n\n        num_left_samples = detector_outcomes_left.shape[0]\n\n        if num_left_samples &gt; 0 and not (\n            erasure_matcher_predecoding and partial_correction_by_predecoding\n        ):\n            num_errors = self.dem_manager.H.shape[1]\n\n            error_preds = np.empty(\n                (num_logical_classes, len(colors), num_left_samples, num_errors),\n                dtype=bool,\n            )\n            weights = np.empty(\n                (num_logical_classes, len(colors), num_left_samples), dtype=float\n            )\n\n            for i in range(len(error_preds_stage1_left)):\n                for i_c, c in enumerate(colors):\n                    if verbose:\n                        print(f\"    &gt; logical class {i}, color {c}...\")\n\n                    if self.comparative_decoding:\n                        detector_outcomes_copy = detector_outcomes_left.copy()\n                        if logical_value is not None:\n                            detector_outcomes_copy[:, -self.num_obs :] = logical_value\n                        else:\n                            detector_outcomes_copy[:, -self.num_obs :] = (\n                                all_logical_values[i]\n                            )\n                        error_preds_new, weights_new = self._decode_stage2(\n                            detector_outcomes_copy,\n                            error_preds_stage1_left[i][c],\n                            c,\n                            custom_dem_data,\n                        )\n                    else:\n                        error_preds_new, weights_new = self._decode_stage2(\n                            detector_outcomes_left,\n                            error_preds_stage1_left[i][c],\n                            c,\n                            custom_dem_data,\n                        )\n\n                    # Map errors back to original DEM ordering\n                    error_preds_new = self.dem_manager.dems_decomposed[\n                        c\n                    ].map_errors_to_org_dem(error_preds_new, stage=2)\n\n                    error_preds[i, i_c, :, :] = error_preds_new\n                    weights[i, i_c, :] = weights_new\n\n            # Find best predictions across logical classes and colors\n            best_logical_classes, best_color_inds, weights_final, logical_gaps = (\n                _get_final_predictions(weights)\n            )\n\n            error_preds_final = error_preds[\n                best_logical_classes, best_color_inds, np.arange(num_left_samples), :\n            ]\n\n            # Calculate observable predictions\n            if self.comparative_decoding:\n                if logical_value is None:\n                    obs_preds_final = all_logical_values[best_logical_classes]\n                    if obs_preds_final.shape != (num_left_samples, self.num_obs):\n                        raise RuntimeError(\"Observable prediction shape mismatch\")\n                else:\n                    obs_preds_final = np.tile(logical_value, (num_left_samples, 1))\n            else:\n                obs_preds_final = np.empty((num_left_samples, self.num_obs), dtype=bool)\n                for i_c, c in enumerate(colors):\n                    obs_matrix = self.dem_manager.obs_matrix\n                    mask = best_color_inds == i_c\n                    obs_preds_final[mask, :] = (\n                        (error_preds_final[mask, :].astype(\"uint8\") @ obs_matrix.T) % 2\n                    ).astype(bool)\n\n            # Adjust color indices for non-standard color selections\n            if colors == [\"r\", \"g\", \"b\"]:\n                best_colors = best_color_inds\n            else:\n                best_colors = np.array([color_to_color_val(c) for c in colors])[\n                    best_color_inds\n                ]\n\n        elif (\n            num_left_samples &gt; 0\n            and erasure_matcher_predecoding\n            and partial_correction_by_predecoding\n        ):\n            # Partial correction strategy\n            predecoding_error_preds_failed = predecoding_error_preds[\n                predecoding_failure, :\n            ].astype(\"uint8\")\n\n            def get_partial_corr(matrix):\n                corr = (predecoding_error_preds_failed @ matrix.T) % 2\n                return corr.astype(bool)\n\n            obs_partial_corr = get_partial_corr(self.dem_manager.obs_matrix)\n            det_partial_corr = get_partial_corr(self.dem_manager.H)\n            detector_outcomes_left ^= det_partial_corr\n\n            # Recursive call with partial correction\n            obs_preds_final = self.decode(\n                detector_outcomes_left,\n                colors=colors,\n                full_output=full_output,\n            )\n            if full_output:\n                obs_preds_final, extra_outputs = obs_preds_final\n            else:\n                extra_outputs = {}\n\n            if obs_preds_final.ndim == 1:\n                obs_preds_final = obs_preds_final[:, np.newaxis]\n\n            if full_output:\n                error_preds_final = extra_outputs[\"error_preds\"]\n                best_colors = extra_outputs[\"best_colors\"]\n                weights_final = extra_outputs[\"weights\"]\n                logical_gaps = extra_outputs[\"logical_gaps\"]\n\n        else:\n            # No samples to decode\n            error_preds_final = np.array([[]], dtype=bool)\n            obs_preds_final = np.array([[]], dtype=bool)\n            best_colors = np.array([], dtype=np.uint8)\n            weights_final = np.array([], dtype=float)\n            logical_gaps = np.array([], dtype=float)\n\n        # Merge predecoding and second-round results\n        if erasure_matcher_predecoding and np.any(predecoding_success):\n            if verbose:\n                print(\"Merging predecoding &amp; second-round decoding outcomes\")\n\n            full_obs_preds_final = predecoding_obs_preds.copy()\n            if full_output:\n                full_best_colors = np.full(detector_outcomes.shape[0], \"P\")\n                full_weights_final = predecoding_weights.copy()\n                full_logical_gaps = np.full(detector_outcomes.shape[0], -1)\n                full_error_preds_final = predecoding_error_preds.copy()\n\n            if detector_outcomes_left.shape[0] &gt; 0:\n                if partial_correction_by_predecoding:\n                    obs_preds_final ^= obs_partial_corr\n                    if full_output:\n                        error_preds_final ^= predecoding_error_preds_failed.astype(bool)\n\n                full_obs_preds_final[predecoding_failure, :] = obs_preds_final\n\n                if full_output:\n                    full_best_colors[predecoding_failure] = best_colors\n                    full_weights_final[predecoding_failure] = weights_final\n                    full_logical_gaps[predecoding_failure] = logical_gaps\n                    full_error_preds_final[predecoding_failure, :] = error_preds_final\n\n            obs_preds_final = full_obs_preds_final\n            if full_output:\n                best_colors = full_best_colors\n                weights_final = full_weights_final\n                logical_gaps = full_logical_gaps\n                error_preds_final = full_error_preds_final\n\n        # Validity checking\n        if check_validity:\n            det_preds = (\n                error_preds_final.astype(\"uint8\") @ self.dem_manager.H.T % 2\n            ).astype(bool)\n            validity = np.all(det_preds == detector_outcomes, axis=1)\n            if verbose:\n                if np.all(validity):\n                    print(\"All predictions are valid\")\n                else:\n                    print(f\"{np.sum(~validity)} invalid predictions found!\")\n\n        # Format output\n        if obs_preds_final.shape[1] == 1:\n            obs_preds_final = obs_preds_final.ravel()\n\n        if full_output:\n            extra_outputs = {\n                \"best_colors\": best_colors,\n                \"weights\": weights_final,\n                \"error_preds\": error_preds_final,\n            }\n\n            if len(error_preds_stage1_all) &gt; 1:\n                extra_outputs[\"logical_gaps\"] = logical_gaps\n                extra_outputs[\"logical_values\"] = all_logical_values\n                if erasure_matcher_predecoding:\n                    extra_outputs[\"erasure_matcher_success\"] = predecoding_success\n                    extra_outputs[\"predecoding_error_preds\"] = predecoding_error_preds\n                    extra_outputs[\"predecoding_obs_preds\"] = predecoding_obs_preds\n\n            if self.circuit_type == \"cult+growing\":\n                extra_outputs[\"cult_success\"] = cult_success\n\n            if check_validity:\n                extra_outputs[\"validity\"] = validity\n\n            return obs_preds_final, extra_outputs\n        else:\n            return obs_preds_final\n\n    def _decode_stage1(\n        self,\n        detector_outcomes: np.ndarray,\n        color: str,\n        custom_dem_data: Optional[Dict[str, Tuple[Tuple, Tuple]]] = None,\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Perform stage 1 decoding for a specific color.\n\n        Stage 1 focuses on local error patterns within each color's subspace.\n\n        Parameters\n        ----------\n        detector_outcomes : np.ndarray\n            2D array of detector outcomes\n        color : str\n            Color to decode ('r', 'g', or 'b')\n\n        Returns\n        -------\n        np.ndarray\n            Stage 1 error predictions\n        \"\"\"\n        det_outcomes_dem1 = detector_outcomes.copy()\n\n        # Use custom DEM data if provided, otherwise use DEM manager data\n        if custom_dem_data and color in custom_dem_data:\n            H, p = custom_dem_data[color][0]  # Stage 1 data (H1, p1)\n        else:\n            H, p = (\n                self.dem_manager.dems_decomposed[color].Hs[0],\n                self.dem_manager.dems_decomposed[color].probs[0],\n            )\n\n        # Remove empty checks\n        checks_to_keep = H.tocsr().getnnz(axis=1) &gt; 0\n        det_outcomes_dem1 = det_outcomes_dem1[:, checks_to_keep]\n        H = H[checks_to_keep, :]\n\n        # MWPM decoding\n        weights = np.log((1 - p) / p)\n        matching = pymatching.Matching.from_check_matrix(H, weights=weights)\n        preds_dem1 = matching.decode_batch(det_outcomes_dem1)\n\n        del det_outcomes_dem1, matching\n        return preds_dem1\n\n    def _decode_stage2(\n        self,\n        detector_outcomes: np.ndarray,\n        preds_dem1: np.ndarray,\n        color: COLOR_LABEL,\n        custom_dem_data: Optional[Dict[str, Tuple[Tuple, Tuple]]] = None,\n    ) -&gt; Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Perform stage 2 decoding for a specific color.\n\n        Stage 2 combines stage 1 predictions with remaining detector information\n        to find global error patterns.\n\n        Parameters\n        ----------\n        detector_outcomes : np.ndarray\n            2D array of detector outcomes\n        preds_dem1 : np.ndarray\n            Stage 1 error predictions\n        color : COLOR_LABEL\n            Color to decode ('r', 'g', or 'b')\n\n        Returns\n        -------\n        tuple\n            (error_predictions, weights) from stage 2 decoding\n        \"\"\"\n        det_outcome_dem2 = detector_outcomes.copy()\n\n        # Mask out detectors not belonging to this color\n        mask = np.full_like(det_outcome_dem2, True)\n        mask[:, self.dem_manager.detector_ids_by_color[color]] = False\n        det_outcome_dem2[mask] = False\n        del mask\n\n        # Combine with stage 1 predictions\n        det_outcome_dem2 = np.concatenate([det_outcome_dem2, preds_dem1], axis=1)\n\n        # Stage 2 MWPM decoding\n        # Use custom DEM data if provided, otherwise use DEM manager data\n        if custom_dem_data and color in custom_dem_data:\n            H, p = custom_dem_data[color][1]  # Stage 2 data (H2, p2)\n        else:\n            H, p = (\n                self.dem_manager.dems_decomposed[color].Hs[1],\n                self.dem_manager.dems_decomposed[color].probs[1],\n            )\n        weights = np.log((1 - p) / p)\n        matching = pymatching.Matching.from_check_matrix(H, weights=weights)\n        preds, weights_new = matching.decode_batch(\n            det_outcome_dem2, return_weights=True\n        )\n\n        return preds, weights_new\n\n    def _find_error_set_intersection(\n        self,\n        preds_dem1: Dict[COLOR_LABEL, np.ndarray],\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Find the intersection of error sets from different colors.\n\n        This method identifies errors that are consistent across all color\n        predictions, used in erasure matcher predecoding.\n\n        Parameters\n        ----------\n        preds_dem1 : dict\n            Stage 1 predictions for each color\n\n        Returns\n        -------\n        np.ndarray\n            Boolean array indicating error set intersection\n        \"\"\"\n        possible_errors = []\n        for c in [\"r\", \"g\", \"b\"]:\n            preds_dem1_c = preds_dem1[c]\n            error_map_matrix = (\n                self.dem_manager.dems_decomposed[c].dems_symbolic[0].error_map_matrix\n            )\n            possible_errors_c = (preds_dem1_c.astype(\"uint8\") @ error_map_matrix) &gt; 0\n            possible_errors.append(possible_errors_c)\n\n        possible_errors = np.stack(possible_errors, axis=-1)\n        error_set_intersection = np.all(possible_errors, axis=-1).astype(bool)\n\n        return error_set_intersection\n\n    def _erasure_matcher_predecoding(\n        self,\n        preds_dem1_all: List[Dict[COLOR_LABEL, np.ndarray]],\n        detector_outcomes: np.ndarray,\n    ) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Perform erasure matcher predecoding.\n\n        This advanced predecoding strategy finds error predictions that are\n        consistent across all colors and logical classes, providing high-confidence\n        corrections before the main decoding stage.\n\n        Parameters\n        ----------\n        preds_dem1_all : list\n            Stage 1 predictions for all logical classes and colors\n        detector_outcomes : np.ndarray\n            Original detector outcomes\n\n        Returns\n        -------\n        tuple\n            (obs_preds, error_preds, weights, validity) from predecoding\n        \"\"\"\n        detector_outcomes = np.asarray(detector_outcomes, dtype=bool)\n\n        # Generate all logical value combinations\n        all_logical_values = list(itertools.product([False, True], repeat=self.num_obs))\n        all_logical_values = np.array(all_logical_values)\n\n        # Calculate error set intersection and weights for each logical class\n        error_preds_all = []\n        weights_all = []\n        for preds_dem1 in preds_dem1_all:\n            error_preds = self._find_error_set_intersection(preds_dem1)\n            llrs_all = np.log(\n                (1 - self.dem_manager.probs_xz) / self.dem_manager.probs_xz\n            )\n            llrs = np.zeros_like(error_preds, dtype=float)\n            llrs[error_preds] = llrs_all[np.where(error_preds)[1]]\n            weights = llrs.sum(axis=1)\n            error_preds_all.append(error_preds)\n            weights_all.append(weights)\n\n        # Stack results\n        error_preds_all = np.stack(error_preds_all, axis=1)\n        weights_all = np.stack(weights_all, axis=1)\n        num_samples = error_preds_all.shape[0]\n\n        # Sort logical classes by prediction weight\n        inds_logical_class_sorted = np.argsort(weights_all, axis=1)\n\n        # Sort error predictions and weights by weight\n        error_preds_all_sorted = error_preds_all[\n            np.arange(num_samples)[:, np.newaxis], inds_logical_class_sorted\n        ].astype(\"uint8\")\n\n        weights_all_sorted = np.take_along_axis(\n            weights_all, inds_logical_class_sorted, axis=1\n        )\n\n        # Check validity (match with detectors and observables)\n        match_with_dets = np.all(\n            ((error_preds_all_sorted @ self.dem_manager.H.T.toarray()) % 2).astype(bool)\n            == detector_outcomes[:, np.newaxis, :],\n            axis=-1,\n        )\n\n        logical_classes_sorted = all_logical_values[inds_logical_class_sorted]\n        match_with_obss = np.all(\n            (\n                (error_preds_all_sorted @ self.dem_manager.obs_matrix.T.toarray()) % 2\n            ).astype(bool)\n            == logical_classes_sorted,\n            axis=-1,\n        )\n\n        validity_full = match_with_dets &amp; match_with_obss\n\n        # Find first valid prediction for each sample\n        inds_first_valid_logical_classes = np.argmax(validity_full, axis=1)\n        obs_preds = logical_classes_sorted[\n            np.arange(num_samples), inds_first_valid_logical_classes, :\n        ]\n        validity = np.any(validity_full, axis=1)\n\n        # Extract weights and error predictions\n        weights = weights_all_sorted[\n            np.arange(num_samples), inds_first_valid_logical_classes\n        ]\n        weights[~validity] = np.inf\n\n        error_preds = error_preds_all_sorted[\n            np.arange(num_samples), inds_first_valid_logical_classes, :\n        ]\n\n        return obs_preds, error_preds, weights, validity\n</code></pre>"},{"location":"api/decoders/concat_matching_decoder/#color_code_stim.decoders.ConcatMatchingDecoder.__init__","title":"<code>__init__(dem_manager)</code>","text":"<p>Initialize the concatenated matching decoder.</p> <p>Parameters:</p> Name Type Description Default <code>dem_manager</code> <code>DEMManager</code> <p>Manager providing access to decomposed DEMs and matrices</p> required Source code in <code>src/color_code_stim/decoders/concat_matching_decoder.py</code> <pre><code>def __init__(\n    self,\n    dem_manager: DemManager,\n):\n    \"\"\"\n    Initialize the concatenated matching decoder.\n\n    Parameters\n    ----------\n    dem_manager : DEMManager\n        Manager providing access to decomposed DEMs and matrices\n    \"\"\"\n    self.dem_manager = dem_manager\n    self.circuit_type = dem_manager.circuit_type\n    self.num_obs = dem_manager.circuit.num_observables\n    self.comparative_decoding = dem_manager.comparative_decoding\n</code></pre>"},{"location":"api/decoders/concat_matching_decoder/#color_code_stim.decoders.ConcatMatchingDecoder.decode","title":"<code>decode(detector_outcomes, colors='all', logical_value=None, erasure_matcher_predecoding=False, partial_correction_by_predecoding=False, full_output=False, check_validity=False, verbose=False, custom_dem_data=None, **kwargs)</code>","text":"<p>Decode detector outcomes using concatenated MWPM decoding.</p> <p>Parameters:</p> Name Type Description Default <code>detector_outcomes</code> <code>ndarray</code> <p>1D or 2D array of detector measurement outcomes. If 1D, interpreted as a single sample. If 2D, each row is a sample, each column a detector.</p> required <code>colors</code> <code>str or list of str</code> <p>Colors to use for decoding. Can be 'all', one of {'r', 'g', 'b'}, or a list containing any combination of {'r', 'g', 'b'}.</p> <code>'all'</code> <code>logical_value</code> <code>bool or sequence of bool</code> <p>Logical value(s) to use for decoding. If None and comparative_decoding is True, all possible logical value combinations will be tested.</p> <code>None</code> <code>erasure_matcher_predecoding</code> <code>bool</code> <p>Whether to use erasure matcher as a pre-decoding step.</p> <code>False</code> <code>partial_correction_by_predecoding</code> <code>bool</code> <p>Whether to apply partial correction from erasure matcher predecoding.</p> <code>False</code> <code>full_output</code> <code>bool</code> <p>Whether to return extra information about the decoding process.</p> <code>False</code> <code>check_validity</code> <code>bool</code> <p>Whether to check the validity of predicted error patterns.</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>Whether to print additional information during decoding.</p> <code>False</code> <code>custom_dem_data</code> <code>dict</code> <p>Custom DEM matrices and probabilities for BP predecoding. Format: {color: ((H1, p1), (H2, p2))} where H1,H2 are parity check matrices and p1,p2 are probability arrays for stages 1 and 2.</p> <code>None</code> <code>**kwargs</code> <p>Additional parameters (for compatibility).</p> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray or tuple</code> <p>If full_output is False: predicted observables as bool array. If full_output is True: tuple of (predictions, extra_outputs_dict).</p> Source code in <code>src/color_code_stim/decoders/concat_matching_decoder.py</code> <pre><code>def decode(\n    self,\n    detector_outcomes: np.ndarray,\n    colors: Union[str, List[str]] = \"all\",\n    logical_value: Union[bool, Sequence[bool], None] = None,\n    erasure_matcher_predecoding: bool = False,\n    partial_correction_by_predecoding: bool = False,\n    full_output: bool = False,\n    check_validity: bool = False,\n    verbose: bool = False,\n    custom_dem_data: Optional[Dict[str, Tuple[Tuple, Tuple]]] = None,\n    **kwargs,\n) -&gt; Union[np.ndarray, Tuple[np.ndarray, dict]]:\n    \"\"\"\n    Decode detector outcomes using concatenated MWPM decoding.\n\n    Parameters\n    ----------\n    detector_outcomes : np.ndarray\n        1D or 2D array of detector measurement outcomes.\n        If 1D, interpreted as a single sample.\n        If 2D, each row is a sample, each column a detector.\n    colors : str or list of str, default 'all'\n        Colors to use for decoding. Can be 'all', one of {'r', 'g', 'b'},\n        or a list containing any combination of {'r', 'g', 'b'}.\n    logical_value : bool or sequence of bool, optional\n        Logical value(s) to use for decoding. If None and comparative_decoding\n        is True, all possible logical value combinations will be tested.\n    erasure_matcher_predecoding : bool, default False\n        Whether to use erasure matcher as a pre-decoding step.\n    partial_correction_by_predecoding : bool, default False\n        Whether to apply partial correction from erasure matcher predecoding.\n    full_output : bool, default False\n        Whether to return extra information about the decoding process.\n    check_validity : bool, default False\n        Whether to check the validity of predicted error patterns.\n    verbose : bool, default False\n        Whether to print additional information during decoding.\n    custom_dem_data : dict, optional\n        Custom DEM matrices and probabilities for BP predecoding.\n        Format: {color: ((H1, p1), (H2, p2))} where H1,H2 are parity check\n        matrices and p1,p2 are probability arrays for stages 1 and 2.\n    **kwargs\n        Additional parameters (for compatibility).\n\n    Returns\n    -------\n    np.ndarray or tuple\n        If full_output is False: predicted observables as bool array.\n        If full_output is True: tuple of (predictions, extra_outputs_dict).\n    \"\"\"\n    if erasure_matcher_predecoding:\n        if not self.comparative_decoding:\n            raise ValueError(\n                \"Erasure matcher predecoding requires comparative_decoding=True\"\n            )\n\n    # Ensure detector_outcomes is 2D\n    detector_outcomes = np.asarray(detector_outcomes, dtype=bool)\n    if detector_outcomes.ndim == 1:\n        detector_outcomes = detector_outcomes.reshape(1, -1)\n\n    # Process color selection\n    if colors == \"all\":\n        colors = [\"r\", \"g\", \"b\"]\n    elif colors in [\"r\", \"g\", \"b\"]:\n        colors = [colors]\n\n    # Generate all logical value combinations for comparative decoding\n    all_logical_values = np.array(\n        list(itertools.product([False, True], repeat=self.num_obs))\n    )\n\n    if logical_value is not None:\n        logical_value = np.asarray(logical_value, dtype=bool).ravel()\n        if len(logical_value) != self.num_obs:\n            raise ValueError(f\"logical_value must have length {self.num_obs}\")\n\n    # Handle cultivation circuit post-selection\n    if self.circuit_type == \"cult+growing\":\n        cult_interface_det_ids = (\n            self.dem_manager.cult_detector_ids\n            + self.dem_manager.interface_detector_ids\n        )\n        cult_success = ~np.any(detector_outcomes[:, cult_interface_det_ids], axis=1)\n        detector_outcomes = detector_outcomes[cult_success, :]\n\n    # Determine number of logical classes to test\n    num_logical_classes = (\n        len(all_logical_values)\n        if self.comparative_decoding and logical_value is None\n        else 1\n    )\n\n    # Stage 1 decoding for all logical classes and colors\n    error_preds_stage1_all = []\n    if verbose:\n        print(\"First-round decoding:\")\n\n    for i in range(num_logical_classes):\n        error_preds_stage1_all.append({})\n        for c in colors:\n            if verbose:\n                print(f\"    &gt; logical class {i}, color {c}...\")\n\n            if self.comparative_decoding:\n                detector_outcomes_copy = detector_outcomes.copy()\n                if logical_value is not None:\n                    detector_outcomes_copy[:, -self.num_obs :] = logical_value\n                else:\n                    detector_outcomes_copy[:, -self.num_obs :] = all_logical_values[\n                        i\n                    ]\n                error_preds_stage1_all[i][c] = self._decode_stage1(\n                    detector_outcomes_copy, c, custom_dem_data\n                )\n            else:\n                error_preds_stage1_all[i][c] = self._decode_stage1(\n                    detector_outcomes, c, custom_dem_data\n                )\n\n    # Erasure matcher predecoding\n    if erasure_matcher_predecoding:\n        if len(error_preds_stage1_all) &lt;= 1:\n            raise ValueError(\n                \"Erasure matcher predecoding requires multiple logical classes\"\n            )\n\n        if verbose:\n            print(\"Erasure matcher predecoding:\")\n\n        (\n            predecoding_obs_preds,\n            predecoding_error_preds,\n            predecoding_weights,\n            predecoding_success,\n        ) = self._erasure_matcher_predecoding(\n            error_preds_stage1_all, detector_outcomes\n        )\n\n        predecoding_failure = ~predecoding_success\n        detector_outcomes_left = detector_outcomes[predecoding_failure, :]\n        error_preds_stage1_left = [\n            {\n                c: arr[predecoding_failure, :]\n                for c, arr in error_preds_stage1_all[i].items()\n            }\n            for i in range(len(error_preds_stage1_all))\n        ]\n\n        if verbose:\n            print(\n                f\"    &gt; # of samples with successful predecoding: {predecoding_success.sum()}\"\n            )\n    else:\n        detector_outcomes_left = detector_outcomes\n        error_preds_stage1_left = error_preds_stage1_all\n\n    # Stage 2 decoding\n    if verbose:\n        print(\"Second-round decoding:\")\n\n    num_left_samples = detector_outcomes_left.shape[0]\n\n    if num_left_samples &gt; 0 and not (\n        erasure_matcher_predecoding and partial_correction_by_predecoding\n    ):\n        num_errors = self.dem_manager.H.shape[1]\n\n        error_preds = np.empty(\n            (num_logical_classes, len(colors), num_left_samples, num_errors),\n            dtype=bool,\n        )\n        weights = np.empty(\n            (num_logical_classes, len(colors), num_left_samples), dtype=float\n        )\n\n        for i in range(len(error_preds_stage1_left)):\n            for i_c, c in enumerate(colors):\n                if verbose:\n                    print(f\"    &gt; logical class {i}, color {c}...\")\n\n                if self.comparative_decoding:\n                    detector_outcomes_copy = detector_outcomes_left.copy()\n                    if logical_value is not None:\n                        detector_outcomes_copy[:, -self.num_obs :] = logical_value\n                    else:\n                        detector_outcomes_copy[:, -self.num_obs :] = (\n                            all_logical_values[i]\n                        )\n                    error_preds_new, weights_new = self._decode_stage2(\n                        detector_outcomes_copy,\n                        error_preds_stage1_left[i][c],\n                        c,\n                        custom_dem_data,\n                    )\n                else:\n                    error_preds_new, weights_new = self._decode_stage2(\n                        detector_outcomes_left,\n                        error_preds_stage1_left[i][c],\n                        c,\n                        custom_dem_data,\n                    )\n\n                # Map errors back to original DEM ordering\n                error_preds_new = self.dem_manager.dems_decomposed[\n                    c\n                ].map_errors_to_org_dem(error_preds_new, stage=2)\n\n                error_preds[i, i_c, :, :] = error_preds_new\n                weights[i, i_c, :] = weights_new\n\n        # Find best predictions across logical classes and colors\n        best_logical_classes, best_color_inds, weights_final, logical_gaps = (\n            _get_final_predictions(weights)\n        )\n\n        error_preds_final = error_preds[\n            best_logical_classes, best_color_inds, np.arange(num_left_samples), :\n        ]\n\n        # Calculate observable predictions\n        if self.comparative_decoding:\n            if logical_value is None:\n                obs_preds_final = all_logical_values[best_logical_classes]\n                if obs_preds_final.shape != (num_left_samples, self.num_obs):\n                    raise RuntimeError(\"Observable prediction shape mismatch\")\n            else:\n                obs_preds_final = np.tile(logical_value, (num_left_samples, 1))\n        else:\n            obs_preds_final = np.empty((num_left_samples, self.num_obs), dtype=bool)\n            for i_c, c in enumerate(colors):\n                obs_matrix = self.dem_manager.obs_matrix\n                mask = best_color_inds == i_c\n                obs_preds_final[mask, :] = (\n                    (error_preds_final[mask, :].astype(\"uint8\") @ obs_matrix.T) % 2\n                ).astype(bool)\n\n        # Adjust color indices for non-standard color selections\n        if colors == [\"r\", \"g\", \"b\"]:\n            best_colors = best_color_inds\n        else:\n            best_colors = np.array([color_to_color_val(c) for c in colors])[\n                best_color_inds\n            ]\n\n    elif (\n        num_left_samples &gt; 0\n        and erasure_matcher_predecoding\n        and partial_correction_by_predecoding\n    ):\n        # Partial correction strategy\n        predecoding_error_preds_failed = predecoding_error_preds[\n            predecoding_failure, :\n        ].astype(\"uint8\")\n\n        def get_partial_corr(matrix):\n            corr = (predecoding_error_preds_failed @ matrix.T) % 2\n            return corr.astype(bool)\n\n        obs_partial_corr = get_partial_corr(self.dem_manager.obs_matrix)\n        det_partial_corr = get_partial_corr(self.dem_manager.H)\n        detector_outcomes_left ^= det_partial_corr\n\n        # Recursive call with partial correction\n        obs_preds_final = self.decode(\n            detector_outcomes_left,\n            colors=colors,\n            full_output=full_output,\n        )\n        if full_output:\n            obs_preds_final, extra_outputs = obs_preds_final\n        else:\n            extra_outputs = {}\n\n        if obs_preds_final.ndim == 1:\n            obs_preds_final = obs_preds_final[:, np.newaxis]\n\n        if full_output:\n            error_preds_final = extra_outputs[\"error_preds\"]\n            best_colors = extra_outputs[\"best_colors\"]\n            weights_final = extra_outputs[\"weights\"]\n            logical_gaps = extra_outputs[\"logical_gaps\"]\n\n    else:\n        # No samples to decode\n        error_preds_final = np.array([[]], dtype=bool)\n        obs_preds_final = np.array([[]], dtype=bool)\n        best_colors = np.array([], dtype=np.uint8)\n        weights_final = np.array([], dtype=float)\n        logical_gaps = np.array([], dtype=float)\n\n    # Merge predecoding and second-round results\n    if erasure_matcher_predecoding and np.any(predecoding_success):\n        if verbose:\n            print(\"Merging predecoding &amp; second-round decoding outcomes\")\n\n        full_obs_preds_final = predecoding_obs_preds.copy()\n        if full_output:\n            full_best_colors = np.full(detector_outcomes.shape[0], \"P\")\n            full_weights_final = predecoding_weights.copy()\n            full_logical_gaps = np.full(detector_outcomes.shape[0], -1)\n            full_error_preds_final = predecoding_error_preds.copy()\n\n        if detector_outcomes_left.shape[0] &gt; 0:\n            if partial_correction_by_predecoding:\n                obs_preds_final ^= obs_partial_corr\n                if full_output:\n                    error_preds_final ^= predecoding_error_preds_failed.astype(bool)\n\n            full_obs_preds_final[predecoding_failure, :] = obs_preds_final\n\n            if full_output:\n                full_best_colors[predecoding_failure] = best_colors\n                full_weights_final[predecoding_failure] = weights_final\n                full_logical_gaps[predecoding_failure] = logical_gaps\n                full_error_preds_final[predecoding_failure, :] = error_preds_final\n\n        obs_preds_final = full_obs_preds_final\n        if full_output:\n            best_colors = full_best_colors\n            weights_final = full_weights_final\n            logical_gaps = full_logical_gaps\n            error_preds_final = full_error_preds_final\n\n    # Validity checking\n    if check_validity:\n        det_preds = (\n            error_preds_final.astype(\"uint8\") @ self.dem_manager.H.T % 2\n        ).astype(bool)\n        validity = np.all(det_preds == detector_outcomes, axis=1)\n        if verbose:\n            if np.all(validity):\n                print(\"All predictions are valid\")\n            else:\n                print(f\"{np.sum(~validity)} invalid predictions found!\")\n\n    # Format output\n    if obs_preds_final.shape[1] == 1:\n        obs_preds_final = obs_preds_final.ravel()\n\n    if full_output:\n        extra_outputs = {\n            \"best_colors\": best_colors,\n            \"weights\": weights_final,\n            \"error_preds\": error_preds_final,\n        }\n\n        if len(error_preds_stage1_all) &gt; 1:\n            extra_outputs[\"logical_gaps\"] = logical_gaps\n            extra_outputs[\"logical_values\"] = all_logical_values\n            if erasure_matcher_predecoding:\n                extra_outputs[\"erasure_matcher_success\"] = predecoding_success\n                extra_outputs[\"predecoding_error_preds\"] = predecoding_error_preds\n                extra_outputs[\"predecoding_obs_preds\"] = predecoding_obs_preds\n\n        if self.circuit_type == \"cult+growing\":\n            extra_outputs[\"cult_success\"] = cult_success\n\n        if check_validity:\n            extra_outputs[\"validity\"] = validity\n\n        return obs_preds_final, extra_outputs\n    else:\n        return obs_preds_final\n</code></pre>"},{"location":"api/decoders/concat_matching_decoder/#color_code_stim.decoders.ConcatMatchingDecoder.supports_comparative_decoding","title":"<code>supports_comparative_decoding()</code>","text":"<p>Return True - this decoder supports comparative decoding.</p> Source code in <code>src/color_code_stim/decoders/concat_matching_decoder.py</code> <pre><code>def supports_comparative_decoding(self) -&gt; bool:\n    \"\"\"Return True - this decoder supports comparative decoding.\"\"\"\n    return True\n</code></pre>"},{"location":"api/decoders/concat_matching_decoder/#color_code_stim.decoders.ConcatMatchingDecoder.supports_predecoding","title":"<code>supports_predecoding()</code>","text":"<p>Return True - this decoder supports pre-decoding strategies.</p> Source code in <code>src/color_code_stim/decoders/concat_matching_decoder.py</code> <pre><code>def supports_predecoding(self) -&gt; bool:\n    \"\"\"Return True - this decoder supports pre-decoding strategies.\"\"\"\n    return True\n</code></pre>"},{"location":"api/dem_utils/dem_decomp/","title":"DemDecomp","text":"<p>Decomposition of a detector error model (DEM) into two stages for concatenated color code decoding.</p> <p>This class decomposes a detector error model into a restricted DEM (stage 1) and a monochromatic DEM (stage 2) for a specific color in the color code.</p> <p>Attributes:</p> Name Type Description <code>color</code> <code>one of {\"r\", \"g\", \"b\"}</code> <p>The color for which the DEM is decomposed.</p> <code>_dems</code> <code>2-tuple of stim.DetectorErrorModel</code> <p>The decomposed detector error models for stages 1 and 2. Can be accessed simply by <code>self[0]</code> and <code>self[1]</code>.</p> <code>dems_symbolic</code> <code>2-tuple of _DemSymbolic</code> <p>Symbolic representations of the decomposed DEMs.</p> <code>Hs</code> <code>2-tuple of csc_matrix (bool)</code> <p>Parity check matrices for stages 1 and 2.</p> <code>probs</code> <code>2-tuple of 1D numpy array (float)</code> <p>Error probabilities for stages 1 and 2.</p> <code>org_dem</code> <code>DetectorErrorModel</code> <p>The original detector error model.</p> <code>org_prob</code> <code>1D numpy array (float)</code> <p>Error probabilities of the original DEM.</p> <code>error_map_matrices</code> <code>2-tuple of csr_matrix (bool)</code> <p>Matrices mapping errors in decomposed DEMs to errors in original DEM.</p> Source code in <code>src/color_code_stim/dem_utils/dem_decomp.py</code> <pre><code>class DemDecomp:\n    \"\"\"\n    Decomposition of a detector error model (DEM) into two stages for concatenated color\n    code decoding.\n\n    This class decomposes a detector error model into a restricted DEM (stage 1) and\n    a monochromatic DEM (stage 2) for a specific color in the color code.\n\n    Attributes\n    ----------\n    color : one of {\"r\", \"g\", \"b\"}\n        The color for which the DEM is decomposed.\n    _dems : 2-tuple of stim.DetectorErrorModel\n        The decomposed detector error models for stages 1 and 2.\n        Can be accessed simply by `self[0]` and `self[1]`.\n    dems_symbolic : 2-tuple of _DemSymbolic\n        Symbolic representations of the decomposed DEMs.\n    Hs : 2-tuple of csc_matrix (bool)\n        Parity check matrices for stages 1 and 2.\n    probs : 2-tuple of 1D numpy array (float)\n        Error probabilities for stages 1 and 2.\n    org_dem : stim.DetectorErrorModel\n        The original detector error model.\n    org_prob : 1D numpy array (float)\n        Error probabilities of the original DEM.\n    error_map_matrices : 2-tuple of csr_matrix (bool)\n        Matrices mapping errors in decomposed DEMs to errors in original DEM.\n    \"\"\"\n\n    color: COLOR_LABEL\n    _dems: Tuple[stim.DetectorErrorModel, stim.DetectorErrorModel]\n    dems_symbolic: Tuple[_DemSymbolic, _DemSymbolic]\n    Hs: Tuple[csc_matrix, csc_matrix]\n    probs: Tuple[np.ndarray, np.ndarray]\n    obs_matrix_stage2: csc_matrix\n    org_dem: stim.DetectorErrorModel\n    org_prob: np.ndarray\n    error_map_matrices: Tuple[\n        csr_matrix, csr_matrix\n    ]  # Each: (# of errors in decomp DEM, # of errors in org DEM), bool\n    # _best_org_error_map: Tuple[np.ndarray, np.ndarray]\n\n    def __init__(\n        self,\n        *,\n        org_dem: stim.DetectorErrorModel,\n        color: COLOR_LABEL,\n        remove_non_edge_like_errors: bool = True,\n    ):\n        \"\"\"\n        Initialize a DemDecomp object for decomposing a detector error model.\n\n        Parameters\n        ----------\n        org_dem : stim.DetectorErrorModel\n            The original detector error model to decompose.\n        color : one of {\"r\", \"g\", \"b\"}\n            The color ('r', 'g', or 'b') for which to decompose the DEM.\n        remove_non_edge_like_errors : bool, default True\n            Whether to remove error mechanisms that are not edge-like when decomposing\n            the original DEM into two stages.\n        \"\"\"\n        self.color = color\n        self.org_dem = org_dem\n\n        dem1_sym, dem2_sym = self.decompose_org_dem(\n            remove_non_edge_like_errors=remove_non_edge_like_errors\n        )\n        self.dems_symbolic = dem1_sym, dem2_sym\n\n        _, _, org_prob = dem_to_parity_check(org_dem)\n        dem1, _ = dem1_sym.to_dem(org_prob)\n        dem2, inds_dem2 = dem2_sym.to_dem(org_prob, sort=True)\n        self._dems = dem1, dem2\n        self.org_prob = org_prob\n\n        error_map_matrix1 = dem1_sym.error_map_matrix\n        error_map_matrix2 = csr_matrix(dem2_sym.error_map_matrix[inds_dem2, :])\n        self.error_map_matrices = (error_map_matrix1, error_map_matrix2)\n\n        # error_map_matrix2 should have at most one element per row / column\n        # Check rows\n        rows_with_multiple = np.diff(error_map_matrix2.indptr) &gt; 1\n        if np.any(rows_with_multiple):\n            raise ValueError(\n                f\"error_map_matrix2 has {np.sum(rows_with_multiple)} rows with multiple non-zero elements\"\n            )\n\n        # Check columns\n        cols_with_multiple = np.bincount(error_map_matrix2.indices) &gt; 1\n        if np.any(cols_with_multiple):\n            raise ValueError(\n                f\"error_map_matrix2 has {np.sum(cols_with_multiple)} columns with multiple non-zero elements\"\n            )\n\n        H1, _, prob1 = dem_to_parity_check(dem1)\n        H2, obs_matrix_stage2, prob2 = dem_to_parity_check(dem2)\n        self.Hs = (H1, H2)\n        self.probs = (prob1, prob2)\n        self.obs_matrix_stage2 = obs_matrix_stage2\n\n        # self._best_org_error_map = self._precompute_best_org_error_map()\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return the string representation of this object.\"\"\"\n\n        return (\n            f\"&lt;DemDecomp object with color='{self.color}', \"\n            f\"Hs[0].shape={self.Hs[0].shape}, Hs[1].shape={self.Hs[1].shape}&gt;\"\n        )\n\n    def decompose_org_dem(\n        self,\n        remove_non_edge_like_errors: bool = True,\n        _decompose_pauli: bool = True,\n    ) -&gt; Tuple[_DemSymbolic, _DemSymbolic]:\n        \"\"\"\n        Decompose the original DEM into the restricted and monochromatic symbolic DEMs.\n\n        Parameters\n        ----------\n        remove_non_edge_like_errors : bool, default True\n            Whether to remove error mechanisms that are not edge-like.\n        _decompose_pauli : bool, default True\n            Internal parameter to control whether to decompose Pauli X and Z errors.\n\n        Returns\n        -------\n        dem1, dem2: _DemSymbolic\n            Restricted and monochromatic DEMs of the given color, respectively, in\n            symbolic form.\n        \"\"\"\n        # Original XZ-decomposed DEM\n        org_dem = self.org_dem\n\n        # Set of detector ids to be reduced\n        det_ids_to_reduce = []\n        detector_coords = org_dem.get_detector_coordinates()\n        for det_id, coord in detector_coords.items():\n            if coord[4] == {\"r\": 0, \"g\": 1, \"b\": 2}[self.color]:\n                det_ids_to_reduce.append(det_id)\n        det_ids_to_reduce = set(det_ids_to_reduce)\n\n        num_org_error_sources = org_dem.num_errors\n        num_detectors = org_dem.num_detectors\n        org_dem_dets = org_dem[num_org_error_sources:]\n        org_dem_errors = org_dem[:num_org_error_sources]\n\n        # Decompose into X and Z errors (normally not needed, but for cult+growing).\n        # (i.e., ignore correlations between X and Z errors)\n        pauli_decomposed_targets_dict = {}\n        pauli_decomposed_probs_dict = {}\n        for i_em, em in enumerate(org_dem_errors):\n            targets = em.targets_copy()\n            target_labels = []\n            detids = []\n            for target in targets:\n                if target.is_relative_detector_id():\n                    detid = int(str(target)[1:])\n                    target_labels.append(detid)\n                    detids.append(detid)\n                elif target.is_logical_observable_id():\n                    target_labels.append(f\"L{str(target)[1:]}\")\n                else:\n                    raise ValueError(f\"Unknown target: {target}\")\n            det_paulis = [detector_coords[detid][3] for detid in detids]\n            if 0 in det_paulis and 2 in det_paulis and _decompose_pauli:\n                target_labels_X = []\n                targets_X = []\n                target_labels_Z = []\n                targets_Z = []\n                for i_label, (target, label) in enumerate(zip(targets, target_labels)):\n                    if not isinstance(label, str) and det_paulis[i_label] == 0:\n                        target_labels_X.append(label)\n                        targets_X.append(target)\n                    else:\n                        target_labels_Z.append(label)\n                        targets_Z.append(target)\n                target_labels_X = frozenset(target_labels_X)\n                pauli_decomposed_targets_dict[target_labels_X] = targets_X\n                pauli_decomposed_probs_dict[target_labels_X] = [i_em]\n                target_labels_Z = frozenset(target_labels_Z)\n                pauli_decomposed_targets_dict[target_labels_Z] = targets_Z\n                pauli_decomposed_probs_dict[target_labels_Z] = [i_em]\n            else:\n                target_labels = frozenset(target_labels)\n                pauli_decomposed_targets_dict[target_labels] = targets\n                pauli_decomposed_probs_dict[target_labels] = [i_em]\n\n        # Obtain targets list for the two steps\n        dem1_probs_dict = {}\n        dem1_dets_dict = {}\n        dem1_obss_dict = {}\n        dem1_virtual_obs_dict = {}\n\n        # dem2_targets_list = []\n        dem2_probs = []\n        dem2_dets = []\n        dem2_obss = []\n\n        for target_ids in pauli_decomposed_targets_dict:\n            targets = pauli_decomposed_targets_dict[target_ids]\n            prob = pauli_decomposed_probs_dict[target_ids]\n\n            dem1_dets_sng = []\n            dem1_obss_sng = []\n            dem2_dets_sng = []\n            dem2_obss_sng = []\n            dem1_det_ids = set()\n\n            for target in targets:\n                if target.is_logical_observable_id():\n                    dem2_obss_sng.append(target)\n                else:\n                    det_id = int(str(target)[1:])\n                    if det_id in det_ids_to_reduce:\n                        dem2_dets_sng.append(target)\n                    else:\n                        dem1_dets_sng.append(target)\n                        dem1_det_ids.add(det_id)\n\n            if remove_non_edge_like_errors:\n                if dem1_dets_sng:\n                    if len(dem1_dets_sng) &gt;= 3 or len(dem2_dets_sng) &gt;= 2:\n                        continue\n                else:\n                    if len(dem2_dets_sng) &gt;= 3:\n                        continue\n\n            if dem1_det_ids:\n                dem1_det_ids = frozenset(dem1_det_ids)\n                try:\n                    dem1_probs_dict[dem1_det_ids].extend(prob.copy())\n                    virtual_obs = dem1_virtual_obs_dict[dem1_det_ids]\n                except KeyError:\n                    virtual_obs = len(dem1_probs_dict)\n                    # dem1_obss_sng.append(stim.target_logical_observable_id(virtual_obs))\n                    dem1_probs_dict[dem1_det_ids] = prob.copy()\n                    dem1_dets_dict[dem1_det_ids] = dem1_dets_sng\n                    dem1_obss_dict[dem1_det_ids] = dem1_obss_sng\n                    dem1_virtual_obs_dict[dem1_det_ids] = virtual_obs\n\n                virtual_det_id = num_detectors + virtual_obs\n                dem2_dets_sng.append(stim.target_relative_detector_id(virtual_det_id))\n\n            # Add a virtual observable to dem2 for distinguishing error sources\n            # L0: real observable. L1, L2, ...: virtual observables.\n            dem2_dets.append(dem2_dets_sng)\n            dem2_obss.append(dem2_obss_sng)\n            dem2_probs.append(prob)\n\n        # Convert dem1 information to lists\n        dem1_probs = list(dem1_probs_dict.values())\n        dem1_dets = [dem1_dets_dict[key] for key in dem1_probs_dict]\n        dem1_obss = [dem1_obss_dict[key] for key in dem1_probs_dict]\n\n        # Convert to _DemSymbolic objects\n        dem1_sym = _DemSymbolic(\n            dem1_probs, dem1_dets, dem1_obss, org_dem_dets, org_dem.num_errors\n        )\n        dem2_sym = _DemSymbolic(\n            dem2_probs, dem2_dets, dem2_obss, org_dem_dets, org_dem.num_errors\n        )\n\n        return dem1_sym, dem2_sym\n\n    def map_errors_to_org_dem(\n        self, errors: List[bool | int] | np.ndarray | spmatrix, *, stage: int\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Map errors from the decomposed DEM back to the original DEM format.\n\n        Parameters\n        ----------\n        errors : list, numpy array, or scipy sparse matrix of bool/int\n            Errors in the decomposed DEM for the specified stage. If it has more than\n            one dimension, the last dimension is assumed to index the errors.\n        stage : int\n            Which stage's errors to map (1 or 2).\n\n        Returns\n        -------\n        errors_org : numpy array of bool\n            Error array mapped to the original DEM format.\n        \"\"\"\n        if isinstance(errors, spmatrix):\n            errors = errors.astype(\"uint8\")\n        else:\n            errors = np.asarray(errors, dtype=np.uint8)\n\n        error_map_matrix = self.error_map_matrices[stage - 1]\n        errors_org = errors @ error_map_matrix\n        return errors_org\n\n    def __iter__(self) -&gt; Iterator[stim.DetectorErrorModel]:\n        \"\"\"\n        Return an iterator over the decomposed detector error models.\n\n        Returns\n        -------\n        Iterator of stim.DetectorErrorModel\n            Yields the restricted and monochromatic detector error models.\n        \"\"\"\n\n        return iter(self._dems)\n\n    def __getitem__(self, idx: int) -&gt; stim.DetectorErrorModel:\n        \"\"\"\n        Access one of the decomposed detector error models by index.\n\n        Parameters\n        ----------\n        idx : int\n            ``0`` for the restricted model or ``1`` for the monochromatic model.\n\n        Returns\n        -------\n        stim.DetectorErrorModel\n            The selected detector error model.\n        \"\"\"\n\n        return self._dems[idx]\n</code></pre>"},{"location":"api/dem_utils/dem_decomp/#color_code_stim.dem_utils.DemDecomp.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Access one of the decomposed detector error models by index.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p><code>0</code> for the restricted model or <code>1</code> for the monochromatic model.</p> required <p>Returns:</p> Type Description <code>DetectorErrorModel</code> <p>The selected detector error model.</p> Source code in <code>src/color_code_stim/dem_utils/dem_decomp.py</code> <pre><code>def __getitem__(self, idx: int) -&gt; stim.DetectorErrorModel:\n    \"\"\"\n    Access one of the decomposed detector error models by index.\n\n    Parameters\n    ----------\n    idx : int\n        ``0`` for the restricted model or ``1`` for the monochromatic model.\n\n    Returns\n    -------\n    stim.DetectorErrorModel\n        The selected detector error model.\n    \"\"\"\n\n    return self._dems[idx]\n</code></pre>"},{"location":"api/dem_utils/dem_decomp/#color_code_stim.dem_utils.DemDecomp.__init__","title":"<code>__init__(*, org_dem, color, remove_non_edge_like_errors=True)</code>","text":"<p>Initialize a DemDecomp object for decomposing a detector error model.</p> <p>Parameters:</p> Name Type Description Default <code>org_dem</code> <code>DetectorErrorModel</code> <p>The original detector error model to decompose.</p> required <code>color</code> <code>one of {\"r\", \"g\", \"b\"}</code> <p>The color ('r', 'g', or 'b') for which to decompose the DEM.</p> required <code>remove_non_edge_like_errors</code> <code>bool</code> <p>Whether to remove error mechanisms that are not edge-like when decomposing the original DEM into two stages.</p> <code>True</code> Source code in <code>src/color_code_stim/dem_utils/dem_decomp.py</code> <pre><code>def __init__(\n    self,\n    *,\n    org_dem: stim.DetectorErrorModel,\n    color: COLOR_LABEL,\n    remove_non_edge_like_errors: bool = True,\n):\n    \"\"\"\n    Initialize a DemDecomp object for decomposing a detector error model.\n\n    Parameters\n    ----------\n    org_dem : stim.DetectorErrorModel\n        The original detector error model to decompose.\n    color : one of {\"r\", \"g\", \"b\"}\n        The color ('r', 'g', or 'b') for which to decompose the DEM.\n    remove_non_edge_like_errors : bool, default True\n        Whether to remove error mechanisms that are not edge-like when decomposing\n        the original DEM into two stages.\n    \"\"\"\n    self.color = color\n    self.org_dem = org_dem\n\n    dem1_sym, dem2_sym = self.decompose_org_dem(\n        remove_non_edge_like_errors=remove_non_edge_like_errors\n    )\n    self.dems_symbolic = dem1_sym, dem2_sym\n\n    _, _, org_prob = dem_to_parity_check(org_dem)\n    dem1, _ = dem1_sym.to_dem(org_prob)\n    dem2, inds_dem2 = dem2_sym.to_dem(org_prob, sort=True)\n    self._dems = dem1, dem2\n    self.org_prob = org_prob\n\n    error_map_matrix1 = dem1_sym.error_map_matrix\n    error_map_matrix2 = csr_matrix(dem2_sym.error_map_matrix[inds_dem2, :])\n    self.error_map_matrices = (error_map_matrix1, error_map_matrix2)\n\n    # error_map_matrix2 should have at most one element per row / column\n    # Check rows\n    rows_with_multiple = np.diff(error_map_matrix2.indptr) &gt; 1\n    if np.any(rows_with_multiple):\n        raise ValueError(\n            f\"error_map_matrix2 has {np.sum(rows_with_multiple)} rows with multiple non-zero elements\"\n        )\n\n    # Check columns\n    cols_with_multiple = np.bincount(error_map_matrix2.indices) &gt; 1\n    if np.any(cols_with_multiple):\n        raise ValueError(\n            f\"error_map_matrix2 has {np.sum(cols_with_multiple)} columns with multiple non-zero elements\"\n        )\n\n    H1, _, prob1 = dem_to_parity_check(dem1)\n    H2, obs_matrix_stage2, prob2 = dem_to_parity_check(dem2)\n    self.Hs = (H1, H2)\n    self.probs = (prob1, prob2)\n    self.obs_matrix_stage2 = obs_matrix_stage2\n</code></pre>"},{"location":"api/dem_utils/dem_decomp/#color_code_stim.dem_utils.DemDecomp.__iter__","title":"<code>__iter__()</code>","text":"<p>Return an iterator over the decomposed detector error models.</p> <p>Returns:</p> Type Description <code>Iterator of stim.DetectorErrorModel</code> <p>Yields the restricted and monochromatic detector error models.</p> Source code in <code>src/color_code_stim/dem_utils/dem_decomp.py</code> <pre><code>def __iter__(self) -&gt; Iterator[stim.DetectorErrorModel]:\n    \"\"\"\n    Return an iterator over the decomposed detector error models.\n\n    Returns\n    -------\n    Iterator of stim.DetectorErrorModel\n        Yields the restricted and monochromatic detector error models.\n    \"\"\"\n\n    return iter(self._dems)\n</code></pre>"},{"location":"api/dem_utils/dem_decomp/#color_code_stim.dem_utils.DemDecomp.__repr__","title":"<code>__repr__()</code>","text":"<p>Return the string representation of this object.</p> Source code in <code>src/color_code_stim/dem_utils/dem_decomp.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return the string representation of this object.\"\"\"\n\n    return (\n        f\"&lt;DemDecomp object with color='{self.color}', \"\n        f\"Hs[0].shape={self.Hs[0].shape}, Hs[1].shape={self.Hs[1].shape}&gt;\"\n    )\n</code></pre>"},{"location":"api/dem_utils/dem_decomp/#color_code_stim.dem_utils.DemDecomp.decompose_org_dem","title":"<code>decompose_org_dem(remove_non_edge_like_errors=True, _decompose_pauli=True)</code>","text":"<p>Decompose the original DEM into the restricted and monochromatic symbolic DEMs.</p> <p>Parameters:</p> Name Type Description Default <code>remove_non_edge_like_errors</code> <code>bool</code> <p>Whether to remove error mechanisms that are not edge-like.</p> <code>True</code> <code>_decompose_pauli</code> <code>bool</code> <p>Internal parameter to control whether to decompose Pauli X and Z errors.</p> <code>True</code> <p>Returns:</p> Type Description <code>dem1, dem2: _DemSymbolic</code> <p>Restricted and monochromatic DEMs of the given color, respectively, in symbolic form.</p> Source code in <code>src/color_code_stim/dem_utils/dem_decomp.py</code> <pre><code>def decompose_org_dem(\n    self,\n    remove_non_edge_like_errors: bool = True,\n    _decompose_pauli: bool = True,\n) -&gt; Tuple[_DemSymbolic, _DemSymbolic]:\n    \"\"\"\n    Decompose the original DEM into the restricted and monochromatic symbolic DEMs.\n\n    Parameters\n    ----------\n    remove_non_edge_like_errors : bool, default True\n        Whether to remove error mechanisms that are not edge-like.\n    _decompose_pauli : bool, default True\n        Internal parameter to control whether to decompose Pauli X and Z errors.\n\n    Returns\n    -------\n    dem1, dem2: _DemSymbolic\n        Restricted and monochromatic DEMs of the given color, respectively, in\n        symbolic form.\n    \"\"\"\n    # Original XZ-decomposed DEM\n    org_dem = self.org_dem\n\n    # Set of detector ids to be reduced\n    det_ids_to_reduce = []\n    detector_coords = org_dem.get_detector_coordinates()\n    for det_id, coord in detector_coords.items():\n        if coord[4] == {\"r\": 0, \"g\": 1, \"b\": 2}[self.color]:\n            det_ids_to_reduce.append(det_id)\n    det_ids_to_reduce = set(det_ids_to_reduce)\n\n    num_org_error_sources = org_dem.num_errors\n    num_detectors = org_dem.num_detectors\n    org_dem_dets = org_dem[num_org_error_sources:]\n    org_dem_errors = org_dem[:num_org_error_sources]\n\n    # Decompose into X and Z errors (normally not needed, but for cult+growing).\n    # (i.e., ignore correlations between X and Z errors)\n    pauli_decomposed_targets_dict = {}\n    pauli_decomposed_probs_dict = {}\n    for i_em, em in enumerate(org_dem_errors):\n        targets = em.targets_copy()\n        target_labels = []\n        detids = []\n        for target in targets:\n            if target.is_relative_detector_id():\n                detid = int(str(target)[1:])\n                target_labels.append(detid)\n                detids.append(detid)\n            elif target.is_logical_observable_id():\n                target_labels.append(f\"L{str(target)[1:]}\")\n            else:\n                raise ValueError(f\"Unknown target: {target}\")\n        det_paulis = [detector_coords[detid][3] for detid in detids]\n        if 0 in det_paulis and 2 in det_paulis and _decompose_pauli:\n            target_labels_X = []\n            targets_X = []\n            target_labels_Z = []\n            targets_Z = []\n            for i_label, (target, label) in enumerate(zip(targets, target_labels)):\n                if not isinstance(label, str) and det_paulis[i_label] == 0:\n                    target_labels_X.append(label)\n                    targets_X.append(target)\n                else:\n                    target_labels_Z.append(label)\n                    targets_Z.append(target)\n            target_labels_X = frozenset(target_labels_X)\n            pauli_decomposed_targets_dict[target_labels_X] = targets_X\n            pauli_decomposed_probs_dict[target_labels_X] = [i_em]\n            target_labels_Z = frozenset(target_labels_Z)\n            pauli_decomposed_targets_dict[target_labels_Z] = targets_Z\n            pauli_decomposed_probs_dict[target_labels_Z] = [i_em]\n        else:\n            target_labels = frozenset(target_labels)\n            pauli_decomposed_targets_dict[target_labels] = targets\n            pauli_decomposed_probs_dict[target_labels] = [i_em]\n\n    # Obtain targets list for the two steps\n    dem1_probs_dict = {}\n    dem1_dets_dict = {}\n    dem1_obss_dict = {}\n    dem1_virtual_obs_dict = {}\n\n    # dem2_targets_list = []\n    dem2_probs = []\n    dem2_dets = []\n    dem2_obss = []\n\n    for target_ids in pauli_decomposed_targets_dict:\n        targets = pauli_decomposed_targets_dict[target_ids]\n        prob = pauli_decomposed_probs_dict[target_ids]\n\n        dem1_dets_sng = []\n        dem1_obss_sng = []\n        dem2_dets_sng = []\n        dem2_obss_sng = []\n        dem1_det_ids = set()\n\n        for target in targets:\n            if target.is_logical_observable_id():\n                dem2_obss_sng.append(target)\n            else:\n                det_id = int(str(target)[1:])\n                if det_id in det_ids_to_reduce:\n                    dem2_dets_sng.append(target)\n                else:\n                    dem1_dets_sng.append(target)\n                    dem1_det_ids.add(det_id)\n\n        if remove_non_edge_like_errors:\n            if dem1_dets_sng:\n                if len(dem1_dets_sng) &gt;= 3 or len(dem2_dets_sng) &gt;= 2:\n                    continue\n            else:\n                if len(dem2_dets_sng) &gt;= 3:\n                    continue\n\n        if dem1_det_ids:\n            dem1_det_ids = frozenset(dem1_det_ids)\n            try:\n                dem1_probs_dict[dem1_det_ids].extend(prob.copy())\n                virtual_obs = dem1_virtual_obs_dict[dem1_det_ids]\n            except KeyError:\n                virtual_obs = len(dem1_probs_dict)\n                # dem1_obss_sng.append(stim.target_logical_observable_id(virtual_obs))\n                dem1_probs_dict[dem1_det_ids] = prob.copy()\n                dem1_dets_dict[dem1_det_ids] = dem1_dets_sng\n                dem1_obss_dict[dem1_det_ids] = dem1_obss_sng\n                dem1_virtual_obs_dict[dem1_det_ids] = virtual_obs\n\n            virtual_det_id = num_detectors + virtual_obs\n            dem2_dets_sng.append(stim.target_relative_detector_id(virtual_det_id))\n\n        # Add a virtual observable to dem2 for distinguishing error sources\n        # L0: real observable. L1, L2, ...: virtual observables.\n        dem2_dets.append(dem2_dets_sng)\n        dem2_obss.append(dem2_obss_sng)\n        dem2_probs.append(prob)\n\n    # Convert dem1 information to lists\n    dem1_probs = list(dem1_probs_dict.values())\n    dem1_dets = [dem1_dets_dict[key] for key in dem1_probs_dict]\n    dem1_obss = [dem1_obss_dict[key] for key in dem1_probs_dict]\n\n    # Convert to _DemSymbolic objects\n    dem1_sym = _DemSymbolic(\n        dem1_probs, dem1_dets, dem1_obss, org_dem_dets, org_dem.num_errors\n    )\n    dem2_sym = _DemSymbolic(\n        dem2_probs, dem2_dets, dem2_obss, org_dem_dets, org_dem.num_errors\n    )\n\n    return dem1_sym, dem2_sym\n</code></pre>"},{"location":"api/dem_utils/dem_decomp/#color_code_stim.dem_utils.DemDecomp.map_errors_to_org_dem","title":"<code>map_errors_to_org_dem(errors, *, stage)</code>","text":"<p>Map errors from the decomposed DEM back to the original DEM format.</p> <p>Parameters:</p> Name Type Description Default <code>errors</code> <code>list, numpy array, or scipy sparse matrix of bool/int</code> <p>Errors in the decomposed DEM for the specified stage. If it has more than one dimension, the last dimension is assumed to index the errors.</p> required <code>stage</code> <code>int</code> <p>Which stage's errors to map (1 or 2).</p> required <p>Returns:</p> Name Type Description <code>errors_org</code> <code>numpy array of bool</code> <p>Error array mapped to the original DEM format.</p> Source code in <code>src/color_code_stim/dem_utils/dem_decomp.py</code> <pre><code>def map_errors_to_org_dem(\n    self, errors: List[bool | int] | np.ndarray | spmatrix, *, stage: int\n) -&gt; np.ndarray:\n    \"\"\"\n    Map errors from the decomposed DEM back to the original DEM format.\n\n    Parameters\n    ----------\n    errors : list, numpy array, or scipy sparse matrix of bool/int\n        Errors in the decomposed DEM for the specified stage. If it has more than\n        one dimension, the last dimension is assumed to index the errors.\n    stage : int\n        Which stage's errors to map (1 or 2).\n\n    Returns\n    -------\n    errors_org : numpy array of bool\n        Error array mapped to the original DEM format.\n    \"\"\"\n    if isinstance(errors, spmatrix):\n        errors = errors.astype(\"uint8\")\n    else:\n        errors = np.asarray(errors, dtype=np.uint8)\n\n    error_map_matrix = self.error_map_matrices[stage - 1]\n    errors_org = errors @ error_map_matrix\n    return errors_org\n</code></pre>"},{"location":"api/dem_utils/dem_manager/","title":"DemManager","text":"<p>Manages detector error model generation, decomposition, and detector information.</p> <p>This class handles DEM generation from quantum circuits, color-based decomposition for concatenated decoding, and detector ID mappings for visualization and analysis.</p> <p>Attributes:</p> Name Type Description <code>circuit</code> <code>Circuit</code> <p>The quantum circuit for which to generate the DEM</p> <code>tanner_graph</code> <code>Graph</code> <p>The Tanner graph representation of the code</p> <code>circuit_type</code> <code>str</code> <p>Type of circuit (tri, rec, rec_stability, growing, cult+growing)</p> <code>comparative_decoding</code> <code>bool</code> <p>Whether to use comparative decoding</p> <code>remove_non_edge_like_errors</code> <code>bool</code> <p>Whether to remove non-edge-like errors in decomposition</p> <code>dem_xz</code> <code>DetectorErrorModel</code> <p>The main detector error model</p> <code>H</code> <code>csc_matrix</code> <p>Parity check matrix</p> <code>obs_matrix</code> <code>csc_matrix</code> <p>Observable matrix</p> <code>probs_xz</code> <code>ndarray</code> <p>Error probabilities</p> <code>detector_info</code> <code>dict</code> <p>Dictionary containing detector ID mappings and metadata</p> <code>dems_decomposed</code> <code>dict</code> <p>Color-decomposed DEMs for concatenated decoding</p> Source code in <code>src/color_code_stim/dem_utils/dem_manager.py</code> <pre><code>class DemManager:\n    \"\"\"\n    Manages detector error model generation, decomposition, and detector information.\n\n    This class handles DEM generation from quantum circuits, color-based decomposition\n    for concatenated decoding, and detector ID mappings for visualization and analysis.\n\n    Attributes\n    ----------\n    circuit : stim.Circuit\n        The quantum circuit for which to generate the DEM\n    tanner_graph : ig.Graph\n        The Tanner graph representation of the code\n    circuit_type : str\n        Type of circuit (tri, rec, rec_stability, growing, cult+growing)\n    comparative_decoding : bool\n        Whether to use comparative decoding\n    remove_non_edge_like_errors : bool\n        Whether to remove non-edge-like errors in decomposition\n    dem_xz : stim.DetectorErrorModel\n        The main detector error model\n    H : csc_matrix\n        Parity check matrix\n    obs_matrix : csc_matrix\n        Observable matrix\n    probs_xz : np.ndarray\n        Error probabilities\n    detector_info : dict\n        Dictionary containing detector ID mappings and metadata\n    dems_decomposed : dict\n        Color-decomposed DEMs for concatenated decoding\n    \"\"\"\n\n    def __init__(\n        self,\n        circuit: stim.Circuit,\n        tanner_graph: ig.Graph,\n        circuit_type: str,\n        comparative_decoding: bool = False,\n        remove_non_edge_like_errors: bool = True,\n    ):\n        \"\"\"\n        Initialize DEMManager with circuit and configuration.\n\n        Parameters\n        ----------\n        circuit : stim.Circuit\n            The quantum circuit for which to generate the DEM\n        tanner_graph : ig.Graph\n            The Tanner graph representation of the code\n        circuit_type : str\n            Type of circuit (tri, rec, rec_stability, growing, cult+growing)\n        comparative_decoding : bool, default False\n            Whether to use comparative decoding\n        remove_non_edge_like_errors : bool, default True\n            Whether to remove non-edge-like errors in decomposition\n        \"\"\"\n        # Store configuration\n        self.circuit = circuit\n        self.tanner_graph = tanner_graph\n        self.circuit_type = circuit_type\n        self.comparative_decoding = comparative_decoding\n        self.remove_non_edge_like_errors = remove_non_edge_like_errors\n\n        # Generate detector information first (needed for DEM generation)\n        self.detector_info = self._generate_detector_info()\n\n        # Generate core DEM components\n        self.dem_xz, self.H, self.obs_matrix, self.probs_xz = self._generate_dem()\n\n        # Decompose DEMs by color\n        self.dems_decomposed = self._decompose_dems()\n\n    def _generate_detector_info(self) -&gt; Dict[str, Any]:\n        \"\"\"\n        Generate detector ID mappings and metadata.\n\n        Extracts detector information including color-based groupings,\n        cultivation/interface detector identification, and detector-to-qubit mappings.\n\n        Returns\n        -------\n        dict\n            Dictionary containing:\n            - 'by_color': Dict mapping colors to detector ID lists\n            - 'cult_ids': List of cultivation detector IDs\n            - 'interface_ids': List of interface detector IDs\n            - 'checks_map': List mapping detector IDs to (qubit, time) tuples\n        \"\"\"\n        tanner_graph = self.tanner_graph\n\n        detector_coords_dict = self.circuit.get_detector_coordinates()\n        detector_ids_by_color = {\n            \"r\": [],\n            \"g\": [],\n            \"b\": [],\n        }\n        cult_detector_ids = []\n        interface_detector_ids = []\n        detectors_checks_map = []\n\n        for detector_id in range(self.circuit.num_detectors):\n            coords = detector_coords_dict[detector_id]\n            if self.circuit_type == \"cult+growing\" and len(coords) == 6:\n                # The detector is in the cultivation circuit or the interface region\n                flag = coords[-1]\n                if flag == -1:\n                    interface_detector_ids.append(detector_id)\n                elif flag == -2:\n                    cult_detector_ids.append(detector_id)\n                    continue\n\n            x = round(coords[0])\n            y = round(coords[1])\n            t = round(coords[2])\n            pauli = round(coords[3])\n            color = color_val_to_color(round(coords[4]))\n            is_obs = len(coords) == 6 and round(coords[-1]) &gt;= 0\n\n            if not is_obs:\n                # Ordinary X/Z detectors\n                if pauli == 0:\n                    name = f\"{x}-{y}-X\"\n                    qubit = tanner_graph.vs.find(name=name)\n                    color = qubit[\"color\"]\n                elif pauli == 2:\n                    name = f\"{x}-{y}-Z\"\n                    qubit = tanner_graph.vs.find(name=name)\n                    color = qubit[\"color\"]\n                elif pauli == 1:\n                    try:\n                        name_X = f\"{x + 2}-{y}-X\"\n                        name_Z = f\"{x}-{y}-Z\"\n                        qubit_X = tanner_graph.vs.find(name=name_X)\n                        qubit_Z = tanner_graph.vs.find(name=name_Z)\n                    except ValueError:\n                        name_X = f\"{x}-{y}-X\"\n                        name_Z = f\"{x - 2}-{y}-Z\"\n                        qubit_X = tanner_graph.vs.find(name=name_X)\n                        qubit_Z = tanner_graph.vs.find(name=name_Z)\n                    qubit = (qubit_X, qubit_Z)\n                    color = qubit_X[\"color\"]\n                else:\n                    print(coords)\n                    raise ValueError(f\"Invalid pauli: {pauli}\")\n\n                detectors_checks_map.append((qubit, t))\n\n            detector_ids_by_color[color].append(detector_id)\n\n        return {\n            \"by_color\": detector_ids_by_color,\n            \"cult_ids\": cult_detector_ids,\n            \"interface_ids\": interface_detector_ids,\n            \"checks_map\": detectors_checks_map,\n        }\n\n    def _generate_dem(\n        self,\n    ) -&gt; Tuple[stim.DetectorErrorModel, csc_matrix, csc_matrix, np.ndarray]:\n        \"\"\"\n        Generate detector error model from the quantum circuit.\n\n        Creates the detector error model by separating depolarizing errors and\n        generating the DEM. Handles special cases for cult+growing circuits\n        including detector filtering and probability adjustment.\n\n        Returns\n        -------\n        tuple\n            (dem_xz, H, obs_matrix, probs_xz) where:\n            - dem_xz: Detector error model\n            - H: Parity check matrix\n            - obs_matrix: Observable matrix\n            - probs_xz: Error probabilities\n        \"\"\"\n        circuit_xz = separate_depolarizing_errors(self.circuit)\n        dem_xz = circuit_xz.detector_error_model(flatten_loops=True)\n\n        if self.circuit_type == \"cult+growing\":\n            # Remove error mechanisms that involve detectors that will be post-selected\n            dem_xz_new = stim.DetectorErrorModel()\n            all_detids_in_dem_xz = set()\n            cult_detector_ids = self.detector_info[\"cult_ids\"]\n\n            for inst in dem_xz:\n                keep = True\n                if inst.type == \"error\":\n                    detids = []\n                    for target in inst.targets_copy():\n                        if target.is_relative_detector_id():\n                            detid = int(str(target)[1:])\n                            detids.append(detid)\n                            if (\n                                detid\n                                in cult_detector_ids\n                                # + self.interface_detector_ids\n                            ):\n                                keep = False\n                                continue\n                    if keep:\n                        all_detids_in_dem_xz.update(detids)\n                if keep:\n                    dem_xz_new.append(inst)\n            dem_xz = dem_xz_new\n            probs_dem_xz = [\n                em.args_copy()[0] for em in dem_xz.flattened() if em.type == \"error\"\n            ]\n\n            # After removing, some detectors during growth may not be involved\n            # in any error mechanisms. Although such detectors have very low probability\n            # to be flipped, we add them in the DEM with an arbitrary very small\n            # probability to prevent PyMatching errors.\n            detids_to_add = set(range(self.circuit.num_detectors))\n            detids_to_add -= all_detids_in_dem_xz\n            detids_to_add -= set(cult_detector_ids)\n            detids_to_add = list(detids_to_add)\n            p_very_small = max(probs_dem_xz) ** 2\n            for detid in detids_to_add:\n                dem_xz.append(\n                    \"error\",\n                    p_very_small,\n                    [stim.DemTarget.relative_detector_id(detid)],\n                )\n\n        H, obs_matrix, probs_xz = dem_to_parity_check(dem_xz)\n\n        return dem_xz, H, obs_matrix, probs_xz\n\n    def _decompose_dems(self) -&gt; Dict[COLOR_LABEL, DemDecomp]:\n        \"\"\"\n        Decompose DEM by color for concatenated decoding.\n\n        Creates color-specific DEM decompositions for the concatenated MWPM decoder.\n\n        Returns\n        -------\n        dict\n            Dictionary mapping colors ('r', 'g', 'b') to DemDecomp objects\n        \"\"\"\n        dems_decomposed = {}\n        for c in [\"r\", \"g\", \"b\"]:\n            dem_decomp = DemDecomp(\n                org_dem=self.dem_xz,\n                color=c,\n                remove_non_edge_like_errors=self.remove_non_edge_like_errors,\n            )\n            dems_decomposed[c] = dem_decomp\n        return dems_decomposed\n\n    @property\n    def detector_ids_by_color(self) -&gt; Dict[COLOR_LABEL, List[int]]:\n        \"\"\"Get detector IDs grouped by color.\"\"\"\n        return self.detector_info[\"by_color\"]\n\n    @property\n    def cult_detector_ids(self) -&gt; List[int]:\n        \"\"\"Get cultivation detector IDs.\"\"\"\n        return self.detector_info[\"cult_ids\"]\n\n    @property\n    def interface_detector_ids(self) -&gt; List[int]:\n        \"\"\"Get interface detector IDs.\"\"\"\n        return self.detector_info[\"interface_ids\"]\n\n    @property\n    def detectors_checks_map(self) -&gt; List[Tuple[ig.Vertex, int]]:\n        \"\"\"Get detector-to-qubit mapping.\"\"\"\n        return self.detector_info[\"checks_map\"]\n\n    def get_decomposed_dems(\n        self, color: COLOR_LABEL\n    ) -&gt; Tuple[stim.DetectorErrorModel, stim.DetectorErrorModel]:\n        \"\"\"\n        Get decomposed detector error models for a specific color.\n\n        Parameters\n        ----------\n        color : COLOR_LABEL\n            Color ('r', 'g', or 'b') for which to get decomposed DEMs\n\n        Returns\n        -------\n        tuple\n            (dem1, dem2) - Stage 1 and stage 2 detector error models\n        \"\"\"\n        dem1 = self.dems_decomposed[color][0].copy()\n        dem2 = self.dems_decomposed[color][1].copy()\n        return dem1, dem2\n</code></pre>"},{"location":"api/dem_utils/dem_manager/#color_code_stim.dem_utils.DemManager.cult_detector_ids","title":"<code>cult_detector_ids</code>  <code>property</code>","text":"<p>Get cultivation detector IDs.</p>"},{"location":"api/dem_utils/dem_manager/#color_code_stim.dem_utils.DemManager.detector_ids_by_color","title":"<code>detector_ids_by_color</code>  <code>property</code>","text":"<p>Get detector IDs grouped by color.</p>"},{"location":"api/dem_utils/dem_manager/#color_code_stim.dem_utils.DemManager.detectors_checks_map","title":"<code>detectors_checks_map</code>  <code>property</code>","text":"<p>Get detector-to-qubit mapping.</p>"},{"location":"api/dem_utils/dem_manager/#color_code_stim.dem_utils.DemManager.interface_detector_ids","title":"<code>interface_detector_ids</code>  <code>property</code>","text":"<p>Get interface detector IDs.</p>"},{"location":"api/dem_utils/dem_manager/#color_code_stim.dem_utils.DemManager.__init__","title":"<code>__init__(circuit, tanner_graph, circuit_type, comparative_decoding=False, remove_non_edge_like_errors=True)</code>","text":"<p>Initialize DEMManager with circuit and configuration.</p> <p>Parameters:</p> Name Type Description Default <code>circuit</code> <code>Circuit</code> <p>The quantum circuit for which to generate the DEM</p> required <code>tanner_graph</code> <code>Graph</code> <p>The Tanner graph representation of the code</p> required <code>circuit_type</code> <code>str</code> <p>Type of circuit (tri, rec, rec_stability, growing, cult+growing)</p> required <code>comparative_decoding</code> <code>bool</code> <p>Whether to use comparative decoding</p> <code>False</code> <code>remove_non_edge_like_errors</code> <code>bool</code> <p>Whether to remove non-edge-like errors in decomposition</p> <code>True</code> Source code in <code>src/color_code_stim/dem_utils/dem_manager.py</code> <pre><code>def __init__(\n    self,\n    circuit: stim.Circuit,\n    tanner_graph: ig.Graph,\n    circuit_type: str,\n    comparative_decoding: bool = False,\n    remove_non_edge_like_errors: bool = True,\n):\n    \"\"\"\n    Initialize DEMManager with circuit and configuration.\n\n    Parameters\n    ----------\n    circuit : stim.Circuit\n        The quantum circuit for which to generate the DEM\n    tanner_graph : ig.Graph\n        The Tanner graph representation of the code\n    circuit_type : str\n        Type of circuit (tri, rec, rec_stability, growing, cult+growing)\n    comparative_decoding : bool, default False\n        Whether to use comparative decoding\n    remove_non_edge_like_errors : bool, default True\n        Whether to remove non-edge-like errors in decomposition\n    \"\"\"\n    # Store configuration\n    self.circuit = circuit\n    self.tanner_graph = tanner_graph\n    self.circuit_type = circuit_type\n    self.comparative_decoding = comparative_decoding\n    self.remove_non_edge_like_errors = remove_non_edge_like_errors\n\n    # Generate detector information first (needed for DEM generation)\n    self.detector_info = self._generate_detector_info()\n\n    # Generate core DEM components\n    self.dem_xz, self.H, self.obs_matrix, self.probs_xz = self._generate_dem()\n\n    # Decompose DEMs by color\n    self.dems_decomposed = self._decompose_dems()\n</code></pre>"},{"location":"api/dem_utils/dem_manager/#color_code_stim.dem_utils.DemManager.get_decomposed_dems","title":"<code>get_decomposed_dems(color)</code>","text":"<p>Get decomposed detector error models for a specific color.</p> <p>Parameters:</p> Name Type Description Default <code>color</code> <code>COLOR_LABEL</code> <p>Color ('r', 'g', or 'b') for which to get decomposed DEMs</p> required <p>Returns:</p> Type Description <code>tuple</code> <p>(dem1, dem2) - Stage 1 and stage 2 detector error models</p> Source code in <code>src/color_code_stim/dem_utils/dem_manager.py</code> <pre><code>def get_decomposed_dems(\n    self, color: COLOR_LABEL\n) -&gt; Tuple[stim.DetectorErrorModel, stim.DetectorErrorModel]:\n    \"\"\"\n    Get decomposed detector error models for a specific color.\n\n    Parameters\n    ----------\n    color : COLOR_LABEL\n        Color ('r', 'g', or 'b') for which to get decomposed DEMs\n\n    Returns\n    -------\n    tuple\n        (dem1, dem2) - Stage 1 and stage 2 detector error models\n    \"\"\"\n    dem1 = self.dems_decomposed[color][0].copy()\n    dem2 = self.dems_decomposed[color][1].copy()\n    return dem1, dem2\n</code></pre>"},{"location":"api/simulation/simulator/","title":"Simulator","text":"<p>Simulation and sampling manager for color code circuits.</p> <p>This class handles Monte Carlo simulation, detector/observable sampling, and utility functions for error analysis. It operates on pre-built circuits and integrates with the decoder architecture through dependency injection.</p> Source code in <code>src/color_code_stim/simulation/simulator.py</code> <pre><code>class Simulator:\n    \"\"\"\n    Simulation and sampling manager for color code circuits.\n\n    This class handles Monte Carlo simulation, detector/observable sampling,\n    and utility functions for error analysis. It operates on pre-built circuits\n    and integrates with the decoder architecture through dependency injection.\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        circuit: stim.Circuit,\n        circuit_type: str,\n    ):\n        \"\"\"\n        Initialize the Simulator with required dependencies.\n\n        Parameters\n        ----------\n        circuit : stim.Circuit\n            The quantum circuit to simulate\n        circuit_type : str\n            Type of circuit ('tri', 'rec', 'rec_stability', 'growing', 'cult+growing')\n        \"\"\"\n        self.circuit = circuit\n        self.circuit_type = circuit_type\n\n    def sample(\n        self, shots: int, seed: Optional[int] = None\n    ) -&gt; Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Sample detector outcomes and observables from the quantum circuit.\n\n        Parameters\n        ----------\n        shots : int\n            Number of samples to generate\n        seed : int, optional\n            Seed value to initialize the random number generator\n\n        Returns\n        -------\n        det : 2D numpy array of bool\n            Detector outcomes. det[i,j] is True if and only if the detector\n            with id j in the i-th sample has an outcome of \u22121.\n        obs : 1D or 2D numpy array of bool\n            Observable outcomes. If there is only one observable, returns a 1D array;\n            otherwise returns a 2D array. obs[i] or obs[i,j] is True if and only if\n            the j-th observable (j=0 when 1D) of the i-th sample has an outcome of -1.\n        \"\"\"\n        sampler = self.circuit.compile_detector_sampler(seed=seed)\n        det, obs = sampler.sample(shots, separate_observables=True)\n        if obs.shape[1] == 1:\n            obs = obs.ravel()\n        return det, obs\n\n    def sample_with_errors(\n        self,\n        shots: int,\n        seed: Optional[int] = None,\n    ) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Sample detector outcomes, observables, and errors from the quantum circuit.\n\n        Parameters\n        ----------\n        shots : int\n            Number of samples to generate\n        seed : int, optional\n            Seed value to initialize the random number generator\n\n        Returns\n        -------\n        det : 2D numpy array of bool\n            Detector outcomes. det[i,j] is True if and only if the detector\n            with id j in the i-th sample has an outcome of \u22121.\n        obs : 1D or 2D numpy array of bool\n            Observable outcomes. If there is only one observable, returns a 1D array;\n            otherwise returns a 2D array. obs[i] or obs[i,j] is True if and only if\n            the j-th observable (j=0 when 1D) of the i-th sample has an outcome of -1.\n        errors : 2D numpy array of bool\n            Errors sampled from the quantum circuit. errors[i,j] is True if and only if\n            the j-th error (in the DEM) of the i-th sample has an outcome of -1.\n        \"\"\"\n        dem = self.circuit.detector_error_model()\n        sampler = dem.compile_sampler(seed=seed)\n        det, obs, err = sampler.sample(shots, return_errors=True)\n        if obs.shape[1] == 1:\n            obs = obs.ravel()\n\n        return det, obs, err\n\n    def simulate(\n        self,\n        shots: int,\n        *,\n        decoder_func,\n        colors: Union[List[str], str] = \"all\",\n        alpha: float = 0.01,\n        confint_method: str = \"wilson\",\n        full_output: bool = False,\n        seed: Optional[int] = None,\n        verbose: bool = False,\n        **kwargs,\n    ) -&gt; Tuple[np.ndarray, dict]:\n        \"\"\"\n        Monte-Carlo simulation of quantum error correction decoding.\n\n        Parameters\n        ----------\n        shots : int\n            Number of shots to simulate.\n        decoder_func : callable\n            Decoder function that takes detector outcomes and returns predictions.\n            Should have signature: decoder_func(detector_outcomes, **kwargs) -&gt; predictions\n        colors : Union[List[str], str], default 'all'\n            Colors of the sub-decoding procedures to consider. Can be 'all', one of {'r', 'g', 'b'},\n            or a list containing any combination of {'r', 'g', 'b'}.\n        alpha : float, default 0.01\n            Significance level for the confidence interval calculation.\n        confint_method : str, default 'wilson'\n            Method to calculate the confidence interval.\n            See statsmodels.stats.proportion.proportion_confint for available options.\n        full_output: bool = False,\n            If True, return additional information.\n        seed : Optional[int], default None\n            Seed to initialize the random number generator.\n        verbose : bool, default False\n            If True, print progress information during simulation.\n        **kwargs :\n            Additional keyword arguments for the decoder function.\n\n        Returns\n        -------\n        num_fails : numpy.ndarray\n            Number of failures for each observable.\n        extra_outputs : dict\n            Dictionary containing additional information:\n            - 'stats': Tuple of (pfail, delta_pfail) where pfail is the estimated failure rate\n              and delta_pfail is the half-width of the confidence interval\n            - 'fails': Boolean array indicating which samples failed\n            - Additional outputs from the decoder function if full_output=True\n        \"\"\"\n        if self.circuit_type == \"cult+growing\":\n            raise NotImplementedError(\n                \"Cult+growing circuit type is not supported for this method.\"\n            )\n\n        if colors == \"all\":\n            colors = [\"r\", \"g\", \"b\"]\n\n        if verbose:\n            print(\"Sampling...\")\n\n        shots = round(shots)\n        det, obs = self.sample(shots, seed=seed)\n\n        if verbose:\n            print(\"Decoding...\")\n\n        preds = decoder_func(\n            det,\n            colors=colors,\n            verbose=verbose,\n            full_output=full_output,\n            **kwargs,\n        )\n\n        if full_output:\n            preds, extra_outputs = preds\n\n        if verbose:\n            print(\"Postprocessing...\")\n\n        fails = np.logical_xor(obs, preds)\n        num_fails = np.sum(fails, axis=0)\n\n        if full_output:\n            pfail, delta_pfail = get_pfail(\n                shots, num_fails, alpha=alpha, confint_method=confint_method\n            )\n            extra_outputs[\"stats\"] = (pfail, delta_pfail)\n            extra_outputs[\"fails\"] = fails\n\n            return num_fails, extra_outputs\n\n        else:\n            return num_fails\n</code></pre>"},{"location":"api/simulation/simulator/#color_code_stim.simulation.Simulator.__init__","title":"<code>__init__(*, circuit, circuit_type)</code>","text":"<p>Initialize the Simulator with required dependencies.</p> <p>Parameters:</p> Name Type Description Default <code>circuit</code> <code>Circuit</code> <p>The quantum circuit to simulate</p> required <code>circuit_type</code> <code>str</code> <p>Type of circuit ('tri', 'rec', 'rec_stability', 'growing', 'cult+growing')</p> required Source code in <code>src/color_code_stim/simulation/simulator.py</code> <pre><code>def __init__(\n    self,\n    *,\n    circuit: stim.Circuit,\n    circuit_type: str,\n):\n    \"\"\"\n    Initialize the Simulator with required dependencies.\n\n    Parameters\n    ----------\n    circuit : stim.Circuit\n        The quantum circuit to simulate\n    circuit_type : str\n        Type of circuit ('tri', 'rec', 'rec_stability', 'growing', 'cult+growing')\n    \"\"\"\n    self.circuit = circuit\n    self.circuit_type = circuit_type\n</code></pre>"},{"location":"api/simulation/simulator/#color_code_stim.simulation.Simulator.sample","title":"<code>sample(shots, seed=None)</code>","text":"<p>Sample detector outcomes and observables from the quantum circuit.</p> <p>Parameters:</p> Name Type Description Default <code>shots</code> <code>int</code> <p>Number of samples to generate</p> required <code>seed</code> <code>int</code> <p>Seed value to initialize the random number generator</p> <code>None</code> <p>Returns:</p> Name Type Description <code>det</code> <code>2D numpy array of bool</code> <p>Detector outcomes. det[i,j] is True if and only if the detector with id j in the i-th sample has an outcome of \u22121.</p> <code>obs</code> <code>1D or 2D numpy array of bool</code> <p>Observable outcomes. If there is only one observable, returns a 1D array; otherwise returns a 2D array. obs[i] or obs[i,j] is True if and only if the j-th observable (j=0 when 1D) of the i-th sample has an outcome of -1.</p> Source code in <code>src/color_code_stim/simulation/simulator.py</code> <pre><code>def sample(\n    self, shots: int, seed: Optional[int] = None\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Sample detector outcomes and observables from the quantum circuit.\n\n    Parameters\n    ----------\n    shots : int\n        Number of samples to generate\n    seed : int, optional\n        Seed value to initialize the random number generator\n\n    Returns\n    -------\n    det : 2D numpy array of bool\n        Detector outcomes. det[i,j] is True if and only if the detector\n        with id j in the i-th sample has an outcome of \u22121.\n    obs : 1D or 2D numpy array of bool\n        Observable outcomes. If there is only one observable, returns a 1D array;\n        otherwise returns a 2D array. obs[i] or obs[i,j] is True if and only if\n        the j-th observable (j=0 when 1D) of the i-th sample has an outcome of -1.\n    \"\"\"\n    sampler = self.circuit.compile_detector_sampler(seed=seed)\n    det, obs = sampler.sample(shots, separate_observables=True)\n    if obs.shape[1] == 1:\n        obs = obs.ravel()\n    return det, obs\n</code></pre>"},{"location":"api/simulation/simulator/#color_code_stim.simulation.Simulator.sample_with_errors","title":"<code>sample_with_errors(shots, seed=None)</code>","text":"<p>Sample detector outcomes, observables, and errors from the quantum circuit.</p> <p>Parameters:</p> Name Type Description Default <code>shots</code> <code>int</code> <p>Number of samples to generate</p> required <code>seed</code> <code>int</code> <p>Seed value to initialize the random number generator</p> <code>None</code> <p>Returns:</p> Name Type Description <code>det</code> <code>2D numpy array of bool</code> <p>Detector outcomes. det[i,j] is True if and only if the detector with id j in the i-th sample has an outcome of \u22121.</p> <code>obs</code> <code>1D or 2D numpy array of bool</code> <p>Observable outcomes. If there is only one observable, returns a 1D array; otherwise returns a 2D array. obs[i] or obs[i,j] is True if and only if the j-th observable (j=0 when 1D) of the i-th sample has an outcome of -1.</p> <code>errors</code> <code>2D numpy array of bool</code> <p>Errors sampled from the quantum circuit. errors[i,j] is True if and only if the j-th error (in the DEM) of the i-th sample has an outcome of -1.</p> Source code in <code>src/color_code_stim/simulation/simulator.py</code> <pre><code>def sample_with_errors(\n    self,\n    shots: int,\n    seed: Optional[int] = None,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Sample detector outcomes, observables, and errors from the quantum circuit.\n\n    Parameters\n    ----------\n    shots : int\n        Number of samples to generate\n    seed : int, optional\n        Seed value to initialize the random number generator\n\n    Returns\n    -------\n    det : 2D numpy array of bool\n        Detector outcomes. det[i,j] is True if and only if the detector\n        with id j in the i-th sample has an outcome of \u22121.\n    obs : 1D or 2D numpy array of bool\n        Observable outcomes. If there is only one observable, returns a 1D array;\n        otherwise returns a 2D array. obs[i] or obs[i,j] is True if and only if\n        the j-th observable (j=0 when 1D) of the i-th sample has an outcome of -1.\n    errors : 2D numpy array of bool\n        Errors sampled from the quantum circuit. errors[i,j] is True if and only if\n        the j-th error (in the DEM) of the i-th sample has an outcome of -1.\n    \"\"\"\n    dem = self.circuit.detector_error_model()\n    sampler = dem.compile_sampler(seed=seed)\n    det, obs, err = sampler.sample(shots, return_errors=True)\n    if obs.shape[1] == 1:\n        obs = obs.ravel()\n\n    return det, obs, err\n</code></pre>"},{"location":"api/simulation/simulator/#color_code_stim.simulation.Simulator.simulate","title":"<code>simulate(shots, *, decoder_func, colors='all', alpha=0.01, confint_method='wilson', full_output=False, seed=None, verbose=False, **kwargs)</code>","text":"<p>Monte-Carlo simulation of quantum error correction decoding.</p> <p>Parameters:</p> Name Type Description Default <code>shots</code> <code>int</code> <p>Number of shots to simulate.</p> required <code>decoder_func</code> <code>callable</code> <p>Decoder function that takes detector outcomes and returns predictions. Should have signature: decoder_func(detector_outcomes, **kwargs) -&gt; predictions</p> required <code>colors</code> <code>Union[List[str], str]</code> <p>Colors of the sub-decoding procedures to consider. Can be 'all', one of {'r', 'g', 'b'}, or a list containing any combination of {'r', 'g', 'b'}.</p> <code>'all'</code> <code>alpha</code> <code>float</code> <p>Significance level for the confidence interval calculation.</p> <code>0.01</code> <code>confint_method</code> <code>str</code> <p>Method to calculate the confidence interval. See statsmodels.stats.proportion.proportion_confint for available options.</p> <code>'wilson'</code> <code>full_output</code> <code>bool</code> <p>If True, return additional information.</p> <code>False</code> <code>seed</code> <code>Optional[int]</code> <p>Seed to initialize the random number generator.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If True, print progress information during simulation.</p> <code>False</code> <code>**kwargs</code> <p>Additional keyword arguments for the decoder function.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>num_fails</code> <code>ndarray</code> <p>Number of failures for each observable.</p> <code>extra_outputs</code> <code>dict</code> <p>Dictionary containing additional information: - 'stats': Tuple of (pfail, delta_pfail) where pfail is the estimated failure rate   and delta_pfail is the half-width of the confidence interval - 'fails': Boolean array indicating which samples failed - Additional outputs from the decoder function if full_output=True</p> Source code in <code>src/color_code_stim/simulation/simulator.py</code> <pre><code>def simulate(\n    self,\n    shots: int,\n    *,\n    decoder_func,\n    colors: Union[List[str], str] = \"all\",\n    alpha: float = 0.01,\n    confint_method: str = \"wilson\",\n    full_output: bool = False,\n    seed: Optional[int] = None,\n    verbose: bool = False,\n    **kwargs,\n) -&gt; Tuple[np.ndarray, dict]:\n    \"\"\"\n    Monte-Carlo simulation of quantum error correction decoding.\n\n    Parameters\n    ----------\n    shots : int\n        Number of shots to simulate.\n    decoder_func : callable\n        Decoder function that takes detector outcomes and returns predictions.\n        Should have signature: decoder_func(detector_outcomes, **kwargs) -&gt; predictions\n    colors : Union[List[str], str], default 'all'\n        Colors of the sub-decoding procedures to consider. Can be 'all', one of {'r', 'g', 'b'},\n        or a list containing any combination of {'r', 'g', 'b'}.\n    alpha : float, default 0.01\n        Significance level for the confidence interval calculation.\n    confint_method : str, default 'wilson'\n        Method to calculate the confidence interval.\n        See statsmodels.stats.proportion.proportion_confint for available options.\n    full_output: bool = False,\n        If True, return additional information.\n    seed : Optional[int], default None\n        Seed to initialize the random number generator.\n    verbose : bool, default False\n        If True, print progress information during simulation.\n    **kwargs :\n        Additional keyword arguments for the decoder function.\n\n    Returns\n    -------\n    num_fails : numpy.ndarray\n        Number of failures for each observable.\n    extra_outputs : dict\n        Dictionary containing additional information:\n        - 'stats': Tuple of (pfail, delta_pfail) where pfail is the estimated failure rate\n          and delta_pfail is the half-width of the confidence interval\n        - 'fails': Boolean array indicating which samples failed\n        - Additional outputs from the decoder function if full_output=True\n    \"\"\"\n    if self.circuit_type == \"cult+growing\":\n        raise NotImplementedError(\n            \"Cult+growing circuit type is not supported for this method.\"\n        )\n\n    if colors == \"all\":\n        colors = [\"r\", \"g\", \"b\"]\n\n    if verbose:\n        print(\"Sampling...\")\n\n    shots = round(shots)\n    det, obs = self.sample(shots, seed=seed)\n\n    if verbose:\n        print(\"Decoding...\")\n\n    preds = decoder_func(\n        det,\n        colors=colors,\n        verbose=verbose,\n        full_output=full_output,\n        **kwargs,\n    )\n\n    if full_output:\n        preds, extra_outputs = preds\n\n    if verbose:\n        print(\"Postprocessing...\")\n\n    fails = np.logical_xor(obs, preds)\n    num_fails = np.sum(fails, axis=0)\n\n    if full_output:\n        pfail, delta_pfail = get_pfail(\n            shots, num_fails, alpha=alpha, confint_method=confint_method\n        )\n        extra_outputs[\"stats\"] = (pfail, delta_pfail)\n        extra_outputs[\"fails\"] = fails\n\n        return num_fails, extra_outputs\n\n    else:\n        return num_fails\n</code></pre>"}]}